{
  "hash": "4a9689659ea611445424249e792c18bb",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"H1 - Effect of Abstention on Sendentary Activity\"\nformat: \n  html:\n    toc: true\n    code-fold: true\nauthor: \"Tamas FÃ¶ldes\"\ndate: today\n---\n\n\n\n## Introduction\n\nThis document demonstrates a simulation-based power analysis for a two-arm parallel randomized controlled trial (RCT) with compositional outcomes. The simulation models 24-hour time use data consisting of three components: sleep, sedentary time, and physical activity, which sum to 1440 minutes (24 hours). The analysis includes visualization of power curves and effect sizes to help determine optimal sample sizes and assess the sensitivity of the study design to different parameters.\n\n### Required Packages\n\n\n::: {.cell}\n\n```{.r .cell-code  code-summary=\"Show code (libraries)\"}\n# Load required packages with error handling\nload_package_safely <- function(pkg) {\n  if (!requireNamespace(pkg, quietly = TRUE)) {\n    message(paste(\"Package\", pkg, \"not available, attempting to install...\"))\n    tryCatch({\n      if (pkg %in% c(\"microbiome\", \"ComplexHeatmap\")) {\n        # Bioconductor packages\n        if (!requireNamespace(\"BiocManager\", quietly = TRUE)) install.packages(\"BiocManager\")\n        BiocManager::install(pkg, update = FALSE)\n      } else if (pkg == \"microViz\") {\n        # Special repository\n        install.packages(pkg, repos = c(davidbarnett = \"https://david-barnett.r-universe.dev\", getOption(\"repos\")))\n      } else {\n        # Regular CRAN packages\n        install.packages(pkg)\n      }\n    }, error = function(e) {\n      message(paste(\"Failed to install\", pkg, \":\", e$message))\n    })\n  }\n  \n  # Try to load the package\n  success <- suppressMessages(suppressWarnings(\n    tryCatch({\n      library(pkg, character.only = TRUE)\n      TRUE\n    }, error = function(e) {\n      message(paste(\"Package\", pkg, \"not available, skipping\"))\n      FALSE\n    })\n  ))\n  return(success)\n}\n\n# Load core packages (required for analysis)\ncore_packages <- c(\"tidyverse\", \"lme4\", \"compositions\", \"lmerTest\", \"MASS\")\nmessage(\"Loading core packages...\")\nloaded_core <- sapply(core_packages, load_package_safely)\nif (!all(loaded_core)) {\n  stop(\"Core packages failed to load: \", paste(core_packages[!loaded_core], collapse = \", \"))\n}\n\n# Load optional packages (nice to have but not critical)\noptional_packages <- c(\"ggtern\", \"progress\", \"patchwork\", \"foreach\", \"doSNOW\", \"doParallel\", \"DT\", \"ggtext\", \"ggraph\")\nmessage(\"Loading optional packages...\")\nloaded_optional <- sapply(optional_packages, load_package_safely)\nmessage(\"Optional packages loaded: \", paste(optional_packages[loaded_optional], collapse = \", \"))\nif (any(!loaded_optional)) {\n  message(\"Optional packages not loaded: \", paste(optional_packages[!loaded_optional], collapse = \", \"))\n}\n\n# Load specialized packages (for microbiome analysis, if needed)\n# Note: phyloseq temporarily commented out due to installation issues\nspecialized_packages <- c(\"microbiome\", \"ComplexHeatmap\", \"microViz\", \"corncob\")\nmessage(\"Loading specialized packages...\")\nloaded_specialized <- sapply(specialized_packages, load_package_safely)\nmessage(\"Specialized packages loaded: \", paste(specialized_packages[loaded_specialized], collapse = \", \"))\nif (any(!loaded_specialized)) {\n  message(\"Specialized packages not loaded: \", paste(specialized_packages[!loaded_specialized], collapse = \", \"))\n}\n```\n:::\n\n\n### Helper Functions\n\nThese functions convert between compositional data and isometric log-ratio (ilr) coordinates.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncomp_to_ilr <- function(x_min) {\n  stopifnot(is.matrix(x_min), ncol(x_min) == 3)\n  bad_row <- !is.finite(rowSums(x_min)) | rowSums(x_min) <= 0\n  if (any(bad_row)) {\n    x_min[bad_row, ] <- matrix(rep(c(600, 480, 360), each = sum(bad_row)), ncol = 3, byrow = TRUE)\n  }\n  x_min[x_min <= 0 | !is.finite(x_min)] <- 1e-6\n  compositions::ilr(sweep(x_min, 1, rowSums(x_min), \"/\"))\n}\n\nilr_to_minutes <- function(ilr_mat, total = 1440) {\n  stopifnot(is.matrix(ilr_mat), ncol(ilr_mat) == 2)\n  comp_obj <- compositions::ilrInv(ilr_mat)\n  prop <- as.data.frame(comp_obj)\n  prop <- as.matrix(prop)\n  \n  bad <- apply(prop, 1, function(r) any(!is.finite(r) | r <= 0) ||\n                                   !is.finite(sum(r)) || abs(sum(r) - 1) > 1e-8)\n  if (any(bad)) prop[bad, ] <- 1/3\n  round(prop * total, 1)\n}\n```\n:::\n\n\n### Simulation Engine\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Power estimation using SimEngine â€“ cleaned version (no play_sd_prop, no corr_noise_sd)\n\n# Install SimEngine if not already installed\nif (!requireNamespace(\"SimEngine\", quietly = TRUE)) {\n  install.packages(\"SimEngine\")\n}\n\n# Load required packages\nlibrary(SimEngine)\nlibrary(lme4)\nlibrary(lmerTest)\nlibrary(compositions)\nlibrary(MASS)\nlibrary(dplyr)\n\n# --------------------------------------------------------------------------------\n# Command line argument parsing ---------------------------------------------------\n# --------------------------------------------------------------------------------\n# Parse command line arguments for flexible parameter adjustment\nargs <- commandArgs(trailingOnly = TRUE)\n\n# Default values\ndefault_sims <- 1000\ndefault_cores <- 16\n\n# Parse arguments: --sims=VALUE --cores=VALUE\nsims_param <- default_sims\ncores_param <- default_cores\n\nif (length(args) > 0) {\n  for (arg in args) {\n    if (grepl(\"^--sims=\", arg)) {\n      sims_param <- as.numeric(sub(\"^--sims=\", \"\", arg))\n      if (is.na(sims_param) || sims_param <= 0) {\n        warning(\"Invalid sims parameter, using default: \", default_sims)\n        sims_param <- default_sims\n      }\n    } else if (grepl(\"^--cores=\", arg)) {\n      cores_param <- as.numeric(sub(\"^--cores=\", \"\", arg))\n      if (is.na(cores_param) || cores_param <= 0) {\n        warning(\"Invalid cores parameter, using default: \", default_cores)\n        cores_param <- default_cores\n      }\n    }\n  }\n}\n\n# Log the parameters being used\nmessage(\"=== SIMULATION PARAMETERS ===\")\nmessage(\"Number of simulations: \", sims_param)\nmessage(\"Number of cores: \", cores_param)\nmessage(\"==============================\")\n\n# --------------------------------------------------------------------------------\n# Main simulation wrapper ---------------------------------------------------------\n# --------------------------------------------------------------------------------\n\nest_power_simengine <- function(n_pg = 40,\n                               effect_min_values = c(30),\n                               s_between_values  = c(0.15),\n                               s_within_values   = c(0.25),\n                               baseline_days     = 7,\n                               intervention_days = 14,\n                               sims              = 500,\n                               cores             = 4) {\n\n  start_time <- Sys.time()\n  message(\"Setting up SimEngine simulation â€¦\")\n\n  # Create simulation object\n  sim <- new_sim()\n\n  # ------------------------------------------------------------------------------\n  # LEVELS (note: no play_sd_prop, no corr_noise_sd) ------------------------------\n  # ------------------------------------------------------------------------------\n  sim %<>% set_levels(\n    n_pg             = n_pg,\n    effect_min       = effect_min_values,\n    s_between        = s_between_values,\n    s_within         = s_within_values,\n    baseline_days    = baseline_days,\n    intervention_days= intervention_days\n  )\n\n  # ------------------------------------------------------------------------------\n  # Helper transformations (INSIDE function for parallel access) ------------------\n  # ------------------------------------------------------------------------------\n  \n  comp_to_ilr <- function(x_min) {\n    stopifnot(is.matrix(x_min), ncol(x_min) == 3)\n    bad_row <- !is.finite(rowSums(x_min)) | rowSums(x_min) <= 0\n    if (any(bad_row)) {\n      x_min[bad_row, ] <- matrix(rep(c(600, 480, 360), each = sum(bad_row)), ncol = 3, byrow = TRUE)\n    }\n    x_min[x_min <= 0 | !is.finite(x_min)] <- 1e-6\n    compositions::ilr(sweep(x_min, 1, rowSums(x_min), \"/\"))\n  }\n\n  ilr_to_minutes <- function(ilr_mat, total = 1440) {\n    stopifnot(is.matrix(ilr_mat), ncol(ilr_mat) == 2)\n    comp_obj <- compositions::ilrInv(ilr_mat)\n    prop <- as.matrix(as.data.frame(comp_obj))\n    bad <- apply(prop, 1, function(r) any(!is.finite(r) | r <= 0) ||\n                   !is.finite(sum(r)) || abs(sum(r) - 1) > 1e-8)\n    if (any(bad)) prop[bad, ] <- 1/3\n    round(prop * total, 1)\n  }\n\n  # ------------------------------------------------------------------------------\n  # Dataâ€‘generating function ------------------------------------------------------\n  # ------------------------------------------------------------------------------\n  generate_data <- function(n_pg, effect_min, baseline_days, intervention_days,\n                            s_between, s_within, seed = NULL) {\n\n    if (!is.null(seed)) set.seed(seed)\n\n    N   <- n_pg * 2\n    grp <- rep(0:1, each = n_pg)              # 0 = Control, 1 = Intervention\n\n    # Mean daily compositions: (sedentary, sleep, physical)\n    base_comp   <- c(600, 480, 360)\n    active_comp <- c(600 - effect_min, 480, 360 + effect_min)\n\n    # Personâ€‘level random effects in ILR space\n    b_ilr <- MASS::mvrnorm(N, mu = c(0, 0), Sigma = diag(s_between^2, 2))\n\n    # Person-specific playtime proportion of sedentary time (10-40%)\n    personal_play_prop <- sapply(1:N, function(i) {\n      p <- rbeta(1, 2, 5) * 0.3 + 0.1  # right-skew between 0.1-0.4\n      return(p)\n    })\n\n    # Person-specific compliance rates for intervention group (60-95%)\n    # Control group gets compliance = 1 (no intervention to comply with)\n    personal_compliance <- sapply(1:N, function(i) {\n      if (grp[i] == 0) {\n        return(1.0)  # Control group - no intervention\n      } else {\n        # Intervention group: Beta distribution shifted to 60-95% range\n        # Beta(2,2) gives symmetric distribution, shifted to [0.6, 0.95]\n        compliance <- rbeta(1, 2, 2) * 0.35 + 0.6\n        return(compliance)\n      }\n    })\n    \n    # Daily compliance variation using Kumaraswamy distribution\n    # This adds day-to-day variation in compliance within each person\n    daily_compliance_variation <- function(n_days, base_compliance) {\n      # Use Kumaraswamy distribution to add daily variation\n      # Parameters chosen to create realistic daily fluctuations around base compliance\n      daily_factors <- extraDistr::rkumar(n_days, a = 0.05, b = 0.1)\n      # Scale the factors to create variation around base compliance\n      # This creates realistic day-to-day variation in compliance behavior\n      pmax(0, pmin(1, base_compliance * (0.8 + 0.4 * daily_factors)))\n    }\n\n    # Containers\n    all_ids <- all_periods <- all_days <- NULL\n    all_ilr <- matrix(, 0, 2)\n    all_sedentary <- numeric()  # Store actual sedentary minutes\n\n    for (i in seq_len(N)) {\n      for (period in c(\"baseline\", \"intervention\")) {\n        ndays   <- if (period == \"baseline\") baseline_days else intervention_days\n        comp_mu <- if (period == \"baseline\" || grp[i] == 0) base_comp else active_comp\n\n        comp_ilr <- comp_to_ilr(matrix(rep(comp_mu, ndays), ncol = 3, byrow = TRUE))\n        comp_ilr <- sweep(comp_ilr, 2, b_ilr[i, ], \"+\")               # add person RE\n        day_ilr  <- comp_ilr + MASS::mvrnorm(ndays, mu = c(0, 0),\n                                             Sigma = diag(s_within^2, 2))\n\n        # Index bookkeeping\n        all_ids     <- c(all_ids, rep(i, ndays))\n        all_periods <- c(all_periods, rep(period, ndays))\n        all_days    <- c(all_days,\n                         if (period == \"baseline\") seq_len(baseline_days)\n                         else baseline_days + seq_len(intervention_days))\n        all_ilr     <- rbind(all_ilr, day_ilr)\n        \n        # Store sedentary minutes for this person-period (will be calculated after ILR transformation)\n        # We'll calculate playtime after we have the actual sedentary minutes\n      }\n    }\n\n    # Backâ€‘transform ILR â†’ minutes and calculate playtime based on actual sedentary behavior\n    mins <- ilr_to_minutes(all_ilr)\n    colnames(mins) <- c(\"sedentary\", \"sleep\", \"physical\")\n    \n    # Now generate playtime based on actual sedentary minutes\n    playmin <- numeric(length(all_ids))\n    \n    # Pre-generate daily compliance for each person during intervention period\n    daily_compliance <- list()\n    for (person_id in 1:N) {\n      if (grp[person_id] == 1) {  # Intervention group\n        daily_compliance[[person_id]] <- daily_compliance_variation(\n          intervention_days, \n          personal_compliance[person_id]\n        )\n      } else {\n        daily_compliance[[person_id]] <- rep(1.0, intervention_days)  # Control group\n      }\n    }\n    \n    # Track intervention day counter for each person\n    intervention_day_counter <- rep(0, N)\n    \n    for (i in seq_along(all_ids)) {\n      person_id <- all_ids[i]\n      period <- all_periods[i]\n      actual_sedentary <- mins[i, \"sedentary\"]\n      \n      # Base playtime as proportion of actual sedentary time\n      base_playtime <- personal_play_prop[person_id] * actual_sedentary\n      \n      # Add small amount of day-to-day noise (2% of base playtime)\n      daily_sd <- 0.02 * base_playtime\n      noisy_playtime <- rnorm(1, base_playtime, daily_sd)\n      \n      # Apply intervention effect for intervention group during intervention period\n      if (period == \"intervention\" && grp[person_id] == 1) {\n        # Increment intervention day counter for this person\n        intervention_day_counter[person_id] <- intervention_day_counter[person_id] + 1\n        \n        # Get daily compliance for this person and day\n        daily_compliance_rate <- daily_compliance[[person_id]][intervention_day_counter[person_id]]\n        \n        # Reduce playtime by effect_min * daily compliance rate\n        # Perfect compliance = full effect_min reduction\n        # Partial compliance = proportional reduction\n        actual_reduction <- effect_min * daily_compliance_rate\n        intervention_playtime <- pmax(0, noisy_playtime - actual_reduction)\n        playmin[i] <- intervention_playtime\n      } else {\n        # Control group or baseline period: just use the playtime based on actual sedentary\n        playmin[i] <- pmax(0, noisy_playtime)  # Ensure non-negative\n      }\n    }\n\n    # Create daily compliance values for the dataset\n    daily_compliance_values <- numeric(length(all_ids))\n    intervention_day_counter <- rep(0, N)\n    \n    for (i in seq_along(all_ids)) {\n      person_id <- all_ids[i]\n      period <- all_periods[i]\n      \n      if (period == \"intervention\" && grp[person_id] == 1) {\n        intervention_day_counter[person_id] <- intervention_day_counter[person_id] + 1\n        daily_compliance_values[i] <- daily_compliance[[person_id]][intervention_day_counter[person_id]]\n      } else {\n        daily_compliance_values[i] <- personal_compliance[person_id]\n      }\n    }\n    \n    # Assemble data frame\n    dat <- data.frame(\n      id        = factor(all_ids),\n      group     = factor(grp[all_ids], labels = c(\"Control\", \"Abstinence\")),\n      period    = factor(all_periods, levels = c(\"baseline\", \"intervention\")),\n      day       = all_days,\n      sedentary = mins[, 1],\n      sleep     = mins[, 2],\n      physical  = mins[, 3],\n      playtime  = playmin,\n      compliance = daily_compliance_values,  # Add daily compliance to dataset\n      base_compliance = personal_compliance[all_ids]  # Add base person-level compliance\n    )\n\n    dat <- dat %>%\n      group_by(id) %>%\n      mutate(\n        base_play_mean      = mean(playtime[period == \"baseline\"]),\n        playtime_reduction  = base_play_mean - playtime,\n        intervention_active = as.integer(group == \"Abstinence\" & period == \"intervention\"),\n        # Calculate actual compliance as proportion of intended reduction achieved\n        intended_reduction  = ifelse(group == \"Abstinence\" & period == \"intervention\", effect_min, 0),\n        actual_compliance   = ifelse(intended_reduction > 0, \n                                   pmin(1, playtime_reduction / intended_reduction), \n                                   compliance)\n      ) %>%\n      ungroup()\n\n    return(dat)\n  }\n\n  # ------------------------------------------------------------------------------\n  # Analysis function -------------------------------------------------------------\n  # ------------------------------------------------------------------------------\n  run_analysis <- function(data) {\n    data_ilr <- data\n    comp_matrix <- as.matrix(data[, c(\"sedentary\", \"sleep\", \"physical\")])\n    ilr_coords  <- comp_to_ilr(comp_matrix)\n    data_ilr$ilr1 <- ilr_coords[, 1]\n\n    results <- list()\n\n    ## Betweenâ€‘group effect during intervention ----------------------------------\n    md <- subset(data_ilr, period == \"intervention\")\n    mb <- try(lmer(ilr1 ~ group + (1 | id), data = md), silent = TRUE)\n    results$p_between <- if (!inherits(mb, \"try-error\")) anova(mb)[\"group\", \"Pr(>F)\"] else NA\n\n    ## Withinâ€‘group effects -------------------------------------------------------\n    mc <- try(lmer(ilr1 ~ period + (1 | id), data = subset(data_ilr, group == \"Control\")), silent = TRUE)\n    results$p_control <- if (!inherits(mc, \"try-error\")) anova(mc)[\"period\", \"Pr(>F)\"] else NA\n\n    mi <- try(lmer(ilr1 ~ period + (1 | id), data = subset(data_ilr, group == \"Abstinence\")), silent = TRUE)\n    results$p_intervention <- if (!inherits(mi, \"try-error\")) anova(mi)[\"period\", \"Pr(>F)\"] else NA\n\n    ## Interaction ----------------------------------------------------------------\n    mx <- try(lmer(ilr1 ~ group * period + (1 | id), data = data_ilr), silent = TRUE)\n    results$p_interaction <- if (!inherits(mx, \"try-error\")) anova(mx)[\"group:period\", \"Pr(>F)\"] else NA\n\n    ## Perâ€‘protocol contrast (original change score approach) ---------------------\n    mp_change <- try(lmer(ilr1 ~ intervention_active * playtime_reduction + (1 | id), data = data_ilr), silent = TRUE)\n    results$p_protocol_change <- if (!inherits(mp_change, \"try-error\")) anova(mp_change)[\"intervention_active:playtime_reduction\", \"Pr(>F)\"] else NA\n    \n    ## Perâ€‘protocol contrast (robust approach without change scores) --------------\n    # This model tests if the intervention effect on sedentary behavior (ilr1) varies \n    # as a function of actual playtime levels, controlling for baseline playtime.\n    # More robust than change scores as it directly models the relationship between\n    # current playtime and outcomes while adjusting for baseline differences.\n    mp_robust <- try(lmer(ilr1 ~ intervention_active * playtime + base_play_mean + (1 | id), data = data_ilr), silent = TRUE)\n    results$p_protocol_robust <- if (!inherits(mp_robust, \"try-error\")) anova(mp_robust)[\"intervention_active:playtime\", \"Pr(>F)\"] else NA\n\n    return(results)\n  }\n\n  # ------------------------------------------------------------------------------\n  # Simulation script ------------------------------------------------------------\n  # ------------------------------------------------------------------------------\n  sim %<>% set_script(function() {\n    set.seed(sample.int(1e7, 1))\n    \n    # Access simulation level variables correctly\n    data <- generate_data(\n      n_pg             = L$n_pg,\n      effect_min       = L$effect_min,\n      baseline_days    = L$baseline_days,\n      intervention_days= L$intervention_days,\n      s_between        = L$s_between,\n      s_within         = L$s_within\n    )\n    \n    # Run analysis and ensure proper error handling\n    result <- tryCatch({\n      run_analysis(data)\n    }, error = function(e) {\n      # Return NA values with proper names if analysis fails\n      list(\n        p_between = NA_real_, \n        p_control = NA_real_, \n        p_intervention = NA_real_,\n        p_interaction = NA_real_, \n        p_protocol_change = NA_real_,\n        p_protocol_robust = NA_real_\n      )\n    })\n    \n    # Ensure result is a proper list with all required elements\n    if (!is.list(result)) {\n      result <- list(\n        p_between = NA_real_, \n        p_control = NA_real_, \n        p_intervention = NA_real_,\n        p_interaction = NA_real_, \n        p_protocol_change = NA_real_,\n        p_protocol_robust = NA_real_\n      )\n    }\n    \n    # Ensure all required columns exist\n    required_names <- c(\"p_between\", \"p_control\", \"p_intervention\", \"p_interaction\", \"p_protocol_change\", \"p_protocol_robust\")\n    for (name in required_names) {\n      if (!(name %in% names(result))) {\n        result[[name]] <- NA_real_\n      }\n    }\n    \n    return(result)\n  })\n\n  # ------------------------------------------------------------------------------\n  # Config & run -----------------------------------------------------------------\n  # ------------------------------------------------------------------------------\n  sim %<>% set_config(\n    num_sim      = sims,\n    parallel     = TRUE,   # Enable parallel processing\n    n_cores      = cores,  # Use specified cores\n    packages     = c(\"lme4\", \"lmerTest\", \"compositions\", \"MASS\", \"dplyr\"),\n    progress_bar = TRUE\n  )\n\n  \n  # # Add a test run to debug issues\n  # message(\"Testing data generation and analysis functions...\")\n  # tryCatch({\n  #   test_data <- generate_data(\n  #     n_pg = 10,  # Small test\n  #     effect_min = 30,\n  #     baseline_days = 7,\n  #     intervention_days = 14,\n  #     s_between = 0.15,\n  #     s_within = 0.25\n  #   )\n  #   message(\"âœ“ Data generation successful\")\n  #   message(\"Test data dimensions: \", nrow(test_data), \" x \", ncol(test_data))\n    \n  #   test_results <- run_analysis(test_data)\n  #   message(\"âœ“ Analysis function successful\")\n  #   message(\"Test results: \", paste(names(test_results), test_results, sep=\"=\", collapse=\", \"))\n  # }, error = function(e) {\n  #   message(\"âŒ Test failed with error: \", e$message)\n  #   stop(\"Stopping due to test failure. Fix the issue before running full simulation.\")\n  # })\n\n  # message(\"Running simulations â€¦\")\n  \n  sim %<>% run()\n\n  # ------------------------------------------------------------------------------\n  # Summarise power --------------------------------------------------------------\n  # ------------------------------------------------------------------------------\n  results <- sim$results\n  \n  # Add debugging information\n  message(\"Debug: Checking simulation results...\")\n  message(\"Results object class: \", class(results))\n  message(\"Results is null: \", is.null(results))\n  if (!is.null(results)) {\n    message(\"Results dimensions: \", nrow(results), \" x \", ncol(results))\n    message(\"Results column names: \", paste(names(results), collapse = \", \"))\n  }\n  \n  # Add error handling for when all simulations fail\n  if (is.null(results) || (is.data.frame(results) && nrow(results) == 0)) {\n    stop(\"All simulations failed. Check your simulation parameters and functions.\")\n  }\n  \n  # Check if required columns exist before processing\n  required_cols <- c(\"p_between\", \"p_control\", \"p_intervention\", \"p_interaction\", \"p_protocol_change\", \"p_protocol_robust\")\n  missing_cols <- setdiff(required_cols, names(results))\n  if (length(missing_cols) > 0) {\n    stop(paste(\"Missing columns in results:\", paste(missing_cols, collapse = \", \")))\n  }\n  \n  for (col in required_cols) {\n    results[[col]] <- as.numeric(as.character(results[[col]]))\n  }\n\n  power_df <- aggregate(\n    cbind(\n      power_between        = results$p_between        < 0.05,\n      power_control        = results$p_control        < 0.05,\n      power_intervention   = results$p_intervention   < 0.05,\n      power_interaction    = results$p_interaction    < 0.05,\n      power_protocol_change= results$p_protocol_change< 0.05,\n      power_protocol_robust= results$p_protocol_robust< 0.05,\n      valid_between        = !is.na(results$p_between),\n      valid_control        = !is.na(results$p_control), \n      valid_intervention   = !is.na(results$p_intervention),\n      valid_interaction    = !is.na(results$p_interaction),\n      valid_protocol_change= !is.na(results$p_protocol_change),\n      valid_protocol_robust= !is.na(results$p_protocol_robust)\n    ),\n    by = list(\n      n_pg             = results$n_pg,\n      effect_min       = results$effect_min,\n      s_between        = results$s_between,\n      s_within         = results$s_within,\n      baseline_days    = results$baseline_days,\n      intervention_days= results$intervention_days\n    ),\n    FUN = mean, na.rm = TRUE\n  )\n\n  end_time <- Sys.time()\n  message(sprintf(\"Total elapsed time: %.2f mins\", as.numeric(difftime(end_time, start_time, units = \"mins\"))))\n\n  list(power_summary = power_df, sim_object = sim)\n}\n\n# --------------------------------------------------------------------------------\n# Example call -------------------------------------------------------------------\n# --------------------------------------------------------------------------------\nresult <- est_power_simengine(\n  n_pg               = 40,  # 40 participants per group\n  effect_min_values =  c(30, 60, 90, 120),          \n  s_between_values = seq(0.1, 0.3, by = 0.05),\n  s_within_values = seq(0.15, 0.35, by = 0.05),\n  baseline_days      = 7,\n  intervention_days  = 14,\n  sims               = sims_param, \n  cores              = cores_param     \n)\n\n# result <- est_power_simengine(\n#   n_pg               = c(50),  # Multiple sample sizes\n#   effect_min_values =  c(30, 60, 90, 120),          \n#   s_between_values = seq(0.1, 0.3, by = 0.05),\n#   s_within_values = seq(0.15, 0.35, by = 0.05),\n#   baseline_days      = 7,\n#   intervention_days  = 14,\n#   sims               = sims_param, \n#   cores              = cores_param     \n# )\n# print(result$power_summary)\n\n# Save results with descriptive name and timestamp\ntimestamp <- format(Sys.time(), \"%Y%m%d_%H%M%S\")\nfilename <- paste0(\"scripts/sim_comp_debug/power_sim_results_\", timestamp, \".RData\")\nsave(result, file = filename)\n\n# Print power summary\n# print(result$power_summary)\n\n# Print save location\nmessage(\"Results saved to: \", filename)\n\n# POWER SUMMARY ANALYSIS\nmessage(\"\\n\" , paste(rep(\"=\", 60), collapse=\"\"))\nmessage(\"POWER SUMMARY - TOP PERFORMING SETTINGS\")\nmessage(paste(rep(\"=\", 60), collapse=\"\"))\n\npower_data <- result$power_summary\n\n# Summary for power_interaction\nmessage(\"\\nðŸŽ¯ INTERACTION EFFECT POWER SUMMARY:\")\nmessage(\"-----------------------------------\")\n\n# Find maximum power for interaction\nmax_interaction_power <- max(power_data$power_interaction, na.rm = TRUE)\nbest_interaction <- power_data[which.max(power_data$power_interaction), ]\n\nmessage(sprintf(\"Maximum Interaction Power: %.3f\", max_interaction_power))\nmessage(\"Best settings:\")\nmessage(sprintf(\"  â€¢ Sample size per group (n_pg): %d\", best_interaction$n_pg))\nmessage(sprintf(\"  â€¢ Effect size (effect_min): %d minutes\", best_interaction$effect_min))\nmessage(sprintf(\"  â€¢ Between-subject SD (s_between): %.3f\", best_interaction$s_between))\nmessage(sprintf(\"  â€¢ Within-subject SD (s_within): %.3f\", best_interaction$s_within))\n\n# Show top 3 settings for interaction\nmessage(\"\\nTop 3 settings for interaction power:\")\ntop_interaction <- power_data[order(power_data$power_interaction, decreasing = TRUE)[1:min(3, nrow(power_data))], ]\nfor(i in 1:nrow(top_interaction)) {\n  row <- top_interaction[i, ]\n  message(sprintf(\"%d. Power=%.3f | n_pg=%d | effect=%d | s_between=%.3f | s_within=%.3f\", \n                  i, row$power_interaction, row$n_pg, row$effect_min, row$s_between, row$s_within))\n}\n\n# Summary for power_protocol (both approaches)\nmessage(\"\\nðŸŽ¯ PROTOCOL EFFECT POWER SUMMARY:\")\nmessage(\"--------------------------------\")\n\n# Change score approach\nmax_protocol_change_power <- max(power_data$power_protocol_change, na.rm = TRUE)\nbest_protocol_change <- power_data[which.max(power_data$power_protocol_change), ]\n\nmessage(\"\\nðŸ“Š CHANGE SCORE APPROACH:\")\nmessage(sprintf(\"Maximum Protocol Power (Change): %.3f\", max_protocol_change_power))\nmessage(\"Best settings:\")\nmessage(sprintf(\"  â€¢ Sample size per group (n_pg): %d\", best_protocol_change$n_pg))\nmessage(sprintf(\"  â€¢ Effect size (effect_min): %d minutes\", best_protocol_change$effect_min))\nmessage(sprintf(\"  â€¢ Between-subject SD (s_between): %.3f\", best_protocol_change$s_between))\nmessage(sprintf(\"  â€¢ Within-subject SD (s_within): %.3f\", best_protocol_change$s_within))\n\n# Robust approach\nmax_protocol_robust_power <- max(power_data$power_protocol_robust, na.rm = TRUE)\nbest_protocol_robust <- power_data[which.max(power_data$power_protocol_robust), ]\n\nmessage(\"\\nðŸ“Š ROBUST APPROACH (no change scores):\")\nmessage(sprintf(\"Maximum Protocol Power (Robust): %.3f\", max_protocol_robust_power))\nmessage(\"Best settings:\")\nmessage(sprintf(\"  â€¢ Sample size per group (n_pg): %d\", best_protocol_robust$n_pg))\nmessage(sprintf(\"  â€¢ Effect size (effect_min): %d minutes\", best_protocol_robust$effect_min))\nmessage(sprintf(\"  â€¢ Between-subject SD (s_between): %.3f\", best_protocol_robust$s_between))\nmessage(sprintf(\"  â€¢ Within-subject SD (s_within): %.3f\", best_protocol_robust$s_within))\n\n# Comparison\nmessage(\"\\nðŸ” PROTOCOL APPROACH COMPARISON:\")\nmessage(sprintf(\"Change Score Approach - Mean: %.3f, Max: %.3f\", \n                mean(power_data$power_protocol_change, na.rm = TRUE),\n                max_protocol_change_power))\nmessage(sprintf(\"Robust Approach - Mean: %.3f, Max: %.3f\", \n                mean(power_data$power_protocol_robust, na.rm = TRUE),\n                max_protocol_robust_power))\n                \npower_diff <- mean(power_data$power_protocol_robust, na.rm = TRUE) - mean(power_data$power_protocol_change, na.rm = TRUE)\nmessage(sprintf(\"Robust approach is %.3f points %s on average\", \n                abs(power_diff), \n                ifelse(power_diff > 0, \"higher\", \"lower\")))\n\n# Overall summary statistics\nmessage(\"\\nðŸ“Š OVERALL POWER STATISTICS:\")\nmessage(\"---------------------------\")\nmessage(sprintf(\"Interaction Power - Mean: %.3f, Range: %.3f - %.3f\", \n                mean(power_data$power_interaction, na.rm = TRUE),\n                min(power_data$power_interaction, na.rm = TRUE),\n                max(power_data$power_interaction, na.rm = TRUE)))\n                \nmessage(sprintf(\"Protocol Power (Change) - Mean: %.3f, Range: %.3f - %.3f\", \n                mean(power_data$power_protocol_change, na.rm = TRUE),\n                min(power_data$power_protocol_change, na.rm = TRUE),\n                max(power_data$power_protocol_change, na.rm = TRUE)))\n                \nmessage(sprintf(\"Protocol Power (Robust) - Mean: %.3f, Range: %.3f - %.3f\", \n                mean(power_data$power_protocol_robust, na.rm = TRUE),\n                min(power_data$power_protocol_robust, na.rm = TRUE),\n                max(power_data$power_protocol_robust, na.rm = TRUE)))\n\n# DATA QUALITY ANALYSIS\nmessage(\"\\n\" , paste(rep(\"=\", 60), collapse=\"\"))\nmessage(\"DATA QUALITY ANALYSIS - VALIDITY RATES\")\nmessage(paste(rep(\"=\", 60), collapse=\"\"))\n\n# Check validity rates for each contrast\nvalidity_threshold <- 0.95\ntotal_rows <- nrow(power_data)\n\n# Function to analyze validity for each contrast\nanalyze_validity <- function(valid_col, contrast_name) {\n  high_validity_count <- sum(power_data[[valid_col]] > validity_threshold, na.rm = TRUE)\n  perfect_validity_count <- sum(power_data[[valid_col]] == 1.0, na.rm = TRUE)\n  mean_validity <- mean(power_data[[valid_col]], na.rm = TRUE)\n  min_validity <- min(power_data[[valid_col]], na.rm = TRUE)\n  \n  message(sprintf(\"\\nðŸ” %s VALIDITY:\", toupper(contrast_name)))\n  message(sprintf(\"  â€¢ Rows with validity > %.2f: %d/%d (%.1f%%)\", \n                  validity_threshold, high_validity_count, total_rows, \n                  100 * high_validity_count / total_rows))\n  message(sprintf(\"  â€¢ Rows with perfect validity (1.0): %d/%d (%.1f%%)\", \n                  perfect_validity_count, total_rows, \n                  100 * perfect_validity_count / total_rows))\n  message(sprintf(\"  â€¢ Mean validity: %.3f\", mean_validity))\n  message(sprintf(\"  â€¢ Minimum validity: %.3f\", min_validity))\n  \n  # Identify problematic parameter combinations if any\n  if (high_validity_count < total_rows) {\n    low_validity_rows <- power_data[power_data[[valid_col]] <= validity_threshold, ]\n    message(sprintf(\"  âš ï¸  %d rows with validity â‰¤ %.2f:\", \n                    nrow(low_validity_rows), validity_threshold))\n    for(i in 1:min(3, nrow(low_validity_rows))) {  # Show up to 3 examples\n      row <- low_validity_rows[i, ]\n      message(sprintf(\"     Example %d: validity=%.3f | n_pg=%d | effect=%d | s_between=%.3f | s_within=%.3f\", \n                      i, row[[valid_col]], row$n_pg, row$effect_min, row$s_between, row$s_within))\n    }\n    if (nrow(low_validity_rows) > 3) {\n      message(sprintf(\"     ... and %d more problematic combinations\", nrow(low_validity_rows) - 3))\n    }\n  } else {\n    message(\"  âœ… All parameter combinations produced high-quality results!\")\n  }\n  \n  return(list(\n    high_validity_count = high_validity_count,\n    perfect_validity_count = perfect_validity_count,\n    mean_validity = mean_validity,\n    min_validity = min_validity\n  ))\n}\n\n# Analyze each contrast type\ncontrasts <- list(\n  \"valid_between\" = \"Between-Group\",\n  \"valid_control\" = \"Control Within-Group\", \n  \"valid_intervention\" = \"Intervention Within-Group\",\n  \"valid_interaction\" = \"Group Ã— Period Interaction\",\n  \"valid_protocol_change\" = \"Per-Protocol (Change Score)\",\n  \"valid_protocol_robust\" = \"Per-Protocol (Robust)\"\n)\n\nvalidity_summary <- list()\nfor(col in names(contrasts)) {\n  validity_summary[[col]] <- analyze_validity(col, contrasts[[col]])\n}\n\n# Overall validity summary\nmessage(\"\\nðŸ“‹ OVERALL VALIDITY SUMMARY:\")\nmessage(\"---------------------------\")\nall_high_validity <- sapply(validity_summary, function(x) x$high_validity_count)\nall_perfect_validity <- sapply(validity_summary, function(x) x$perfect_validity_count)\nall_mean_validity <- sapply(validity_summary, function(x) x$mean_validity)\n\nmessage(sprintf(\"Contrast with highest reliability: %s (%d/%d rows > %.2f)\", \n                contrasts[[which.max(all_high_validity)]], \n                max(all_high_validity), total_rows, validity_threshold))\nmessage(sprintf(\"Contrast with lowest reliability: %s (%d/%d rows > %.2f)\", \n                contrasts[[which.min(all_high_validity)]], \n                min(all_high_validity), total_rows, validity_threshold))\n\n# Check if all contrasts are highly reliable\nif(all(all_high_validity == total_rows)) {\n  message(\"âœ… EXCELLENT: All contrasts have high validity (>95%) across all parameter combinations!\")\n} else {\n  problematic_contrasts <- names(contrasts)[all_high_validity < total_rows]\n  message(sprintf(\"âš ï¸  WARNING: %d contrast(s) have some parameter combinations with low validity:\", \n                  length(problematic_contrasts)))\n  for(contrast in problematic_contrasts) {\n    message(sprintf(\"   â€¢ %s: %d/%d rows with validity â‰¤ %.2f\", \n                    contrasts[[contrast]], \n                    total_rows - all_high_validity[[contrast]], \n                    total_rows, validity_threshold))\n  }\n}\n\nmessage(\"\\n\" , paste(rep(\"=\", 60), collapse=\"\"))\n```\n:::\n\n\n### Simulate study\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Updated generate_data function with compliance\ngenerate_data <- function(n_pg, effect_min, baseline_days, intervention_days,\n                          s_between, s_within, seed = NULL) {\n\n  if (!is.null(seed)) set.seed(seed)\n\n  N   <- n_pg * 2\n  grp <- rep(0:1, each = n_pg)              # 0 = Control, 1 = Intervention\n\n  # Mean daily compositions: (sedentary, sleep, physical)\n  base_comp   <- c(600, 480, 360)\n  active_comp <- c(600 - effect_min, 480, 360 + effect_min)\n\n  # Personâ€‘level random effects in ILR space\n  b_ilr <- MASS::mvrnorm(N, mu = c(0, 0), Sigma = diag(s_between^2, 2))\n\n  # Person-specific playtime proportion of sedentary time (10-40%)\n  personal_play_prop <- sapply(1:N, function(i) {\n    p <- rbeta(1, 2, 5) * 0.3 + 0.1  # right-skew between 0.1-0.4\n    return(p)\n  })\n\n  # Person-specific compliance rates for intervention group (60-95%)\n  # Control group gets compliance = 1 (no intervention to comply with)\n  personal_compliance <- sapply(1:N, function(i) {\n    if (grp[i] == 0) {\n      return(1.0)  # Control group - no intervention\n    } else {\n      # Intervention group: Beta distribution shifted to 60-95% range\n      # Beta(2,2) gives symmetric distribution, shifted to [0.6, 0.95]\n      compliance <- rbeta(1, 2, 2) * 0.35 + 0.6\n      return(compliance)\n    }\n  })\n  \n  # Daily compliance variation using Kumaraswamy distribution\n  # This adds day-to-day variation in compliance within each person\n  daily_compliance_variation <- function(n_days, base_compliance) {\n    # Use Kumaraswamy distribution to add daily variation\n    # Parameters chosen to create realistic daily fluctuations around base compliance\n    daily_factors <- extraDistr::rkumar(n_days, a = 0.05, b = 0.1)\n    # Scale the factors to create variation around base compliance\n    # This creates realistic day-to-day variation in compliance behavior\n    pmax(0, pmin(1, base_compliance * (0.8 + 0.4 * daily_factors)))\n  }\n\n  # Containers\n  all_ids <- all_periods <- all_days <- NULL\n  all_ilr <- matrix(, 0, 2)\n  all_sedentary <- numeric()  # Store actual sedentary minutes\n\n  for (i in seq_len(N)) {\n    for (period in c(\"baseline\", \"intervention\")) {\n      ndays   <- if (period == \"baseline\") baseline_days else intervention_days\n      comp_mu <- if (period == \"baseline\" || grp[i] == 0) base_comp else active_comp\n\n      comp_ilr <- comp_to_ilr(matrix(rep(comp_mu, ndays), ncol = 3, byrow = TRUE))\n      comp_ilr <- sweep(comp_ilr, 2, b_ilr[i, ], \"+\")               # add person RE\n      day_ilr  <- comp_ilr + MASS::mvrnorm(ndays, mu = c(0, 0),\n                                            Sigma = diag(s_within^2, 2))\n\n      # Index bookkeeping\n      all_ids     <- c(all_ids, rep(i, ndays))\n      all_periods <- c(all_periods, rep(period, ndays))\n      all_days    <- c(all_days,\n                        if (period == \"baseline\") seq_len(baseline_days)\n                        else baseline_days + seq_len(intervention_days))\n      all_ilr     <- rbind(all_ilr, day_ilr)\n      \n      # Store sedentary minutes for this person-period (will be calculated after ILR transformation)\n      # We'll calculate playtime after we have the actual sedentary minutes\n    }\n  }\n\n  # Backâ€‘transform ILR â†’ minutes and calculate playtime based on actual sedentary behavior\n  mins <- ilr_to_minutes(all_ilr)\n  colnames(mins) <- c(\"sedentary\", \"sleep\", \"physical\")\n  \n  # Now generate playtime based on actual sedentary minutes\n  playmin <- numeric(length(all_ids))\n  \n  # Pre-generate daily compliance for each person during intervention period\n  daily_compliance <- list()\n  for (person_id in 1:N) {\n    if (grp[person_id] == 1) {  # Intervention group\n      daily_compliance[[person_id]] <- daily_compliance_variation(\n        intervention_days, \n        personal_compliance[person_id]\n      )\n    } else {\n      daily_compliance[[person_id]] <- rep(1.0, intervention_days)  # Control group\n    }\n  }\n  \n  # Track intervention day counter for each person\n  intervention_day_counter <- rep(0, N)\n  \n  for (i in seq_along(all_ids)) {\n    person_id <- all_ids[i]\n    period <- all_periods[i]\n    actual_sedentary <- mins[i, \"sedentary\"]\n    \n    # Base playtime as proportion of actual sedentary time\n    base_playtime <- personal_play_prop[person_id] * actual_sedentary\n    \n    # Add small amount of day-to-day noise (2% of base playtime)\n    daily_sd <- 0.02 * base_playtime\n    noisy_playtime <- rnorm(1, base_playtime, daily_sd)\n    \n    # Apply intervention effect for intervention group during intervention period\n    if (period == \"intervention\" && grp[person_id] == 1) {\n      # Increment intervention day counter for this person\n      intervention_day_counter[person_id] <- intervention_day_counter[person_id] + 1\n      \n      # Get daily compliance for this person and day\n      daily_compliance_rate <- daily_compliance[[person_id]][intervention_day_counter[person_id]]\n      \n      # Reduce playtime by effect_min * daily compliance rate\n      # Perfect compliance = full effect_min reduction\n      # Partial compliance = proportional reduction\n      actual_reduction <- effect_min * daily_compliance_rate\n      intervention_playtime <- pmax(0, noisy_playtime - actual_reduction)\n      playmin[i] <- intervention_playtime\n    } else {\n      # Control group or baseline period: just use the playtime based on actual sedentary\n      playmin[i] <- pmax(0, noisy_playtime)  # Ensure non-negative\n    }\n  }\n\n  # Create daily compliance values for the dataset\n  daily_compliance_values <- numeric(length(all_ids))\n  intervention_day_counter <- rep(0, N)\n  \n  for (i in seq_along(all_ids)) {\n    person_id <- all_ids[i]\n    period <- all_periods[i]\n    \n    if (period == \"intervention\" && grp[person_id] == 1) {\n      intervention_day_counter[person_id] <- intervention_day_counter[person_id] + 1\n      daily_compliance_values[i] <- daily_compliance[[person_id]][intervention_day_counter[person_id]]\n    } else {\n      daily_compliance_values[i] <- personal_compliance[person_id]\n    }\n  }\n  \n  # Assemble data frame\n  dat <- data.frame(\n    id        = factor(all_ids),\n    group     = factor(grp[all_ids], labels = c(\"Control\", \"Abstinence\")),\n    period    = factor(all_periods, levels = c(\"baseline\", \"intervention\")),\n    day       = all_days,\n    sedentary = mins[, 1],\n    sleep     = mins[, 2],\n    physical  = mins[, 3],\n    playtime  = playmin,\n    compliance = daily_compliance_values,  # Add daily compliance to dataset\n    base_compliance = personal_compliance[all_ids]  # Add base person-level compliance\n  )\n\n  dat <- dat %>%\n    group_by(id) %>%\n    mutate(\n      base_play_mean      = mean(playtime[period == \"baseline\"]),\n      playtime_reduction  = base_play_mean - playtime,\n      intervention_active = as.integer(group == \"Abstinence\" & period == \"intervention\"),\n      # Calculate actual compliance as proportion of intended reduction achieved\n      intended_reduction  = ifelse(group == \"Abstinence\" & period == \"intervention\", effect_min, 0),\n      actual_compliance   = ifelse(intended_reduction > 0, \n                                 pmin(1, playtime_reduction / intended_reduction), \n                                 compliance)\n    ) %>%\n    ungroup()\n\n  return(dat)\n}\n# Generate sample data with moderate effect size\nset.seed(123)\nsample_data <- generate_data(\n  n_pg = 40,              # 40 participants per group\n  effect_min = 60,         \n  baseline_days = 7,      # 7 days baseline\n  intervention_days = 14, # 14 days intervention\n  s_between = 0.3,        # moderate between-subject variability\n  s_within = 0.2,         # moderate within-subject variability\n  seed = 123\n)\n\n# Check the structure of the generated data\nglimpse(sample_data)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRows: 1,680\nColumns: 15\n$ id                  <fct> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,â€¦\n$ group               <fct> Control, Control, Control, Control, Control, Contrâ€¦\n$ period              <fct> baseline, baseline, baseline, baseline, baseline, â€¦\n$ day                 <dbl> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15,â€¦\n$ sedentary           <dbl> 487.2, 594.3, 685.2, 588.8, 501.1, 552.4, 485.0, 7â€¦\n$ sleep               <dbl> 569.8, 471.5, 384.0, 575.3, 494.8, 574.9, 521.3, 3â€¦\n$ physical            <dbl> 383.0, 374.2, 370.8, 275.9, 444.0, 312.7, 433.7, 2â€¦\n$ playtime            <dbl> 130.43873, 158.18295, 181.87780, 155.21545, 128.59â€¦\n$ compliance          <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,â€¦\n$ base_compliance     <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,â€¦\n$ base_play_mean      <dbl> 147.30262, 147.30262, 147.30262, 147.30262, 147.30â€¦\n$ playtime_reduction  <dbl> 16.8638909, -10.8803287, -34.5751773, -7.9128323, â€¦\n$ intervention_active <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,â€¦\n$ intended_reduction  <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,â€¦\n$ actual_compliance   <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,â€¦\n```\n\n\n:::\n\n```{.r .cell-code}\n# Show compliance distribution in intervention group\ncompliance_summary <- sample_data %>%\n  filter(group == \"Abstinence\", period == \"intervention\") %>%\n  distinct(id, compliance) %>%\n  summarise(\n    n = n(),\n    mean_compliance = mean(compliance),\n    sd_compliance = sd(compliance),\n    min_compliance = min(compliance),\n    max_compliance = max(compliance)\n  )\n\nprint(\"Compliance Summary for Intervention Group:\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"Compliance Summary for Intervention Group:\"\n```\n\n\n:::\n\n```{.r .cell-code}\nprint(compliance_summary)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 Ã— 5\n      n mean_compliance sd_compliance min_compliance max_compliance\n  <int>           <dbl>         <dbl>          <dbl>          <dbl>\n1   475           0.828         0.129          0.507              1\n```\n\n\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Calculate daily means for compositions across all participants by group and period\ndaily_composition_means <- sample_data %>%\n  group_by(group, period, day) %>%\n  summarise(\n    sedentary_mean = mean(sedentary),\n    sleep_mean = mean(sleep),\n    physical_mean = mean(physical),\n    .groups = \"drop\"\n  ) %>%\n  pivot_longer(\n    cols = c(sedentary_mean, sleep_mean, physical_mean),\n    names_to = \"component\",\n    values_to = \"minutes\"\n  ) %>%\n  mutate(\n    component = factor(\n      gsub(\"_mean\", \"\", component),\n      levels = c(\"sedentary\", \"sleep\", \"physical\"),\n      labels = c(\"Sedentary\", \"Sleep\", \"Physical Activity\")\n    )\n  )\n\n# Longitudinal compositional barplot\ncomposition_longitudinal <- ggplot(daily_composition_means, \n                                  aes(x = day, y = minutes, fill = component)) +\n  geom_col(position = \"stack\", alpha = 0.8) +\n  geom_vline(xintercept = 7.5, linetype = \"dashed\", color = \"black\", size = 1) +\n  annotate(\"text\", x = 4, y = 1300, label = \"Baseline\", hjust = 0.5, size = 4, fontface = \"bold\") +\n  annotate(\"text\", x = 14, y = 1300, label = \"Intervention\", hjust = 0.5, size = 4, fontface = \"bold\") +\n  facet_wrap(~ group, \n             labeller = labeller(\n               group = c(\"Control\" = \"Control Group\", \"Abstinence\" = \"Abstinence Group\")\n             )) +\n  labs(\n    title = \"Daily Mean Compositions Over Time\",\n    subtitle = \"24-hour time use patterns by study day (stacked bars)\",\n    x = \"Study Day\",\n    y = \"Minutes per Day\",\n    fill = \"Component\"\n  ) +\n  theme_minimal() +\n  theme(\n    legend.position = \"bottom\",\n    strip.text = element_text(size = 12, face = \"bold\"),\n    panel.grid.minor.x = element_blank(),\n    panel.grid.major.x = element_blank()\n  ) +\n  scale_fill_viridis_d(option = \"plasma\", begin = 0.2, end = 0.8) +\n  scale_y_continuous(breaks = seq(0, 1400, 200)) +\n  scale_x_continuous(breaks = seq(0, 25, 5))\n\nprint(composition_longitudinal)\n```\n\n::: {.cell-output-display}\n![](sim_comp_report_files/figure-html/longitudinal_plots-1.png){width=672}\n:::\n\n```{.r .cell-code}\n# Calculate daily means for playtime by group and period\ndaily_playtime_means <- sample_data %>%\n  group_by(group, period, day) %>%\n  summarise(\n    playtime_mean = mean(playtime),\n    playtime_se = sd(playtime) / sqrt(n()),\n    .groups = \"drop\"\n  )\n\n# Longitudinal plot for daily mean playtime - now faceted by group like the composition plot\nplaytime_longitudinal <- ggplot(daily_playtime_means, \n                               aes(x = day, y = playtime_mean, color = group)) +\n  geom_line(size = 1.2, alpha = 0.8) +\n  geom_point(size = 2, alpha = 0.7) +\n  geom_ribbon(aes(ymin = playtime_mean - playtime_se, \n                  ymax = playtime_mean + playtime_se, \n                  fill = group), \n              alpha = 0.2, color = NA) +\n  geom_vline(xintercept = 7.5, linetype = \"dashed\", color = \"black\", size = 1) +\n  annotate(\"text\", x = 4, y = 175, label = \"Baseline\", hjust = 0.5, size = 4, fontface = \"bold\") +\n  annotate(\"text\", x = 14, y = 175, label = \"Intervention\", hjust = 0.5, size = 4, fontface = \"bold\") +\n  facet_wrap(~ group, \n             labeller = labeller(\n               group = c(\"Control\" = \"Control Group\", \"Abstinence\" = \"Abstinence Group\")\n             )) +\n  labs(\n    title = \"Daily Mean Playtime Over Time\",\n    subtitle = \"Gaming/screen time trends by study day with standard error bands\",\n    x = \"Study Day\",\n    y = \"Mean Playtime (minutes per day)\",\n    color = \"Group\",\n    fill = \"Group\"\n  ) +\n  theme_minimal() +\n  theme(\n    legend.position = \"bottom\",\n    strip.text = element_text(size = 12, face = \"bold\"),\n    panel.grid.minor.x = element_blank()\n  ) +\n  scale_color_manual(values = c(\"Control\" = \"#2E8B57\", \"Abstinence\" = \"#FF6347\")) +\n  scale_fill_manual(values = c(\"Control\" = \"#2E8B57\", \"Abstinence\" = \"#FF6347\")) +\n  scale_y_continuous(breaks = seq(0, 200, 25)) +\n  scale_x_continuous(breaks = seq(0, 25, 5))\n\nprint(playtime_longitudinal)\n```\n\n::: {.cell-output-display}\n![](sim_comp_report_files/figure-html/longitudinal_plots-2.png){width=672}\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Calculate daily averages for compositions by group and period\ncomposition_summary <- sample_data %>%\n  group_by(group, period, id) %>%\n  summarise(\n    sedentary = mean(sedentary),\n    sleep = mean(sleep), \n    physical = mean(physical),\n    .groups = \"drop\"\n  ) %>%\n  pivot_longer(\n    cols = c(sedentary, sleep, physical),\n    names_to = \"component\",\n    values_to = \"minutes\"\n  ) %>%\n  mutate(\n    component = factor(component, \n                      levels = c(\"sedentary\", \"sleep\", \"physical\"),\n                      labels = c(\"Sedentary\", \"Sleep\", \"Physical Activity\"))\n  )\n\n# Create 2x2 faceted plot for compositions\ncomposition_plot <- ggplot(composition_summary, \n                          aes(x = component, y = minutes, fill = component)) +\n  geom_boxplot(alpha = 0.7) +\n  geom_point(position = position_jitter(width = 0.2), alpha = 0.3, size = 0.8) +\n  facet_grid(period ~ group, \n             labeller = labeller(\n               period = c(\"baseline\" = \"Baseline\", \"intervention\" = \"Intervention\"),\n               group = c(\"Control\" = \"Control Group\", \"Abstinence\" = \"Abstinence Group\")\n             )) +\n  labs(\n    title = \"Daily Average Compositions by Group and Period\",\n    subtitle = \"24-hour time use patterns (minutes per day)\",\n    x = \"Activity Component\",\n    y = \"Minutes per Day\",\n    fill = \"Component\"\n  ) +\n  theme_minimal() +\n  theme(\n    legend.position = \"bottom\",\n    strip.text = element_text(size = 12, face = \"bold\"),\n    axis.text.x = element_text(angle = 45, hjust = 1)\n  ) +\n  scale_fill_viridis_d(option = \"plasma\", begin = 0.2, end = 0.8) +\n  scale_y_continuous(breaks = seq(0, 800, 100))\n\nprint(composition_plot)\n```\n\n::: {.cell-output-display}\n![](sim_comp_report_files/figure-html/composition_plots-1.png){width=672}\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Calculate playtime averages by group and period  \nplaytime_summary <- sample_data %>%\n  group_by(group, period, id) %>%\n  summarise(\n    avg_playtime = mean(playtime),\n    .groups = \"drop\"\n  )\n\n# Create 2x2 faceted plot for playtime\nplaytime_plot <- ggplot(playtime_summary, \n                       aes(x = group, y = avg_playtime, fill = group)) +\n  geom_boxplot(alpha = 0.7, width = 0.6) +\n  geom_point(position = position_jitter(width = 0.2), alpha = 0.5, size = 1.2) +\n  stat_summary(fun = mean, geom = \"point\", shape = 23, size = 3, \n               fill = \"white\", color = \"black\") +\n  facet_wrap(~ period, \n             labeller = labeller(\n               period = c(\"baseline\" = \"Baseline Period\", \n                         \"intervention\" = \"Intervention Period\")\n             )) +\n  labs(\n    title = \"Average Daily Playtime by Group and Period\",\n    subtitle = \"Gaming/screen time reduction intervention effect\",\n    x = \"Study Group\",\n    y = \"Average Playtime (minutes per day)\",\n    fill = \"Group\"\n  ) +\n  theme_minimal() +\n  theme(\n    legend.position = \"bottom\",\n    strip.text = element_text(size = 12, face = \"bold\"),\n    panel.grid.minor = element_blank()\n  ) +\n  scale_fill_manual(values = c(\"Control\" = \"#2E8B57\", \"Intervention\" = \"#FF6347\")) +\n  scale_y_continuous(breaks = seq(0, 200, 25))\n\nprint(playtime_plot)\n```\n\n::: {.cell-output-display}\n![](sim_comp_report_files/figure-html/playtime_plots-1.png){width=672}\n:::\n\n```{.r .cell-code}\n# Summary statistics table\nplaytime_stats <- playtime_summary %>%\n  group_by(group, period) %>%\n  summarise(\n    n = n(),\n    mean_playtime = round(mean(avg_playtime), 1),\n    sd_playtime = round(sd(avg_playtime), 1),\n    median_playtime = round(median(avg_playtime), 1),\n    q25 = round(quantile(avg_playtime, 0.25), 1),\n    q75 = round(quantile(avg_playtime, 0.75), 1),\n    .groups = \"drop\"\n  )\n\n# Display summary table\nknitr::kable(\n  playtime_stats,\n  caption = \"Summary Statistics for Daily Playtime by Group and Period\",\n  col.names = c(\"Group\", \"Period\", \"N\", \"Mean\", \"SD\", \"Median\", \"Q25\", \"Q75\")\n)\n```\n\n::: {.cell-output-display}\n\n\nTable: Summary Statistics for Daily Playtime by Group and Period\n\n|Group      |Period       |  N|  Mean|   SD| Median|  Q25|   Q75|\n|:----------|:------------|--:|-----:|----:|------:|----:|-----:|\n|Control    |baseline     | 40| 110.2| 31.1|  110.7| 87.6| 127.3|\n|Control    |intervention | 40| 110.0| 29.8|  107.3| 90.2| 127.8|\n|Abstinence |baseline     | 40| 107.4| 36.7|  100.0| 78.7| 129.3|\n|Abstinence |intervention | 40|  36.5| 31.9|   24.8| 11.3|  56.3|\n\n\n:::\n:::\n\n\n## Power analysis \n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Load the results from the SimEngine power analysis\nload(\"scripts/sim_comp_debug/power_sim_results_20250714_160955.RData\")\n\n# Get the power summary data frame\npower_results_multi <- result$power_summary\n\n# Filter rows where all columns starting with \"valid\" have values >= 0.95\nvalid_cols <- grep(\"^valid\", names(power_results_multi), value = TRUE)\npower_results_multi <- power_results_multi %>%\n  filter(if_all(all_of(valid_cols), ~ .x >= 0.95))\n\n# Add a factor for effect size for better plotting\npower_results_multi$effect_min_factor <- factor(\n  power_results_multi$effect_min,\n  levels = unique(power_results_multi$effect_min),\n  labels = paste0(unique(power_results_multi$effect_min), \" min\")\n)\n\n# Convert from wide to long format to plot all power metrics\npower_results_long <- power_results_multi %>%\n  pivot_longer(\n    cols = c(\"power_interaction\", \"power_protocol_change\", \"power_protocol_robust\"),\n    names_to = \"power_type\",\n    values_to = \"power\"\n  ) %>%\n  mutate(\n    power_type = factor(\n      power_type,\n      levels = c(\"power_interaction\", \"power_protocol_change\", \"power_protocol_robust\"),\n      labels = c(\"Intention to Treat Effect\", \"Per-Protocol (Change)\", \"Per-Protocol (Robust)\")\n    )\n  )\n\n# Create a faceted plot showing all power curves\nggplot(power_results_long, \n       aes(x = s_between, y = power, \n           color = effect_min_factor,\n           alpha = factor(s_within),\n           group = interaction(effect_min_factor, s_within))) +\n  geom_line(size = 1.2) +\n  geom_point(size = 1.5) +\n  facet_wrap(~ power_type, ncol = 2) +\n  labs(title = \"Power Curves by Effect Size and Variability Parameters\",\n       subtitle = \"Each line represents a unique Effect Size Ã— Within-subject SD combination\",\n       x = \"Between-subject SD\", \n       y = \"Statistical Power\",\n       color = \"Effect Size\",\n       alpha = \"Within-subject SD\") +\n  theme_minimal() +\n  geom_hline(yintercept = 0.8, linetype = \"dashed\", color = \"red\", alpha = 0.7) +\n  scale_y_continuous(limits = c(0, 1), breaks = seq(0, 1, 0.2)) +\n  scale_alpha_discrete(range = c(0.4, 1.0)) +\n  theme(legend.position = \"bottom\") +\n  guides(\n    color = guide_legend(title = \"Effect Size\", nrow = 1, order = 1),\n    alpha = guide_legend(title = \"Within-subject SD\", nrow = 1, order = 2)\n  )\n```\n\n::: {.cell-output-display}\n![](sim_comp_report_files/figure-html/power_analysis_extended-1.png){width=672}\n:::\n\n```{.r .cell-code}\n# Create a condensed comparison plot\nggplot(power_results_long, \n       aes(x = effect_min, y = power, \n           color = power_type,\n           linetype = power_type)) +\n  geom_smooth(se = FALSE) +\n  labs(title = \"Comparison of Power by Effect Type\",\n       x = \"Effect Size (minutes)\", \n       y = \"Statistical Power\",\n       color = \"Effect Type\",\n       linetype = \"Effect Type\") +\n  theme_minimal() +\n  geom_hline(yintercept = 0.8, linetype = \"dashed\", color = \"black\") +\n  scale_y_continuous(limits = c(0, 1), breaks = seq(0, 1, 0.2))\n```\n\n::: {.cell-output-display}\n![](sim_comp_report_files/figure-html/power_analysis_extended-2.png){width=672}\n:::\n\n```{.r .cell-code}\npower_protocol_change_heatmap <- power_results_multi %>%\n  ggplot(aes(x = s_between, y = s_within, fill = power_protocol_change)) +\n  geom_tile() +\n  facet_wrap(~ effect_min_factor) +\n  scale_fill_viridis_c(limits = c(0, 1), breaks = seq(0, 1, 0.2)) +\n  labs(title = \"Power Heatmap for Per-Protocol Effect (Change Score)\",\n       x = \"Between-subject SD\",\n       y = \"Within-subject SD\",\n       fill = \"Power\") +\n  theme_minimal() +\n  theme(legend.position = \"right\")\n\n# Display the heatmap\npower_protocol_change_heatmap\n```\n\n::: {.cell-output-display}\n![](sim_comp_report_files/figure-html/power_analysis_extended-3.png){width=672}\n:::\n\n```{.r .cell-code}\npower_protocol_robust_heatmap <- power_results_multi %>%\n  ggplot(aes(x = s_between, y = s_within, fill = power_protocol_robust)) +\n  geom_tile() +\n  facet_wrap(~ effect_min_factor) +\n  scale_fill_viridis_c(limits = c(0, 1), breaks = seq(0, 1, 0.2)) +\n  labs(title = \"Power Heatmap for Per-Protocol Effect (Robust)\",\n       x = \"Between-subject SD\",\n       y = \"Within-subject SD\",\n       fill = \"Power\") +\n  theme_minimal() +\n  theme(legend.position = \"right\")\n\n# Display the heatmap\npower_protocol_robust_heatmap\n```\n\n::: {.cell-output-display}\n![](sim_comp_report_files/figure-html/power_analysis_extended-4.png){width=672}\n:::\n\n```{.r .cell-code}\n# Create a heatmap visualization showing power for different parameter combinations\n# Focus on the interaction effect as it's typically the primary outcome\npower_interaction_heatmap <- power_results_multi %>%\n  ggplot(aes(x = s_between, y = s_within, fill = power_interaction)) +\n  geom_tile() +\n  facet_wrap(~ effect_min_factor) +\n  scale_fill_viridis_c(limits = c(0, 1), breaks = seq(0, 1, 0.2)) +\n  labs(title = \"Power Heatmap for Intention to Treat Effect\",\n       x = \"Between-subject SD\",\n       y = \"Within-subject SD\",\n       fill = \"Power\") +\n  theme_minimal() +\n  theme(legend.position = \"right\")\n\n# Display the heatmap\npower_interaction_heatmap\n```\n\n::: {.cell-output-display}\n![](sim_comp_report_files/figure-html/power_analysis_extended-5.png){width=672}\n:::\n\n```{.r .cell-code}\n# Create a table summarizing the minimum effect size needed for 80% power\n# under different variability conditions\npower_threshold <- 0.8\npower_summary_table <- power_results_multi %>%\n  group_by(s_between, s_within) %>%\n  summarize(\n    min_effect_for_interaction = min(effect_min[power_interaction >= power_threshold], na.rm = TRUE),\n    min_effect_for_protocol_change = min(effect_min[power_protocol_change >= power_threshold], na.rm = TRUE),\n    min_effect_for_protocol_robust = min(effect_min[power_protocol_robust >= power_threshold], na.rm = TRUE),\n    .groups = \"drop\"\n  )\n\n# Display the summary table\nlibrary(DT)\n\ndatatable(\n  power_summary_table,\n  colnames = c(\n    \"Between-subject SD\", \"Within-subject SD\", \n    \"Min Effect for 80% Int to Treat Power (min)\", \n    \"Min Effect for 80% Protocol Power (Change) (min)\",\n    \"Min Effect for 80% Protocol Power (Robust) (min)\"\n  ),\n  caption = \"Minimum effect size needed for 80% power under different variability conditions\",\n  options = list(\n    pageLength = 10,\n    autoWidth = TRUE,\n    searching = TRUE,\n    ordering = TRUE\n  )\n)\n```\n\n::: {.cell-output-display}\n\n```{=html}\n<div class=\"datatables html-widget html-fill-item\" id=\"htmlwidget-0e9588d33f096f207cca\" style=\"width:100%;height:auto;\"></div>\n<script type=\"application/json\" data-for=\"htmlwidget-0e9588d33f096f207cca\">{\"x\":{\"filter\":\"none\",\"vertical\":false,\"caption\":\"<caption>Minimum effect size needed for 80% power under different variability conditions<\\/caption>\",\"data\":[[\"1\",\"2\",\"3\",\"4\",\"5\",\"6\"],[0.1,0.1,0.15,0.2,0.25,0.3],[0.1,0.15,0.1,0.1,0.1,0.1],[30,60,30,30,30,30],[30,60,30,30,30,30],[null,null,null,null,null,120]],\"container\":\"<table class=\\\"display\\\">\\n  <thead>\\n    <tr>\\n      <th> <\\/th>\\n      <th>Between-subject SD<\\/th>\\n      <th>Within-subject SD<\\/th>\\n      <th>Min Effect for 80% Int to Treat Power (min)<\\/th>\\n      <th>Min Effect for 80% Protocol Power (Change) (min)<\\/th>\\n      <th>Min Effect for 80% Protocol Power (Robust) (min)<\\/th>\\n    <\\/tr>\\n  <\\/thead>\\n<\\/table>\",\"options\":{\"pageLength\":10,\"autoWidth\":true,\"searching\":true,\"ordering\":true,\"columnDefs\":[{\"className\":\"dt-right\",\"targets\":[1,2,3,4,5]},{\"orderable\":false,\"targets\":0},{\"name\":\" \",\"targets\":0},{\"name\":\"s_between\",\"targets\":1},{\"name\":\"s_within\",\"targets\":2},{\"name\":\"min_effect_for_interaction\",\"targets\":3},{\"name\":\"min_effect_for_protocol_change\",\"targets\":4},{\"name\":\"min_effect_for_protocol_robust\",\"targets\":5}],\"order\":[],\"orderClasses\":false}},\"evals\":[],\"jsHooks\":[]}</script>\n```\n\n:::\n:::\n\n\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<link href=\"../site_libs/htmltools-fill-0.5.8.1/fill.css\" rel=\"stylesheet\" />\n<script src=\"../site_libs/htmlwidgets-1.6.4/htmlwidgets.js\"></script>\n<link href=\"../site_libs/datatables-css-0.0.0/datatables-crosstalk.css\" rel=\"stylesheet\" />\n<script src=\"../site_libs/datatables-binding-0.33/datatables.js\"></script>\n<script src=\"../site_libs/jquery-3.6.0/jquery-3.6.0.min.js\"></script>\n<link href=\"../site_libs/dt-core-1.13.6/css/jquery.dataTables.min.css\" rel=\"stylesheet\" />\n<link href=\"../site_libs/dt-core-1.13.6/css/jquery.dataTables.extra.css\" rel=\"stylesheet\" />\n<script src=\"../site_libs/dt-core-1.13.6/js/jquery.dataTables.min.js\"></script>\n<link href=\"../site_libs/crosstalk-1.2.1/css/crosstalk.min.css\" rel=\"stylesheet\" />\n<script src=\"../site_libs/crosstalk-1.2.1/js/crosstalk.min.js\"></script>\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}