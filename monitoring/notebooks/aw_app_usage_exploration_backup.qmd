---
title: "App Usage Data Exploration by Study Day"
author: "Gaming Reduction Study Analysis"
format: 
  html:
    page-layout: full
    code-fold: true
    code-summary: "Show code"
    toc: true
    toc-depth: 3
    toc-location: left
    grid:
      sidebar-width: 250px
      body-width: 1400px
      margin-width: 100px
    css: |
      .quarto-container {
        max-width: none !important;
      }
      .content {
        max-width: 1400px !important;
        margin: 0 auto;
      }
      table {
        font-size: 0.85em;
      }
      .cell-output-display {
        overflow-x: auto;
      }
editor: visual
---

## Overview

This notebook explores app usage data from the gaming reduction study, focusing on data availability across study days (1-30) for each participant. The analysis uses enrollment dates to calculate study days and assess whether donated data exists for each day.

### Data Refresh

The notebook can automatically pull fresh data from Supabase before analysis: - **To refresh data**: Set `REFRESH_DATA <- TRUE` in the Data Loading section (default) - **To use existing files**: Set `REFRESH_DATA <- FALSE` to skip the refresh - The Python pipeline (`join_diary_activitywatch.py`) handles: - Pulling ActivityWatch data from Supabase - Fetching diary responses via Qualtrics API - Parsing and joining the data - Generating the three required CSV files

```{r setup, include=FALSE}
library(tidyverse)
library(lubridate)
library(knitr)
library(DT)

# Set options
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
```

## Data Loading

```{r load-data}
# Set to FALSE to skip data refresh and use existing files
REFRESH_DATA <- FALSE

if (REFRESH_DATA) {
  # First, pull fresh data from Supabase using the Python pipeline
  # This runs the full pipeline: pull ActivityWatch & diary data, parse it, and join with enrichment
  cat("=== REFRESHING DATA FROM SUPABASE ===\n")
  cat("Running Python pipeline to pull fresh data...\n")
  
  tryCatch({
    pipeline_result <- system2(
      "python3",
      args = c("/home/tamas.foldes/Development/Projects/gaming-reduction-backend/monitoring/join_diary_activitywatch.py", "--output-dir", "../../.tmp"),
      stdout = TRUE,
      stderr = TRUE,
      wait = TRUE
    )
    
    # Check exit status
    exit_status <- attr(pipeline_result, "status")
    if (!is.null(exit_status) && exit_status != 0) {
      cat("⚠️ Warning: Pipeline exited with non-zero status:", exit_status, "\n")
      cat("Error output:\n")
      cat(paste(pipeline_result, collapse = "\n"), "\n")
      cat("\nAttempting to use existing files if available...\n")
    } else {
      # Show last few lines of successful output
      if (length(pipeline_result) > 0) {
        tail_output <- tail(pipeline_result, 5)
        cat("✅ Pipeline completed successfully!\n")
        cat("Last 5 lines of output:\n")
        cat(paste(tail_output, collapse = "\n"), "\n")
      }
    }
  }, error = function(e) {
    cat("❌ Error running pipeline:", e$message, "\n")
    cat("Attempting to use existing files if available...\n")
  })
  
  cat("\n")
} else {
  cat("=== USING EXISTING DATA FILES ===\n")
  cat("Skipping data refresh (REFRESH_DATA = FALSE)\n\n")
}

# Check if files exist and show their timestamps
files_to_check <- c(
  "../../.tmp/joined_app_usage.csv",
  "../../.tmp/participant_report.csv", 
  "../../.tmp/exit_responses_lifetime.csv"
)

for (file in files_to_check) {
  if (file.exists(file)) {
    file_info <- file.info(file)
    cat(sprintf("✓ %s exists (modified: %s, size: %s bytes)\n", 
                basename(file), 
                file_info$mtime, 
                format(file_info$size, big.mark = ",")))
  } else {
    cat(sprintf("✗ %s not found\n", basename(file)))
  }
}
cat("\n")

# Load the joined app usage data
app_usage <- read_csv("../../.tmp/joined_app_usage.csv")

# Load participant report with enrollment dates
participant_report <- read_csv("../../.tmp/participant_report.csv")

# Load exit survey responses to identify participants who completed the study
exit_responses <- read_csv("../../.tmp/exit_responses_lifetime.csv")

# Display data structure
cat("App Usage Data Structure:\n")
glimpse(app_usage)

cat("\nParticipant Report Structure:\n")
glimpse(participant_report)

# Display interactive table for participant report
datatable(participant_report %>% 
            select(RANDOM_ID, Condition, Platforms, phoneType, EnrollmentDate, 
                   data_type, num_submission_ids, num_unique_donations, 
                   total_donation_records, uniqueness_ratio, num_study_days_with_data),
          caption = "Participant Report Structure - Interactive Table",
          options = list(
            pageLength = 10,
            scrollX = TRUE,
            columnDefs = list(
              list(width = '100px', targets = 0),
              list(width = '80px', targets = c(1, 3, 5))
            )
          ),
          filter = 'top')

# Display simple table with RANDOM_ID and submission IDs
datatable(participant_report %>% 
            select(RANDOM_ID, submission_ids_list),
          caption = "Participant Submission IDs",
          colnames = c("Participant ID", "Submission IDs"),
          options = list(
            pageLength = 15,
            scrollX = TRUE,
            columnDefs = list(
              list(width = '150px', targets = 0),
              list(width = '600px', targets = 1)
            )
          ),
          filter = 'top')

cat("\nExit Survey Data Structure:\n")
glimpse(exit_responses)
```

## Data Preparation

```{r data-prep}
# Convert datetime columns and ensure consistent RANDOM_ID data types
app_usage <- app_usage %>%
  mutate(
    session_datetime = ymd_hms(session_datetime),
    created_at_datetime = ymd_hms(created_at_datetime),
    session_date = as.Date(session_datetime),
    RANDOM_ID = as.character(RANDOM_ID)  # Ensure consistent data type
  )

# Process exit survey data to identify participants who completed the study
exit_completed_participants <- exit_responses %>%
  filter(!is.na(RANDOM_ID) & RANDOM_ID != "") %>%
  mutate(RANDOM_ID = as.character(RANDOM_ID)) %>%
  distinct(RANDOM_ID) %>%
  mutate(completed_exit_survey = TRUE)

# Parse enrollment dates from participant report and add completion status
participant_report <- participant_report %>%
  mutate(
    RANDOM_ID = as.character(RANDOM_ID),  # Ensure consistent data type
    EnrollmentDate = ymd(EnrollmentDate),
    # Parse study_days_with_data from string representation of list
    study_days_with_data = str_remove_all(study_days_with_data, "[\\[\\]]") %>%
      str_split(", ") %>%
      map(~ as.numeric(.x[.x != ""]))
  ) %>%
  # Join with exit survey completion data
  left_join(exit_completed_participants, by = "RANDOM_ID") %>%
  mutate(
    completed_exit_survey = ifelse(is.na(completed_exit_survey), FALSE, completed_exit_survey),
    # Calculate study completion status
    report_generation_date = Sys.Date(),
    study_end_date = EnrollmentDate + days(27), # 28 days total (0-27)
    days_since_enrollment = as.numeric(report_generation_date - EnrollmentDate),
    study_should_be_complete = days_since_enrollment >= 28,
    study_completion_status = case_when(
      !study_should_be_complete ~ "🟡 In Progress",
      study_should_be_complete & num_study_days_with_data >= 20 ~ "✅ Complete",
      days_since_enrollment > 30 & num_study_days_with_data < 20 ~ "🔴 Incomplete",
      study_should_be_complete & completed_exit_survey & num_study_days_with_data < 20 ~ "🔴 Incomplete",
      study_should_be_complete & !completed_exit_survey & num_study_days_with_data < 20 ~ "🟡 In Progress", 
      TRUE ~ "❓ Unknown"
    ),
    # Status for sorting and filtering
    status_category = case_when(
      !study_should_be_complete ~ "in_progress",
      study_should_be_complete & num_study_days_with_data >= 20 ~ "complete",
      days_since_enrollment > 30 & num_study_days_with_data < 20 ~ "incomplete",
      study_should_be_complete & completed_exit_survey & num_study_days_with_data < 20 ~ "incomplete",
      study_should_be_complete & !completed_exit_survey & num_study_days_with_data < 20 ~ "in_progress",
      TRUE ~ "unknown"
    )
  )

# Process enrollment dates and calculate study days
app_usage_with_enrollment <- app_usage %>%
  mutate(
    EnrollmentDate = ymd(EnrollmentDate),
    # Calculate study day based on enrollment date  
    study_day = as.numeric(session_date - EnrollmentDate) + 1
  ) %>%
  filter(!is.na(EnrollmentDate)) %>%
  filter(study_day >= 1 & study_day <= 30)  # Focus on study period

cat("Data after processing:\n")
cat("Participants with enrollment dates:", n_distinct(app_usage_with_enrollment$RANDOM_ID), "\n")
cat("Date range:", range(app_usage_with_enrollment$session_date, na.rm = TRUE), "\n")
cat("Study day range:", range(app_usage_with_enrollment$study_day, na.rm = TRUE), "\n")
```

## Participant Overview

```{r participant-overview}
# Add platform information from app usage data
participant_platform_info <- app_usage_with_enrollment %>%
  group_by(RANDOM_ID) %>%
  summarise(
    platform_from_data = paste(unique(platform), collapse = ", "),
    .groups = "drop"
  )

# Summary by participant with completion status and platform
participant_summary <- participant_report %>%
  left_join(participant_platform_info, by = "RANDOM_ID") %>%
  select(RANDOM_ID, study_completion_status, status_category, Condition, 
         platform_from_data, Platforms, completed_exit_survey,
         EnrollmentDate, days_since_enrollment, study_end_date,
         num_submission_ids, total_donation_records, 
         num_study_days_with_data, study_days_with_data) %>%
  arrange(status_category, platform_from_data, RANDOM_ID) %>% # Sort by status, platform, then ID
  select(-status_category) # Remove the sorting column from display

# Display interactive participant table
datatable(participant_summary, 
      caption = "Participant Summary with Study Completion Status and Platform",
      colnames = c("Participant ID", "Status", "Condition", "Data Platform", "Study Platforms", 
                   "Exit Survey", "Enrollment Date", "Days Since Enrollment", "Study End Date",
                   "Submissions", "Total Records", "Days with Data", "Study Days List"),
      options = list(
        pageLength = 20,
        scrollX = TRUE,
        columnDefs = list(list(width = '120px', targets = c(1, 3, 4, 5))),
        order = list(list(1, 'asc'))
      ),
      filter = 'top')

# Summary of completion status
status_summary <- participant_report %>%
  count(study_completion_status, status_category) %>%
  arrange(status_category)

cat("\n=== STUDY COMPLETION STATUS SUMMARY ===\n")
for(i in 1:nrow(status_summary)) {
  cat(status_summary$study_completion_status[i], ":", status_summary$n[i], "participants\n")
}
```

## Data Availability by Study Day

```{r data-availability}
# Create a comprehensive data availability matrix
study_day_availability <- app_usage_with_enrollment %>%
  group_by(RANDOM_ID, study_day) %>%
  summarise(
    has_data = TRUE,
    num_records = n(),
    num_apps = n_distinct(App),
    total_duration = sum(`Duration (min)`, na.rm = TRUE),
    .groups = "drop"
  )

# Create complete grid of participant x study day combinations
all_participants <- unique(app_usage_with_enrollment$RANDOM_ID)
all_study_days <- 1:30

complete_grid <- expand_grid(
  RANDOM_ID = all_participants,
  study_day = all_study_days
) %>%
  left_join(study_day_availability, by = c("RANDOM_ID", "study_day")) %>%
  mutate(has_data = ifelse(is.na(has_data), FALSE, has_data)) %>%
  left_join(
    participant_report %>% select(RANDOM_ID, Condition, EnrollmentDate, 
                                study_completion_status, status_category),
    by = "RANDOM_ID"
  )

# Summary statistics
availability_summary <- complete_grid %>%
  group_by(study_day) %>%
  summarise(
    participants_with_data = sum(has_data),
    total_participants = n(),
    percentage_with_data = (participants_with_data / total_participants) * 100,
    .groups = "drop"
  )

cat("Data Availability Summary:\n")
datatable(availability_summary,
          caption = "Data Availability Summary by Study Day",
          colnames = c("Study Day", "Participants with Data", "Total Participants", "Percentage with Data"),
          options = list(
            pageLength = 15,
            scrollX = TRUE,
            order = list(list(0, 'asc'))
          ),
          filter = 'top') %>%
  formatRound(columns = c(4), digits = 1)
```

## Visualization: Data Availability Heatmap

```{r heatmap-setup}
# Add platform information to complete_grid
complete_grid_with_platform <- complete_grid %>%
  left_join(
    app_usage_with_enrollment %>% 
      select(RANDOM_ID, platform) %>% 
      distinct(),
    by = "RANDOM_ID"
  )

# Get available platforms
available_platforms <- unique(complete_grid_with_platform$platform)
available_platforms <- available_platforms[!is.na(available_platforms)]

cat("Available platforms for heatmaps:", paste(available_platforms, collapse = ", "), "\n")
```

### Android Platform Heatmap

```{r heatmap-android}
if ("Android" %in% available_platforms) {
  # Create heatmap for Android platform only
  android_participants <- complete_grid_with_platform %>%
    filter(platform == "Android") %>%
    pull(RANDOM_ID) %>%
    unique()
  
  heatmap_android <- complete_grid %>%
    filter(RANDOM_ID %in% android_participants) %>%
    # Add completion status colors to participant labels
    mutate(
      participant_label = paste0(RANDOM_ID, " (", str_extract(study_completion_status, "^[🟡✅🔴❓]"), ")")
    ) %>%
    # Sort by completion status for better visualization
    arrange(status_category, RANDOM_ID) %>%
    mutate(participant_label = factor(participant_label, levels = unique(participant_label))) %>%
    ggplot(aes(x = study_day, y = participant_label, fill = has_data)) +
    geom_tile(color = "white", size = 0.1) +
    scale_fill_manual(
      values = c("FALSE" = "#f7f7f7", "TRUE" = "#2166ac"),
      labels = c("No Data", "Has Data"),
      name = "Data Status"
    ) +
    scale_x_continuous(breaks = seq(1, 30, 2)) +
    labs(
      title = "App Usage Data Availability by Study Day - Android Platform",
      x = "Study Day",
      y = "Participant ID (Completion Status)",
      caption = paste0("Blue = Data available, Gray = No data. Android platform participants only (", 
                      length(android_participants), " participants).\nParticipants sorted by completion status: 🟡 In Progress, ✅ Complete, 🔴 Incomplete.\nIncomplete = >30 days since enrollment with <20 days data OR completed exit survey with <20 days data.")
    ) +
    theme_minimal() +
    theme(
      axis.text.y = element_text(size = 7),
      axis.text.x = element_text(size = 10),
      plot.title = element_text(size = 14, face = "bold"),
      plot.subtitle = element_text(size = 11),
      legend.position = "bottom"
    )
  
  print(heatmap_android)
  cat("Android platform participants:", length(android_participants), "\n")
} else {
  cat("No Android platform data available for heatmap.\n")
}
```

### Other Platform Heatmap

```{r heatmap-other}
if ("Other" %in% available_platforms) {
  # Create heatmap for Other platform only
  other_participants <- complete_grid_with_platform %>%
    filter(platform == "Other") %>%
    pull(RANDOM_ID) %>%
    unique()
  
  heatmap_other <- complete_grid %>%
    filter(RANDOM_ID %in% other_participants) %>%
    # Add completion status colors to participant labels
    mutate(
      participant_label = paste0(RANDOM_ID, " (", str_extract(study_completion_status, "^[🟡✅🔴❓]"), ")")
    ) %>%
    # Sort by completion status for better visualization
    arrange(status_category, RANDOM_ID) %>%
    mutate(participant_label = factor(participant_label, levels = unique(participant_label))) %>%
    ggplot(aes(x = study_day, y = participant_label, fill = has_data)) +
    geom_tile(color = "white", size = 0.1) +
    scale_fill_manual(
      values = c("FALSE" = "#f7f7f7", "TRUE" = "#2166ac"),
      labels = c("No Data", "Has Data"),
      name = "Data Status"
    ) +
    scale_x_continuous(breaks = seq(1, 30, 2)) +
    labs(
      title = "App Usage Data Availability by Study Day - Other Platform",
      x = "Study Day",
      y = "Participant ID (Completion Status)",
      caption = paste0("Blue = Data available, Gray = No data. Other platform participants only (", 
                      length(other_participants), " participants).\nParticipants sorted by completion status: 🟡 In Progress, ✅ Complete, 🔴 Incomplete.\nIncomplete = >30 days since enrollment with <20 days data OR completed exit survey with <20 days data.")
    ) +
    theme_minimal() +
    theme(
      axis.text.y = element_text(size = 7),
      axis.text.x = element_text(size = 10),
      plot.title = element_text(size = 14, face = "bold"),
      plot.subtitle = element_text(size = 11),
      legend.position = "bottom"
    )
  
  print(heatmap_other)
  cat("Other platform participants:", length(other_participants), "\n")
} else {
  cat("No Other platform data available for heatmap.\n")
}
```

### Combined Heatmap (All Platforms)

```{r heatmap-combined}
# Create combined heatmap of data availability with completion status (original version)
heatmap_plot <- complete_grid %>%
  # Add completion status colors to participant labels
  mutate(
    participant_label = paste0(RANDOM_ID, " (", str_extract(study_completion_status, "^[🟡✅🔴❓]"), ")")
  ) %>%
  # Sort by completion status for better visualization
  arrange(status_category, RANDOM_ID) %>%
  mutate(participant_label = factor(participant_label, levels = unique(participant_label))) %>%
  ggplot(aes(x = study_day, y = participant_label, fill = has_data)) +
  geom_tile(color = "white", size = 0.1) +
  scale_fill_manual(
    values = c("FALSE" = "#f7f7f7", "TRUE" = "#2166ac"),
    labels = c("No Data", "Has Data"),
    name = "Data Status"
  ) +
  scale_x_continuous(breaks = seq(1, 30, 2)) +
  labs(
    title = "App Usage Data Availability by Study Day - All Platforms",
    x = "Study Day",
    y = "Participant ID (Completion Status)",
    caption = "Blue = Data available, Gray = No data. All platforms combined. Participants sorted by completion status.\nEach row represents a participant with completion status: 🟡 In Progress, ✅ Complete, 🔴 Incomplete.\nIncomplete = >30 days since enrollment with <20 days data OR completed exit survey with <20 days data."
  ) +
  theme_minimal() +
  theme(
    axis.text.y = element_text(size = 7),
    axis.text.x = element_text(size = 10),
    plot.title = element_text(size = 14, face = "bold"),
    plot.subtitle = element_text(size = 11),
    legend.position = "bottom"
  )

print(heatmap_plot)
```

## Data Availability Trends

```{r availability-trends}
# Plot percentage of participants with data by study day
availability_trend <- availability_summary %>%
  ggplot(aes(x = study_day, y = percentage_with_data)) +
  geom_line(color = "#2166ac", size = 1) +
  geom_point(color = "#2166ac", size = 2) +
  scale_x_continuous(breaks = seq(1, 30, 2)) +
  scale_y_continuous(limits = c(0, 100), labels = function(x) paste0(x, "%")) +
  labs(
    title = "Percentage of Participants with App Usage Data by Study Day",
    x = "Study Day",
    y = "Percentage of Participants with Data",
    caption = paste0("Based on ", length(all_participants), " participants")
  ) +
  theme_minimal()

print(availability_trend)

# Additional summary statistics
cat("\nData Availability Statistics:\n")
cat("- Days with 100% participation:", sum(availability_summary$percentage_with_data == 100), "\n")
cat("- Days with >50% participation:", sum(availability_summary$percentage_with_data > 50), "\n")
cat("- Days with <25% participation:", sum(availability_summary$percentage_with_data < 25), "\n")
```

## Data Volume Analysis by Study Day

```{r data-volume}
# Analyze data volume (number of records) by study day and condition (Complete participants only)
# First, identify participants with "Complete" status for volume analysis
complete_participants <- participant_report %>%
  filter(str_detect(study_completion_status, "✅ Complete")) %>%
  pull(RANDOM_ID)

cat("Using participants with Complete status:", length(complete_participants), "participants\n")

# Filter study_day_availability for complete participants only
study_day_availability_complete <- study_day_availability %>%
  filter(RANDOM_ID %in% complete_participants)

# Debug: Test the join step by step for complete participants
temp_participant_data_complete <- participant_report %>% 
  filter(RANDOM_ID %in% complete_participants) %>%
  select(RANDOM_ID, Condition)

cat("participant_report RANDOM_ID type:", class(temp_participant_data_complete$RANDOM_ID), "\n")
cat("study_day_availability RANDOM_ID type:", class(study_day_availability_complete$RANDOM_ID), "\n")

joined_data <- study_day_availability_complete %>%
  left_join(temp_participant_data_complete, by = "RANDOM_ID")

cat("Joined data columns:", paste(names(joined_data), collapse=", "), "\n")
cat("Missing Condition values:", sum(is.na(joined_data$Condition)), "out of", nrow(joined_data), "\n")

# Calculate both totals and individual participant stats for error bars
volume_by_day_condition <- joined_data %>%
  filter(!is.na(Condition)) %>%  # Filter out rows where Condition is missing
  group_by(study_day, Condition) %>%
  summarise(
    total_records = sum(num_records, na.rm = TRUE),
    avg_records_per_participant = mean(num_records, na.rm = TRUE),
    median_records_per_participant = median(num_records, na.rm = TRUE),
    se_records_per_participant = sd(num_records, na.rm = TRUE) / sqrt(n()),
    participants_with_data = n(),
    .groups = "drop"
  ) %>%
  mutate(
    # Calculate error bars for total records (using SE of individual participants)
    total_records_se = se_records_per_participant * sqrt(participants_with_data),
    total_records_lower = total_records - total_records_se,
    total_records_upper = total_records + total_records_se
  )

# Note: complete_participants already defined above (participants with >=15 days of data)

# Create duration data following the EXACT same pattern as volume analysis
study_day_duration <- app_usage_with_enrollment %>%
  filter(RANDOM_ID %in% complete_participants) %>%  # Filter for complete participants only
  group_by(RANDOM_ID, study_day) %>%
  summarise(
    daily_duration = sum(`Duration (min)`, na.rm = TRUE),
    .groups = "drop"
  )

# Join with participant data to get Condition, following volume analysis pattern
temp_participant_data_complete <- participant_report %>% 
  filter(RANDOM_ID %in% complete_participants) %>%
  select(RANDOM_ID, Condition)

duration_joined_data <- study_day_duration %>%
  left_join(temp_participant_data_complete, by = "RANDOM_ID")

# Aggregate by study day and condition with error bars - EXACT same pattern as volume
duration_by_day_condition_complete <- duration_joined_data %>%
  filter(!is.na(Condition)) %>%  # Filter out rows where Condition is missing
  group_by(study_day, Condition) %>%
  summarise(
    total_duration = sum(daily_duration, na.rm = TRUE),
    avg_duration_per_participant = mean(daily_duration, na.rm = TRUE),
    median_duration_per_participant = median(daily_duration, na.rm = TRUE),
    se_duration_per_participant = sd(daily_duration, na.rm = TRUE) / sqrt(n()),
    participants_with_data = n(),  # Use n() like volume, not n_distinct()
    .groups = "drop"
  ) %>%
  mutate(
    # Calculate error bars for total duration - same pattern as volume
    total_duration_se = se_duration_per_participant * sqrt(participants_with_data),
    total_duration_lower = pmax(0, total_duration - total_duration_se),  # Ensure non-negative
    total_duration_upper = total_duration + total_duration_se
  )

# Both plots now have error bars showing daily variation between participants

# Plot data volume trends by condition with error bars
volume_plot <- volume_by_day_condition %>%
  ggplot(aes(x = study_day, y = total_records, color = Condition)) +
  geom_ribbon(aes(ymin = total_records_lower, ymax = total_records_upper, fill = Condition), 
              alpha = 0.2, color = NA) +
  geom_vline(xintercept = 7, linetype = "dashed", color = "gray50", alpha = 0.7) +
  geom_vline(xintercept = 21, linetype = "dashed", color = "gray50", alpha = 0.7) +
  geom_line(size = 1) +
  geom_point(size = 2) +
  scale_x_continuous(breaks = seq(1, 30, 2)) +
  scale_color_manual(values = c("control" = "#d73027", "intervention" = "#1a9850")) +
  scale_fill_manual(values = c("control" = "#d73027", "intervention" = "#1a9850"), guide = "none") +
  labs(
    title = "Total App Usage Records by Study Day and Condition (Complete Participants Only)",
    x = "Study Day",
    y = "Total Number of Records",
    color = "Condition",
    caption = paste0("Complete participants only (", length(complete_participants), " participants total). Error bars show ±1 SE.")
  ) +
  theme_minimal() +
  theme(legend.position = "bottom")

print(volume_plot)

# Plot total duration trends by condition with error bars (Complete participants only)
duration_plot_complete <- duration_by_day_condition_complete %>%
  ggplot(aes(x = study_day, y = total_duration, color = Condition)) +
  geom_ribbon(aes(ymin = total_duration_lower, ymax = total_duration_upper, fill = Condition), 
              alpha = 0.2, color = NA) +
  geom_vline(xintercept = 7, linetype = "dashed", color = "gray50", alpha = 0.7) +
  geom_vline(xintercept = 21, linetype = "dashed", color = "gray50", alpha = 0.7) +
  geom_line(size = 1) +
  geom_point(size = 2) +
  scale_x_continuous(breaks = seq(1, 30, 2)) +
  scale_color_manual(values = c("control" = "#d73027", "intervention" = "#1a9850")) +
  scale_fill_manual(values = c("control" = "#d73027", "intervention" = "#1a9850"), guide = "none") +
  labs(
    title = "Total App Duration by Study Day and Condition (Complete Participants Only)",
    x = "Study Day",
    y = "Total Duration (minutes)",
    color = "Condition",
    caption = paste0("Complete participants only (", length(complete_participants), " participants total). Error bars show ±1 SE.")
  ) +
  theme_minimal() +
  theme(legend.position = "bottom")

print(duration_plot_complete)

# Interactive summary table - Volume data by condition (Complete participants only)
datatable(volume_by_day_condition, 
      caption = "Data Volume Summary by Study Day and Condition (Complete Participants Only)",
      colnames = c("Study Day", "Condition", "Total Records", "Avg Records/Participant", 
                   "Median Records/Participant", "SE Records/Participant", "Participants with Data", 
                   "SE Total Records", "Lower CI", "Upper CI"),
      options = list(
        pageLength = 15,
        scrollX = TRUE,
        order = list(list(0, 'asc'), list(1, 'asc'))
      ),
      filter = 'top') %>%
      formatRound(columns = c(4, 5), digits = 1)

cat("\n")

# Interactive summary table - Duration data by condition (Complete participants only)
datatable(duration_by_day_condition_complete, 
      caption = "Total Duration Summary by Study Day and Condition (Complete Participants Only)",
      colnames = c("Study Day", "Condition", "Total Duration (min)", "Avg Duration/Participant", 
                   "SE Duration/Participant", "Participants with Data", "SE Total Duration", 
                   "Lower CI", "Upper CI"),
      options = list(
        pageLength = 15,
        scrollX = TRUE,
        order = list(list(0, 'asc'), list(1, 'asc'))
      ),
      filter = 'top') %>%
      formatRound(columns = c(3), digits = 1)
```

## Condition-Specific Analysis

```{r condition-analysis}
# Analyze data availability by experimental condition
condition_availability <- complete_grid %>%
  group_by(Condition, study_day) %>%
  summarise(
    participants_with_data = sum(has_data),
    total_participants = n(),
    percentage_with_data = (participants_with_data / total_participants) * 100,
    .groups = "drop"
  )

# Plot by condition
condition_plot <- condition_availability %>%
  ggplot(aes(x = study_day, y = percentage_with_data, color = Condition)) +
  geom_line(size = 1) +
  geom_point(size = 2) +
  scale_x_continuous(breaks = seq(1, 30, 2)) +
  scale_y_continuous(limits = c(0, 100), labels = function(x) paste0(x, "%")) +
  scale_color_manual(values = c("control" = "#d73027", "intervention" = "#1a9850")) +
  labs(
    title = "Data Availability by Study Day and Experimental Condition",
    x = "Study Day",
    y = "Percentage of Participants with Data",
    color = "Condition"
  ) +
  theme_minimal() +
  theme(legend.position = "bottom")

print(condition_plot)

# Completion status by condition
completion_by_condition <- participant_report %>%
  count(Condition, study_completion_status) %>%
  group_by(Condition) %>%
  mutate(
    total_in_condition = sum(n),
    percentage = round((n / total_in_condition) * 100, 1)
  ) %>%
  ungroup()

cat("\n=== COMPLETION STATUS BY CONDITION ===\n")
for(condition in unique(completion_by_condition$Condition)) {
  cat("\n", toupper(condition), "GROUP:\n")
  condition_data <- completion_by_condition %>% filter(Condition == condition)
  for(i in 1:nrow(condition_data)) {
    cat("  ", condition_data$study_completion_status[i], ":", 
        condition_data$n[i], "participants (", condition_data$percentage[i], "%)\n")
  }
}
```

## Participant Session Statistics

```{r session-statistics-setup}
# Calculate detailed session statistics for each participant by platform
session_stats_by_platform <- app_usage_with_enrollment %>%
  group_by(RANDOM_ID, platform, session_date) %>%
  summarise(
    daily_sessions = n(),
    daily_duration = sum(`Duration (min)`, na.rm = TRUE),
    daily_apps = n_distinct(App),
    .groups = "drop"
  ) %>%
  group_by(RANDOM_ID, platform) %>%
  summarise(
    # Session count statistics
    min_daily_sessions = min(daily_sessions),
    max_daily_sessions = max(daily_sessions),
    avg_daily_sessions = round(mean(daily_sessions), 1),
    median_daily_sessions = median(daily_sessions),
    
    # Duration statistics  
    min_daily_duration = round(min(daily_duration), 1),
    max_daily_duration = round(max(daily_duration), 1),
    avg_daily_duration = round(mean(daily_duration), 1),
    median_daily_duration = round(median(daily_duration), 1),
    
    # App diversity statistics
    min_daily_apps = min(daily_apps),
    max_daily_apps = max(daily_apps),
    avg_daily_apps = round(mean(daily_apps), 1),
    median_daily_apps = median(daily_apps),
    
    # Overall statistics
    total_days = n(),
    total_sessions = sum(daily_sessions),
    total_duration_hours = round(sum(daily_duration) / 60, 1),
    
    .groups = "drop"
  ) %>%
  # Add completion status information
  left_join(
    participant_report %>% select(RANDOM_ID, study_completion_status, Condition),
    by = "RANDOM_ID"
  ) %>%
  # Sort by platform, completion status and session count
  arrange(platform, study_completion_status, desc(avg_daily_sessions))

# Get available platforms
platforms <- unique(session_stats_by_platform$platform)
```

### Android

```{r session-statistics-android}
if ("Android" %in% platforms) {
  platform_data_android <- session_stats_by_platform %>% filter(platform == "Android")
  
  datatable(platform_data_android %>% select(-platform), 
        caption = "Detailed Session Statistics - Android Platform",
        colnames = c(
          "Participant ID", "Min Daily Sessions", "Max Daily Sessions", 
          "Avg Daily Sessions", "Median Daily Sessions",
          "Min Daily Duration (min)", "Max Daily Duration (min)",
          "Avg Daily Duration (min)", "Median Daily Duration (min)",
          "Min Daily Apps", "Max Daily Apps", "Avg Daily Apps", "Median Daily Apps",
          "Total Days", "Total Sessions", "Total Duration (hrs)",
          "Status", "Condition"
        ),
        options = list(
          pageLength = 15,
          scrollX = TRUE,
          columnDefs = list(list(width = '100px', targets = c(0, 16, 17))),
          order = list(list(3, 'desc'))
        ),
        filter = 'top') %>%
        formatRound(columns = c(4, 6, 8, 10, 12, 16), digits = 1)
} else {
  cat("No Android platform data available.")
}
```

### Other

```{r session-statistics-other}
if ("Other" %in% platforms) {
  platform_data_other <- session_stats_by_platform %>% filter(platform == "Other")
  
  datatable(platform_data_other %>% select(-platform), 
        caption = "Detailed Session Statistics - Other Platform",
        colnames = c(
          "Participant ID", "Min Daily Sessions", "Max Daily Sessions", 
          "Avg Daily Sessions", "Median Daily Sessions",
          "Min Daily Duration (min)", "Max Daily Duration (min)",
          "Avg Daily Duration (min)", "Median Daily Duration (min)",
          "Min Daily Apps", "Max Daily Apps", "Avg Daily Apps", "Median Daily Apps",
          "Total Days", "Total Sessions", "Total Duration (hrs)",
          "Status", "Condition"
        ),
        options = list(
          pageLength = 15,
          scrollX = TRUE,
          columnDefs = list(list(width = '100px', targets = c(0, 16, 17))),
          order = list(list(3, 'desc'))
        ),
        filter = 'top') %>%
        formatRound(columns = c(4, 6, 8, 10, 12, 16), digits = 1)
} else {
  cat("No Other platform data available.")
}

# Handle any additional platforms dynamically
other_platforms <- setdiff(platforms, c("Android", "Other"))
if (length(other_platforms) > 0) {
  for(platform_name in other_platforms) {
    cat(sprintf("\n### %s\n\n", str_to_title(platform_name)))
    
    platform_data <- session_stats_by_platform %>% filter(platform == platform_name)
    
    datatable(platform_data %>% select(-platform), 
          caption = paste("Detailed Session Statistics -", str_to_title(platform_name), "Platform"),
          colnames = c(
            "Participant ID", "Min Daily Sessions", "Max Daily Sessions", 
            "Avg Daily Sessions", "Median Daily Sessions",
            "Min Daily Duration (min)", "Max Daily Duration (min)",
            "Avg Daily Duration (min)", "Median Daily Duration (min)",
            "Min Daily Apps", "Max Daily Apps", "Avg Daily Apps", "Median Daily Apps",
            "Total Days", "Total Sessions", "Total Duration (hrs)",
            "Status", "Condition"
          ),
          options = list(
            pageLength = 15,
            scrollX = TRUE,
            columnDefs = list(list(width = '100px', targets = c(0, 16, 17))),
            order = list(list(3, 'desc'))
          ),
          filter = 'top') %>%
          formatRound(columns = c(4, 6, 8, 10, 12, 16), digits = 1)
  }
}
```

### Summary by Platform and Condition

```{r session-statistics-summary}
# Summary statistics by platform and condition
platform_condition_summary <- session_stats_by_platform %>%
  group_by(platform, Condition) %>%
  summarise(
    participants = n(),
    avg_sessions_per_day = round(mean(avg_daily_sessions), 1),
    avg_duration_per_day = round(mean(avg_daily_duration), 1),
    avg_apps_per_day = round(mean(avg_daily_apps), 1),
    avg_total_hours = round(mean(total_duration_hours), 1),
    .groups = "drop"
  )

datatable(platform_condition_summary,
          caption = "Session Statistics Summary by Platform and Condition",
          colnames = c("Platform", "Condition", "Participants", "Avg Sessions/Day", 
                       "Avg Duration/Day", "Avg Apps/Day", "Avg Total Hours"),
          options = list(
            pageLength = 10,
            scrollX = TRUE,
            order = list(list(0, 'asc'), list(1, 'asc'))
          ),
          filter = 'top') %>%
          formatRound(columns = c(4, 5, 6, 7), digits = 1)
```

## Top Apps Analysis by Participant

```{r top-apps-analysis}
# Calculate top apps for each participant by platform
top_apps_by_participant_platform <- app_usage_with_enrollment %>%
  group_by(RANDOM_ID, platform, App) %>%
  summarise(
    total_sessions = n(),
    total_duration = sum(`Duration (min)`, na.rm = TRUE),
    days_used = n_distinct(session_date),
    avg_duration_per_session = round(mean(`Duration (min)`, na.rm = TRUE), 1),
    .groups = "drop"
  ) %>%
  # Rank apps by total duration for each participant within each platform
  group_by(RANDOM_ID, platform) %>%
  arrange(RANDOM_ID, platform, desc(total_duration)) %>%
  mutate(
    app_rank = row_number(),
    pct_of_total_duration = round((total_duration / sum(total_duration)) * 100, 1)
  ) %>%
  filter(app_rank <= 10) %>% # Top 10 apps only
  ungroup()

# Add participant completion status and platform info
top_apps_with_status_platform <- top_apps_by_participant_platform %>%
  left_join(
    participant_report %>% select(RANDOM_ID, study_completion_status, Condition),
    by = "RANDOM_ID"
  )

# Create interactive summary tables by platform
platforms <- unique(top_apps_with_status_platform$platform)

for(platform_name in platforms) {
  platform_apps_data <- top_apps_with_status_platform %>%
    filter(platform == platform_name)
  
  cat("\n=== TOP APPS SUMMARY:", toupper(platform_name), "PLATFORM ===\n")
  cat("Total records:", nrow(platform_apps_data), "\n\n")
  
  # Show sample of top apps data in text format
  if (nrow(platform_apps_data) > 0) {
    # Group by participant and show their top 10 apps
    sample_participants <- platform_apps_data %>%
      filter(app_rank <= 10) %>%
      arrange(RANDOM_ID, app_rank)
    
    if (nrow(sample_participants) > 0) {
      cat("Sample of participants' top apps:\n")
      current_participant <- ""
      for(i in 1:min(nrow(sample_participants), 100)) { # Show first 100 entries (10 apps x ~10 participants)
        row <- sample_participants[i,]
        if (row$RANDOM_ID != current_participant) {
          current_participant <- row$RANDOM_ID
          cat(sprintf("\n%s (%s, %s):\n", row$RANDOM_ID, row$study_completion_status, row$Condition))
        }
        cat(sprintf("  %d. %s (%d sessions, %.1f min, %d days, %.1f%%)\n", 
                    row$app_rank, row$App, row$total_sessions, row$total_duration, 
                    row$days_used, row$pct_of_total_duration))
      }
      if (nrow(sample_participants) > 100) {
        cat(sprintf("  ... and %d more entries\n", nrow(sample_participants) - 100))
      }
    }
  }
  cat("\n")
}

# Summary: Most popular apps across all participants by platform
for(platform_name in platforms) {
  platform_popular_apps <- top_apps_with_status_platform %>%
    filter(platform == platform_name) %>%
    group_by(App) %>%
    summarise(
      users_count = n_distinct(RANDOM_ID),
      total_sessions_all = sum(total_sessions),
      total_duration_all = sum(total_duration),
      avg_rank = round(mean(app_rank), 1),
      avg_pct_time = round(mean(pct_of_total_duration), 1),
      .groups = "drop"
    ) %>%
    filter(users_count >= 2) %>% # Apps used by at least 2 participants
    arrange(desc(users_count), desc(total_duration_all))
  
  # cat("\n=== MOST POPULAR APPS:", toupper(platform_name), "PLATFORM ===\n")
  # cat("(Apps used by 2+ participants)\n\n")
  
  if (nrow(platform_popular_apps) > 0) {
    # Convert duration from minutes to hours for better readability
    platform_popular_apps_display <- platform_popular_apps %>%
      mutate(total_duration_hours = round(total_duration_all / 60, 1))
    
    datatable(platform_popular_apps_display %>% 
                select(App, users_count, total_sessions_all, total_duration_hours, 
                       total_duration_all, avg_rank, avg_pct_time),
          caption = paste("Most Popular Apps (Used by 2+ Participants) -", platform_name, "Platform"),
          colnames = c("App Name", "Users", "Total Sessions", "Total Duration (hrs)", 
                       "Total Duration (min)", "Avg Rank", "Avg % of User Time"),
          options = list(
            pageLength = 15,
            scrollX = TRUE,
            columnDefs = list(list(width = '150px', targets = c(0))),
            order = list(list(1, 'desc'), list(3, 'desc'))
          ),
          filter = 'top') %>%
          formatRound(columns = c(4, 5, 6, 7), digits = 1)
  } else {
    # cat("No apps used by 2+ participants found.\n")
  }
  # cat("\n")
}
```

## Unique Apps Analysis

```{r unique-apps-analysis}
# Generate comprehensive unique apps table with usage statistics by platform
unique_apps_by_platform <- app_usage_with_enrollment %>%
  group_by(platform, App) %>%
  summarise(
    total_sessions = n(),
    total_duration_min = sum(`Duration (min)`, na.rm = TRUE),
    total_duration_hours = round(sum(`Duration (min)`, na.rm = TRUE) / 60, 1),
    unique_users = n_distinct(RANDOM_ID),
    unique_days = n_distinct(session_date),
    avg_duration_per_session = round(mean(`Duration (min)`, na.rm = TRUE), 2),
    avg_sessions_per_user = round(total_sessions / unique_users, 1),
    avg_hours_per_user = round(total_duration_hours / unique_users, 1),
    .groups = "drop"
  )

# Calculate percentages within each platform
unique_apps_by_platform <- unique_apps_by_platform %>%
  group_by(platform) %>%
  mutate(
    pct_of_total_sessions = round((total_sessions / sum(total_sessions)) * 100, 2),
    pct_of_total_duration = round((total_duration_min / sum(total_duration_min)) * 100, 2)
  ) %>%
  ungroup() %>%
  # Sort by platform, then by total sessions descending
  arrange(platform, desc(total_sessions))

# Display interactive tables by platform
platforms <- unique(unique_apps_by_platform$platform)

# Process Android platform
android_apps <- unique_apps_by_platform %>% filter(platform == "Android")

cat("\n=== UNIQUE APPS: ANDROID PLATFORM ===\n")
cat("Total unique apps identified:", nrow(android_apps), "\n\n")
```

```{r android-comprehensive-table}
# Android comprehensive table
datatable(android_apps %>% select(-platform),
      caption = "Complete List of Unique Apps - Android Platform",
      colnames = c(
        "App Name", "Total Sessions", "Total Duration (min)", "Total Duration (hrs)",
        "Users", "Days Used", "Avg Duration/Session", "Avg Sessions/User", 
        "Avg Hours/User", "% of Sessions", "% of Duration"
      ),
      options = list(
        pageLength = 15,
        scrollX = TRUE,
        columnDefs = list(list(width = '120px', targets = c(0))),
        order = list(list(1, 'desc'))
      ),
      filter = 'top') %>%
      formatRound(columns = c(2, 3, 6, 7, 8, 9, 10), digits = c(0, 1, 2, 1, 1, 2, 2))
```

```{r android-summary}
# Summary statistics for Android platform
cat("\n=== UNIQUE APPS SUMMARY: ANDROID PLATFORM ===\n")
cat("Total unique apps:", nrow(android_apps), "\n")
cat("Apps used by only 1 user:", sum(android_apps$unique_users == 1), "\n")
cat("Apps used by 2+ users:", sum(android_apps$unique_users >= 2), "\n")
cat("Apps used by 5+ users:", sum(android_apps$unique_users >= 5), "\n")
cat("Apps used by 10+ users:", sum(android_apps$unique_users >= 10), "\n\n")

# Interactive tables showing all apps by different metrics
cat("=== INTERACTIVE TABLES BY DIFFERENT METRICS: ANDROID ===\n\n")
cat("**Apps Ranked by Total Sessions:**\n")
```

```{r other-platform-setup}
# Process Other platform
other_apps <- unique_apps_by_platform %>% filter(platform == "Other")

cat("\n=== UNIQUE APPS: OTHER PLATFORM ===\n")
cat("Total unique apps identified:", nrow(other_apps), "\n\n")
```

```{r other-comprehensive-table}
# Other platform comprehensive table
datatable(other_apps %>% select(-platform),
      caption = "Complete List of Unique Apps - Other Platform",
      colnames = c(
        "App Name", "Total Sessions", "Total Duration (min)", "Total Duration (hrs)",
        "Users", "Days Used", "Avg Duration/Session", "Avg Sessions/User", 
        "Avg Hours/User", "% of Sessions", "% of Duration"
      ),
      options = list(
        pageLength = 15,
        scrollX = TRUE,
        columnDefs = list(list(width = '120px', targets = c(0))),
        order = list(list(1, 'desc'))
      ),
      filter = 'top') %>%
      formatRound(columns = c(2, 3, 6, 7, 8, 9, 10), digits = c(0, 1, 2, 1, 1, 2, 2))
```

```{r other-summary}
# Summary statistics for Other platform
cat("\n=== UNIQUE APPS SUMMARY: OTHER PLATFORM ===\n")
cat("Total unique apps:", nrow(other_apps), "\n")
cat("Apps used by only 1 user:", sum(other_apps$unique_users == 1), "\n")
cat("Apps used by 2+ users:", sum(other_apps$unique_users >= 2), "\n")
cat("Apps used by 5+ users:", sum(other_apps$unique_users >= 5), "\n")
cat("Apps used by 10+ users:", sum(other_apps$unique_users >= 10), "\n\n")

# Interactive tables showing all apps by different metrics
cat("=== INTERACTIVE TABLES BY DIFFERENT METRICS: OTHER ===\n\n")
cat("**Apps Ranked by Total Sessions:**\n")
```

## Individual Participant Patterns

```{r individual-patterns}
# Look at individual participant data patterns
participant_patterns <- complete_grid %>%
  group_by(RANDOM_ID, Condition, study_completion_status, status_category) %>%
  summarise(
    total_days_with_data = sum(has_data),
    consecutive_days = max(rle(has_data)$lengths[rle(has_data)$values == TRUE], na.rm = TRUE),
    first_day_with_data = min(study_day[has_data], na.rm = TRUE),
    last_day_with_data = max(study_day[has_data], na.rm = TRUE),
    .groups = "drop"
  ) %>%
  mutate(
    consecutive_days = ifelse(is.infinite(consecutive_days), 0, consecutive_days),
    data_span = last_day_with_data - first_day_with_data + 1
  ) %>%
  # Sort by completion status
  arrange(status_category, RANDOM_ID)

# Summary by condition
pattern_summary <- participant_patterns %>%
  group_by(Condition) %>%
  summarise(
    n_participants = n(),
    avg_days_with_data = mean(total_days_with_data, na.rm = TRUE),
    median_days_with_data = median(total_days_with_data, na.rm = TRUE),
    avg_consecutive_days = mean(consecutive_days, na.rm = TRUE),
    avg_data_span = mean(data_span, na.rm = TRUE),
    .groups = "drop"
  )

cat("Participant Data Patterns by Condition:\n")
datatable(pattern_summary,
          caption = "Participant Data Patterns Summary by Condition",
          colnames = c("Condition", "Participants", "Avg Days with Data", "Median Days with Data", 
                       "Avg Consecutive Days", "Avg Data Span"),
          options = list(
            pageLength = 10,
            scrollX = TRUE,
            order = list(list(0, 'asc'))
          ),
          filter = 'top') %>%
          formatRound(columns = c(3, 4, 5, 6), digits = 1)

# Interactive detailed participant table
datatable(participant_patterns, 
      caption = "Individual Participant Data Patterns (Sorted by Completion Status)",
      options = list(
        pageLength = 20,
        scrollX = TRUE,
        columnDefs = list(list(width = '100px', targets = c(0, 1, 2, 3))),
        order = list(list(2, 'asc'))
      ),
      filter = 'top') %>%
      formatRound(columns = c(5, 6, 7, 8, 9), digits = 0)
```

## Key Findings Summary

```{r summary}
# Calculate key statistics
total_participants <- length(all_participants)
days_with_any_data <- sum(availability_summary$participants_with_data > 0)
peak_participation_day <- availability_summary$study_day[which.max(availability_summary$percentage_with_data)]
peak_participation_rate <- max(availability_summary$percentage_with_data)

avg_days_per_participant <- mean(participant_patterns$total_days_with_data, na.rm = TRUE)
participants_with_full_month <- sum(participant_patterns$total_days_with_data >= 28, na.rm = TRUE)

# Completion status counts
completion_counts <- participant_report %>% count(study_completion_status)
in_progress <- completion_counts$n[completion_counts$study_completion_status == "🟡 In Progress"]
complete <- completion_counts$n[completion_counts$study_completion_status == "✅ Complete"]
incomplete <- completion_counts$n[completion_counts$study_completion_status == "🔴 Incomplete"]

# Handle NA values for missing statuses
in_progress <- ifelse(length(in_progress) == 0, 0, in_progress)
complete <- ifelse(length(complete) == 0, 0, complete)
incomplete <- ifelse(length(incomplete) == 0, 0, incomplete)

cat("=== KEY FINDINGS ===\n\n")
cat("Study Overview:\n")
cat("- Total participants with app usage data:", total_participants, "\n")
cat("- Report generated on:", as.character(Sys.Date()), "\n")
cat("- Study days with any data:", days_with_any_data, "out of 30\n")
cat("- Peak participation on day", peak_participation_day, "with", round(peak_participation_rate, 1), "% of participants\n\n")

cat("Study Completion Status:\n")
cat("- 🟡 In Progress (not yet 28 days since enrollment):", in_progress, "participants\n")
cat("- ✅ Complete (≥28 days, ≥20 days of data):", complete, "participants\n")
cat("- 🔴 Incomplete (≥28 days, <20 days of data):", incomplete, "participants\n\n")

cat("Data Coverage:\n")
cat("- Average days with data per participant:", round(avg_days_per_participant, 1), "\n")
cat("- Participants with data for ≥28 days:", participants_with_full_month, "out of", total_participants, "\n")
cat("- Overall data availability rate:", round(mean(availability_summary$percentage_with_data), 1), "%\n\n")

cat("Condition Comparison:\n")
control_avg <- pattern_summary$avg_days_with_data[pattern_summary$Condition == "control"]
intervention_avg <- pattern_summary$avg_days_with_data[pattern_summary$Condition == "intervention"]
cat("- Control group average days:", round(control_avg, 1), "\n")
cat("- Intervention group average days:", round(intervention_avg, 1), "\n")
```

## Data Export

```{r export}
# Export processed data for further analysis
write_csv(complete_grid, "../../.tmp/aw/study_day_availability_matrix.csv")
write_csv(availability_summary, "../../.tmp/aw/daily_availability_summary.csv")
write_csv(participant_patterns, "../../.tmp/aw/participant_data_patterns.csv")
write_csv(session_stats_by_platform, "../../.tmp/aw/participant_session_statistics_by_platform.csv")
write_csv(top_apps_with_status_platform, "../../.tmp/aw/top_apps_by_participant_platform.csv")
write_csv(unique_apps_by_platform, "../../.tmp/aw/unique_apps_with_statistics_by_platform.csv")

cat("Exported files:\n")
cat("- study_day_availability_matrix.csv: Complete participant x study day matrix\n")
cat("- daily_availability_summary.csv: Daily availability percentages\n")
cat("- participant_data_patterns.csv: Individual participant patterns\n")
cat("- participant_session_statistics_by_platform.csv: Detailed session statistics per participant by platform\n")
cat("- top_apps_by_participant_platform.csv: Top 10 apps for each participant by platform\n")
cat("- unique_apps_with_statistics_by_platform.csv: Complete list of unique apps with usage statistics by platform\n")
```