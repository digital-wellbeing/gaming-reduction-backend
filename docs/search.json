[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Gaming Reduction Experiment",
    "section": "",
    "text": "This site describes the data simulation, preprocessing, and analysis code for our RCT on gaming effects.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Simulation-based Power Analysis for Two-arm RCT with Linear and Compositional Outcomes</span>"
    ]
  },
  {
    "objectID": "scripts/sim_comp_report.html",
    "href": "scripts/sim_comp_report.html",
    "title": "2  H1 - Effect of Abstention on Sendentary Activity",
    "section": "",
    "text": "2.1 Introduction\nThis document demonstrates a simulation-based power analysis for a two-arm parallel randomized controlled trial (RCT) with compositional outcomes. The simulation models 24-hour time use data consisting of three components: sleep, sedentary time, and physical activity, which sum to 1440 minutes (24 hours). The analysis includes visualization of power curves and effect sizes to help determine optimal sample sizes and assess the sensitivity of the study design to different parameters.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>H1 - Effect of Abstention on Sendentary Activity</span>"
    ]
  },
  {
    "objectID": "scripts/sim_comp_report.html#introduction",
    "href": "scripts/sim_comp_report.html#introduction",
    "title": "2  H1 - Effect of Abstention on Sendentary Activity",
    "section": "",
    "text": "2.1.1 Required Packages\n\n\nShow code (libraries)\n# Load required packages with error handling\nload_package_safely &lt;- function(pkg) {\n  if (!requireNamespace(pkg, quietly = TRUE)) {\n    message(paste(\"Package\", pkg, \"not available, attempting to install...\"))\n    tryCatch({\n      if (pkg %in% c(\"microbiome\", \"ComplexHeatmap\")) {\n        # Bioconductor packages\n        if (!requireNamespace(\"BiocManager\", quietly = TRUE)) install.packages(\"BiocManager\")\n        BiocManager::install(pkg, update = FALSE)\n      } else if (pkg == \"microViz\") {\n        # Special repository\n        install.packages(pkg, repos = c(davidbarnett = \"https://david-barnett.r-universe.dev\", getOption(\"repos\")))\n      } else {\n        # Regular CRAN packages\n        install.packages(pkg)\n      }\n    }, error = function(e) {\n      message(paste(\"Failed to install\", pkg, \":\", e$message))\n    })\n  }\n  \n  # Try to load the package\n  success &lt;- suppressMessages(suppressWarnings(\n    tryCatch({\n      library(pkg, character.only = TRUE)\n      TRUE\n    }, error = function(e) {\n      message(paste(\"Package\", pkg, \"not available, skipping\"))\n      FALSE\n    })\n  ))\n  return(success)\n}\n\n# Load core packages (required for analysis)\ncore_packages &lt;- c(\"tidyverse\", \"lme4\", \"compositions\", \"lmerTest\", \"MASS\")\nmessage(\"Loading core packages...\")\nloaded_core &lt;- sapply(core_packages, load_package_safely)\nif (!all(loaded_core)) {\n  stop(\"Core packages failed to load: \", paste(core_packages[!loaded_core], collapse = \", \"))\n}\n\n# Load optional packages (nice to have but not critical)\noptional_packages &lt;- c(\"ggtern\", \"progress\", \"patchwork\", \"foreach\", \"doSNOW\", \"doParallel\", \"DT\", \"ggtext\", \"ggraph\", \"kableExtra\")\nmessage(\"Loading optional packages...\")\nloaded_optional &lt;- sapply(optional_packages, load_package_safely)\nmessage(\"Optional packages loaded: \", paste(optional_packages[loaded_optional], collapse = \", \"))\nif (any(!loaded_optional)) {\n  message(\"Optional packages not loaded: \", paste(optional_packages[!loaded_optional], collapse = \", \"))\n}\n\n# Load specialized packages (for microbiome analysis, if needed)\n# Note: phyloseq temporarily commented out due to installation issues\nspecialized_packages &lt;- c(\"microbiome\", \"ComplexHeatmap\", \"microViz\", \"corncob\")\nmessage(\"Loading specialized packages...\")\nloaded_specialized &lt;- sapply(specialized_packages, load_package_safely)\nmessage(\"Specialized packages loaded: \", paste(specialized_packages[loaded_specialized], collapse = \", \"))\nif (any(!loaded_specialized)) {\n  message(\"Specialized packages not loaded: \", paste(specialized_packages[!loaded_specialized], collapse = \", \"))\n}\n\n\n\n\n2.1.2 Helper Functions\nThese functions convert between compositional data and isometric log-ratio (ilr) coordinates.\n\n\nCode\ncomp_to_ilr &lt;- function(x_min) {\n  stopifnot(is.matrix(x_min), ncol(x_min) == 3)\n  bad_row &lt;- !is.finite(rowSums(x_min)) | rowSums(x_min) &lt;= 0\n  if (any(bad_row)) {\n    x_min[bad_row, ] &lt;- matrix(rep(c(600, 480, 360), each = sum(bad_row)), ncol = 3, byrow = TRUE)\n  }\n  x_min[x_min &lt;= 0 | !is.finite(x_min)] &lt;- 1e-6\n  compositions::ilr(sweep(x_min, 1, rowSums(x_min), \"/\"))\n}\n\nilr_to_minutes &lt;- function(ilr_mat, total = 1440) {\n  stopifnot(is.matrix(ilr_mat), ncol(ilr_mat) == 2)\n  comp_obj &lt;- compositions::ilrInv(ilr_mat)\n  prop &lt;- as.data.frame(comp_obj)\n  prop &lt;- as.matrix(prop)\n  \n  bad &lt;- apply(prop, 1, function(r) any(!is.finite(r) | r &lt;= 0) ||\n                                   !is.finite(sum(r)) || abs(sum(r) - 1) &gt; 1e-8)\n  if (any(bad)) prop[bad, ] &lt;- 1/3\n  round(prop * total, 1)\n}",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>H1 - Effect of Abstention on Sendentary Activity</span>"
    ]
  },
  {
    "objectID": "scripts/sim_comp_report.html#power-analysis",
    "href": "scripts/sim_comp_report.html#power-analysis",
    "title": "2  H1 - Effect of Abstention on Sendentary Activity",
    "section": "2.4 Power analysis",
    "text": "2.4 Power analysis\n\n\nCode\n# Load the results from the SimEngine power analysis\nload(\"scripts/sim_comp_debug/power_sim_results_20250906_224427.RData\")\n\n# Get the power summary data frame\npower_results_multi &lt;- result$power_summary\n\n# Filter rows where all columns starting with \"valid\" have values &gt;= 0.95\nvalid_cols &lt;- grep(\"^valid\", names(power_results_multi), value = TRUE)\npower_results_multi &lt;- power_results_multi %&gt;%\n  filter(if_all(all_of(valid_cols), ~ .x &gt;= 0.95))\n\n# Add a factor for effect size for better plotting\npower_results_multi$effect_min_factor &lt;- factor(\n  power_results_multi$effect_min,\n  levels = unique(power_results_multi$effect_min),\n  labels = paste0(unique(power_results_multi$effect_min), \" min\")\n)\n\n# Convert from wide to long format to plot all power metrics\npower_results_long &lt;- power_results_multi %&gt;%\n  pivot_longer(\n    cols = c(\"power_interaction\", \"power_protocol_robust\"),\n    names_to = \"power_type\",\n    values_to = \"power\"\n  ) %&gt;%\n  mutate(\n    power_type = factor(\n      power_type,\n      levels = c(\"power_interaction\", \"power_protocol_robust\"),\n      labels = c(\"Intention to Treat Effect\", \"Per-Protocol (Robust)\")\n    )\n  )\n\n# Create a faceted plot showing all power curves\nggplot(power_results_long, \n       aes(x = s_within, y = power, \n           color = effect_min_factor,\n           alpha = factor(s_between),\n           group = interaction(effect_min_factor, s_between))) +\n  geom_line(size = 1.2) +\n  geom_point(size = 1.5) +\n  facet_wrap(~ power_type, ncol = 2) +\n  labs(title = \"Power Curves by Effect Size and Variability Parameters\",\n       subtitle = \"Each line represents a unique Effect Size × Between-subject SD combination\",\n       x = \"Within-subject SD\", \n       y = \"Statistical Power\",\n       color = \"Effect Size\",\n       alpha = \"Between-subject SD\") +\n  theme_minimal() +\n  geom_hline(yintercept = 0.8, linetype = \"dashed\", color = \"red\", alpha = 0.7) +\n  scale_y_continuous(limits = c(0, 1), breaks = seq(0, 1, 0.2)) +\n  scale_x_reverse() +\n  scale_alpha_discrete(range = c(0.4, 1.0)) +\n  theme(legend.position = \"bottom\") +\n  guides(\n    color = guide_legend(title = \"Effect Size\", nrow = 1, order = 1),\n    alpha = guide_legend(title = \"Between-subject SD\", nrow = 1, order = 2)\n  )\n\n\n\n\n\n\n\n\n\nCode\n# Create a condensed comparison plot focusing on highest within-subject SD\nhighest_s_within &lt;- max(power_results_long$s_within)\npower_results_highest_sd &lt;- power_results_long %&gt;%\n  filter(s_within == highest_s_within)\n\n# Calculate summary statistics across between-subject SD values for ribbon\npower_summary_ribbon &lt;- power_results_highest_sd %&gt;%\n  group_by(effect_min, power_type) %&gt;%\n  summarise(\n    mean_power = mean(power, na.rm = TRUE),\n    min_power = min(power, na.rm = TRUE),\n    max_power = max(power, na.rm = TRUE),\n    .groups = \"drop\"\n  )\n\nggplot(power_summary_ribbon, \n       aes(x = effect_min, y = mean_power, \n           color = power_type,\n           fill = power_type,\n           linetype = power_type)) +\n  geom_ribbon(aes(ymin = min_power, ymax = max_power), alpha = 0.2, color = NA) +\n  geom_line(size = 1.2) +\n  geom_point(size = 2) +\n  labs(title = paste(\"Comparison of Power by Effect Type (Highest Within-Subject SD =\", highest_s_within, \")\"),\n       subtitle = \"Lines show mean power; ribbons show range across Between-subject SD values\",\n       x = \"Effect Size (minutes)\", \n       y = \"Statistical Power\",\n       color = \"Effect Type\",\n       fill = \"Effect Type\",\n       linetype = \"Effect Type\") +\n  theme_minimal() +\n  geom_hline(yintercept = 0.8, linetype = \"dashed\", color = \"black\") +\n  scale_y_continuous(limits = c(0, 1), breaks = seq(0, 1, 0.2))\n\n\n\n\n\n\n\n\n\nCode\npower_protocol_robust_heatmap &lt;- power_results_multi %&gt;%\n  ggplot(aes(x = s_within, y = s_between, fill = power_protocol_robust)) +\n  geom_tile() +\n  facet_wrap(~ effect_min_factor) +\n  scale_fill_viridis_c(limits = c(0, 1), breaks = seq(0, 1, 0.2)) +\n  labs(title = \"Power Heatmap for Per-Protocol Effect (Robust)\",\n       x = \"Within-subject SD\",\n       y = \"Between-subject SD\",\n       fill = \"Power\") +\n  theme_minimal() +\n  theme(legend.position = \"right\")\n\n# Display the heatmap\npower_protocol_robust_heatmap\n\n\n\n\n\n\n\n\n\nCode\n# Create a heatmap visualization showing power for different parameter combinations\n# Focus on the interaction effect as it's typically the primary outcome\npower_interaction_heatmap &lt;- power_results_multi %&gt;%\n  ggplot(aes(x = s_within, y = s_between, fill = power_interaction)) +\n  geom_tile() +\n  facet_wrap(~ effect_min_factor) +\n  scale_fill_viridis_c(limits = c(0, 1), breaks = seq(0, 1, 0.2)) +\n  labs(title = \"Power Heatmap for Intention to Treat Effect\",\n       x = \"Within-subject SD\",\n       y = \"Between-subject SD\",\n       fill = \"Power\") +\n  theme_minimal() +\n  theme(legend.position = \"right\")\n\n# Display the heatmap\npower_interaction_heatmap\n\n\n\n\n\n\n\n\n\nCode\n# Create a table summarizing the minimum effect size needed for 80% power\n# under different variability conditions\npower_threshold &lt;- 0.8\npower_summary_table &lt;- power_results_multi %&gt;%\n  group_by(s_between, s_within) %&gt;%\n  summarize(\n    min_effect_for_interaction = min(effect_min[power_interaction &gt;= power_threshold], na.rm = TRUE),\n    min_effect_for_protocol_change = min(effect_min[power_protocol_change &gt;= power_threshold], na.rm = TRUE),\n    min_effect_for_protocol_robust = min(effect_min[power_protocol_robust &gt;= power_threshold], na.rm = TRUE),\n    .groups = \"drop\"\n  )\n\n# Display the summary table\nlibrary(DT)\n\ndatatable(\n  power_summary_table,\n  colnames = c(\n    \"Between-subject SD\", \"Within-subject SD\", \n    \"Min Effect for 80% Int to Treat Power (min)\", \n    \"Min Effect for 80% Protocol Power (Change) (min)\",\n    \"Min Effect for 80% Protocol Power (Robust) (min)\"\n  ),\n  caption = \"Minimum effect size needed for 80% power under different variability conditions\",\n  options = list(\n    pageLength = 10,\n    autoWidth = TRUE,\n    searching = TRUE,\n    ordering = TRUE\n  )\n)",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>H1 - Effect of Abstention on Sendentary Activity</span>"
    ]
  },
  {
    "objectID": "scripts/sim_sleepquality_report.html",
    "href": "scripts/sim_sleepquality_report.html",
    "title": "3  H2 - Effect of Abstention on Sleep Quality",
    "section": "",
    "text": "3.1 Introduction\nThis document demonstrates a complete workflow for generating synthetic data, introducing dropout, and fitting models (a GAM or MLM) to the data. The main focus is on the sim_study function, which orchestrates the data simulation, dropout process, and model fitting.\nAs an overview, we compare the following possible models for estimating the effect of gaming reduction, for both H2a (the intention-to-treat effect) and H2b (the per-protocol effect; i.e., the effect of actual gaming reduction relative to one’s own baseline). For the per-protocol effect, we compare two approaches: a traditional change score approach and a robust approach that avoids potential issues with change scores by directly modeling the relationship between current playtime and outcomes while controlling for baseline differences. The models we compare are:",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>H2 - Effect of Abstention on Sleep Quality</span>"
    ]
  },
  {
    "objectID": "scripts/sim_sleepquality_report.html#introduction",
    "href": "scripts/sim_sleepquality_report.html#introduction",
    "title": "3  H2 - Effect of Abstention on Sleep Quality",
    "section": "",
    "text": "ITT = Intention-to-treat; PP = per-protocol\n\n\n\n\n\n\n\n\nModel Name\nSyntax\nTarget Effect\nNotes\n\n\n\n\nGAM\ngam(sleep_quality ~ condition:intervention_period + age + gender + s(id, bs = \"re\") + s(day, by = condition, bs = \"tp\"), correlation = corAR1(form = ~ day | id))\nITT\n\n\n\nGAM with no main effect\ngam(sleep_quality ~         age + gender +         s(id, bs = \"re\") +         s(day, by = condition, bs = \"tp\"),       data = dat,       correlation = corCAR1(form = ~ day | id))\nITT\nHere we do not estimate a parameter for the effect of the intervention directly; rather, we simply fit separate curves to each condition and calculate the average marginal effect using {emmeans}\n\n\nMLM\nlme(     fixed = sleep_quality ~ condition*intervention_period + age + gender,     random = ~ 1|id,     correlation = corCAR1(form = ~ day | id),     method = \"ML\"   )\nITT\nMultiple versions of this model failed when including random slopes; we therefore dropped these\n\n\nMLM Simple\nlme(     fixed = sleep_quality ~ baseline + condition + age + gender,     random = ~ 1 + condition|id,     correlation = corCAR1(form = ~ day | id),     method = \"ML\",   )\nITT\nHere we do not model the baseline (pre-intervention period) itself—we model only the 14-day period when the intervention is active, using average sleep_quality during baseline as a covariate\n\n\nGLS (generalized least squares)\ngls(     sleep_quality ~ condition * intervention_period + age + gender,     correlation = corCAR1(form = ~ day | id),   )\nITT\n\n\n\nGLS Simple\ngls(     sleep_quality ~ condition + baseline + age + gender,     correlation = corAR1(form = ~ day | id),   )\nITT\n\n\n\nGLS Splines\ngls(     sleep_quality ~ ns(day, df = 4) * intervention_period * condition,     correlation = corCAR1(form = ~ day | id),     data = dat   )\nITT\nIn this version, we fit a GLS but allow non-linearity in the trajectory of sleep_quality using splines\n\n\nMLM Reduction\nlme(     fixed = sleep_quality ~ intervention_active*reduction + age + gender,     random = ~ 1 + intervention_active*reduction | id,     correlation = corCAR1(form = ~ day | id)   )\nPP\nHere we test our intended model for the per-protocol effect; reduction is the number of hours played relative to that person’s mean playtime at baseline\n\n\nMLM Reduction Robust\nlme(     fixed = sleep_quality ~ intervention_active*playtime + baseline_playtime + age + gender,     random = ~ 1 | id,     correlation = corCAR1(form = ~ day | id)   )\nPP\nRobust approach without change scores - tests if intervention effect varies by actual playtime levels, controlling for baseline playtime\n\n\n\n\n3.1.1 Take-aways\nOur simulations show that several models perform well at parameter recovery for the ITT effect, but that the GAM model has the highest power for small effects—the type of effects we believe we are most likely to observed—and for non-linear trajectories over the 14 day period (e.g., an effect that slowly accumulates over a couple of days and then plateaus, or a temporary withdrawal followed by a later improvement). The GAM has approximately 50% power for a standardized effect of .2, and 80% power for a standardized effect of .3, but this varies based the shape of that effect over time.\nThe MLM Reduction model performs very well, and has &gt;95% power for standardized effects of approximately .2 or greater. The MLM Reduction Robust model provides an alternative approach that avoids potential issues with change scores by directly modeling the relationship between current playtime and outcomes while controlling for baseline differences.\n\n\n3.1.2 Load Libraries\nFirst we load packages with pacman, which is fully compatible with renv.\n\n\nShow code (load libraries)\nlibrary(pacman)\n\np_load(tidyverse, qualtRics, lme4, mgcv, marginaleffects, broom, forestplot, broom.mixed, nlme, rms, emmeans, splines, furrr, extraDistr, kableExtra)\n\n# Replace your current plan() line with:\nif (interactive()) {\n  plan(multisession, workers = parallel::detectCores()-8)\n} else {\n  plan(multisession, workers = parallel::detectCores()-8)\n}\n# Diagnostic information about parallel setup\n\nmessage(\"=== PARALLEL PROCESSING SETUP ===\")\nmessage(\"Total CPU cores detected: \", parallel::detectCores())\nmessage(\"Number of workers allocated: \", nbrOfWorkers())\nmessage(\"Future plan: \", paste(class(plan()), collapse = \", \"))\nmessage(\"===================================\")\n\ntheme_set(theme_minimal())\ntheme_update(\n  strip.background = element_rect(fill = \"black\"),\n  strip.text = element_text(color = \"white\", size = 10),\n  panel.grid.minor = element_blank(),\n  panel.border = element_rect(colour = \"black\", fill = NA, linewidth = 1),\n)\n\noptions(scipen = 999)\n\n\n\n\n3.1.3 Simulation, Dropout, and Fitting Functions\nHere we define:\n\nsim_data: Generates synthetic data with random intercepts/slopes and AR(1) errors.\nsim_dropout: Introduces missingness and dropout in the dataset.\nfit_*: Fits a statistical model to the simulated data (see table above)\nsim_study: Ties everything together—generates data, applies dropout, then fits the chosen model and returns a tidy summary.\n\n\n\nShow code (sim functions)\n#' Generate Synthetic Data\n#'\n#' This function simulates synthetic panel data for `n` participants over `n_days` time points,\n#' with an intervention effect, random intercepts and slopes, and AR(1)-correlated residuals.\n#'\n#' @param n Number of participants. Default is 80.\n#' @param n_days Number of time points per participant.\n#' @param b Fixed effect of condition (if mediated == FALSE) or a 1-hour reduction in playtime.\n#' @param phi AR(1) autocorrelation coefficient.\n#' @param sigma AR(1) residual standard deviation.\n\nsim_data &lt;- function(n = 80,\n                     n_days = 28,\n                     \n                     # effect parameters\n                     b = 0.8, # effect in unstandardized units (scaled for 5-25 range)\n                     mu = 15, # grand mean of the outcome (center of 5-25 range)\n                     \n                     \n                     # random effects parameters\n                     tau_int = 2.5,   # Random intercept SD (between-person variance)\n                     tau_slope = .05,  # Random slope SD \n                     within_person_sd = 2.0, # Within-person SD (scaled for 5-25 range)\n                     \n                     # AR(1) parameters\n                     phi = 0.8,     # Autocorrelation coefficient\n                     effect_shape = \"grow\",\n                     k = .5, # affects how quickly the plateau effect plateaus\n                     \n                     mediated = FALSE,\n                     \n                     # playtime parameters\n                     playtime_grand_mean = 1,   # Average baseline playtime in hours\n                     playtime_grand_sd = .5,   # SD for baseline playtime in log units (log-normal distribution)\n                     daily_play_sd = 0.5      # Daily noise in playtime\n                     # compliance_mean = 0.7,    # Average reduction (in hours) for intervention group during intervention period\n)     \n{\n  dat &lt;- tibble(\n    id = 1:n,\n    age = sample(18:36, n, replace = TRUE),\n    gender = sample(c(\"man\",\"woman\",\"non-binary\"), n, prob = c(.45, .45, .1), replace = TRUE),\n    condition = factor(sample(c(\"control\", \"intervention\"), n, replace = TRUE)),\n    experimental_condition = ifelse(condition == \"intervention\", 1, 0),\n    intercept_sq = rnorm(n, 0, tau_int), # Renamed from intercept_wb\n    slope_sq = rnorm(n, 0, tau_slope), # Renamed from slope_wb\n    intercept_play = rlnorm(n, log(playtime_grand_mean), playtime_grand_sd),\n  ) |&gt; \n    # expand to 28 waves per id\n    crossing(\n      day = 1:n_days\n    ) |&gt; \n    mutate(\n      intervention_period = as.numeric(day &gt; 7 & day &lt; 22),\n      intervention_active = intervention_period & condition == \"intervention\",\n      compliance = ifelse(intervention_active, rkumar(n*n_days, a = .05, b = .1), 0),\n      \n      # In the baseline period, play is just the subject's baseline plus some day-to-day noise\n      # During the intervention, experimental subjects reduce play by their compliance amount\n      playtime = (1 - compliance) * rlnorm(n, log(intercept_play), daily_play_sd),\n      effect_time = case_when(\n        effect_shape == \"plateau\" ~ if_else(intervention_period == 1, (b + slope_sq) * (1-exp(-k * (day - 7))), 0), # Renamed from slope_wb\n        effect_shape == \"grow\" ~ if_else(intervention_period == 1, (day - 7) * ((b + slope_sq)/7), 0), # Renamed from slope_wb\n        TRUE ~ NA_real_\n      ),\n    ) |&gt; \n    group_by(id) |&gt; \n    mutate(\n      \n      baseline_playtime = mean(playtime[day &lt;= 7]),\n      reduction = baseline_playtime - playtime, # The mediator: reduction in play relative to the baseline average\n      sigma = within_person_sd * sqrt(1-phi^2),\n      # Generate AR(1) errors for each participant\n      e = as.numeric(arima.sim(n = n_days, \n                               model = list(ar = phi), \n                               sd = sigma)),\n      # Add random effect + fixed effect + AR(1) error\n      sleep_quality_raw = case_when( # Renamed from wellbeing\n        mediated == TRUE ~ mu + \n                            intercept_sq + # Renamed from intercept_wb\n                            effect_time * reduction + \n                            .01*(age-18) +\n                            -.05*(gender %in% c(\"women\",\"non-binary\")) + \n                            e,\n        mediated == FALSE ~ mu + \n                            intercept_sq + # Renamed from intercept_wb\n                            effect_time * experimental_condition * intervention_period + \n                            .01*(age-18) +\n                            -.05*(gender %in% c(\"women\",\"non-binary\")) + \n                            e\n      ),\n      # Constrain to 5-25 range and round to integers\n      sleep_quality = round(pmax(5, pmin(25, sleep_quality_raw)))\n    ) |&gt; \n    ungroup() |&gt; \n    mutate(across(where(is.numeric), ~ round(., 3)))\n  \n  dat\n\n}\n\n\n\n\nShow code (sim data example)\nsim_data(n = 10, n_days = 10, effect_shape = \"grow\")\n\n\n# A tibble: 100 × 20\n      id   age gender condition    experimental_condition intercept_sq slope_sq\n   &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;  &lt;fct&gt;                         &lt;dbl&gt;        &lt;dbl&gt;    &lt;dbl&gt;\n 1     1    19 woman  intervention                      1        0.549    0.011\n 2     1    19 woman  intervention                      1        0.549    0.011\n 3     1    19 woman  intervention                      1        0.549    0.011\n 4     1    19 woman  intervention                      1        0.549    0.011\n 5     1    19 woman  intervention                      1        0.549    0.011\n 6     1    19 woman  intervention                      1        0.549    0.011\n 7     1    19 woman  intervention                      1        0.549    0.011\n 8     1    19 woman  intervention                      1        0.549    0.011\n 9     1    19 woman  intervention                      1        0.549    0.011\n10     1    19 woman  intervention                      1        0.549    0.011\n# ℹ 90 more rows\n# ℹ 13 more variables: intercept_play &lt;dbl&gt;, day &lt;dbl&gt;,\n#   intervention_period &lt;dbl&gt;, intervention_active &lt;lgl&gt;, compliance &lt;dbl&gt;,\n#   playtime &lt;dbl&gt;, effect_time &lt;dbl&gt;, baseline_playtime &lt;dbl&gt;,\n#   reduction &lt;dbl&gt;, sigma &lt;dbl&gt;, e &lt;dbl&gt;, sleep_quality_raw &lt;dbl&gt;,\n#   sleep_quality &lt;dbl&gt;\n\n\nShow code (sim data example)\n#' Simulate Dropout\n#'\n#' Introduces missingness and dropout into a dataset by randomly assigning records as missing\n#' or dropped out. Once a participant is dropped out, all subsequent records become missing.\n#'\n#' @param dat A tibble generated by \\code{sim_data()}.\n#'\n#' @return A tibble of the same structure as \\code{dat}, but with some \\code{sleep_quality} values set to NA. # Renamed from wellbeing\n#'\nsim_dropout &lt;- function(dat) {\n  \n  dropout &lt;- dat |&gt; \n    mutate(\n      missing = sample(c(TRUE, FALSE), n(), replace = TRUE, prob = c(.10, .90)),\n      dropout = sample(c(TRUE, FALSE), n(), replace = TRUE, prob = c(.01, .99))\n    ) |&gt;\n    mutate(\n      missing = ifelse(cumsum(dropout) &gt; 0, TRUE, missing),\n      .by = id\n    ) |&gt;\n    arrange(as.integer(id), day) |&gt; \n    mutate(sleep_quality = ifelse(missing, NA, sleep_quality)) # Renamed from wellbeing\n  dropout\n}\n\n\n\n\nCode\n#' Fit a Generalized Additive Model (GAM)\n#'\n#' Fits a GAM model to the provided dataset using \\code{mgcv::gam}, including an AR(1)\n#' correlation structure and random intercept for each ID.\n#'\n#' @param dat A tibble of repeated-measures data (e.g., from \\code{sim_data()} and \\code{sim_dropout()}).\n#'\n#' @return An object of class \\code{gam}, which is the fitted GAM model.\n#'\n#' \nfit_gam &lt;- function(dat) {\n  \n  gam(sleep_quality ~ # Renamed from wellbeing\n        condition:intervention_period + age + gender +\n        s(id, bs = \"re\") + \n        s(day, by = condition, bs = \"tp\"), \n      data = dat,\n      correlation = corAR1(form = ~ day | id))\n}\n\nfit_gam_no_main &lt;- function(dat) {\n  \n  gam(sleep_quality ~ # Renamed from wellbeing\n        age + gender +\n        s(id, bs = \"re\") + \n        s(day, by = condition, bs = \"tp\"), \n      data = dat,\n      correlation = corCAR1(form = ~ day | id))\n}\n\n#' Fit a Multi-Level Model (MLM)\n#'\n#' Fits a linear mixed-effects model (LME) with random intercept for each ID using \\code{lme4::lmer}.\n#'\n#' @param dat A tibble of repeated-measures data (e.g., from \\code{sim_data()} and \\code{sim_dropout()}).\n#'\n#' @return An object of class \\code{lmerMod}, which is the fitted MLM model.\n#'\nfit_mlm &lt;- function(dat) {\n  # lmer(sleep_quality ~ condition*intervention_period + age + gender + (1|id), data = dat) # Renamed from wellbeing\n  lme(\n    fixed = sleep_quality ~ condition*intervention_period + age + gender, # Renamed from wellbeing\n    random = ~ 1|id,  # or use a more flexible structure if needed\n    correlation = corCAR1(form = ~ day | id),\n    method = \"ML\",\n    data = dat |&gt; filter(!is.na(sleep_quality)) # Renamed from wellbeing\n  )\n}\n\nfit_mlm_simple &lt;- function(dat) {\n  \n  tmp &lt;- dat |&gt; \n    group_by(id) |&gt; \n    # take the mean of days 1-7 \n    mutate(baseline = mean(sleep_quality[day &lt; 8], na.rm = TRUE)) |&gt; # Renamed from wellbeing\n    filter(intervention_period == 1) |&gt; \n    filter(!is.na(sleep_quality)) # Renamed from wellbeing\n  \n  lme(\n    fixed = sleep_quality ~ baseline + condition + age + gender, # Renamed from wellbeing\n    random = ~ 1|id,  # Only random intercept since condition is between-subjects\n    correlation = corCAR1(form = ~ day | id),\n    method = \"ML\",\n    data = tmp |&gt; filter(!is.na(sleep_quality)) # Renamed from wellbeing\n  )\n}\n\nfit_gls &lt;- function(dat) {\n  \n  gls(\n    sleep_quality ~ condition * intervention_period + age + gender, # Renamed from wellbeing\n    correlation = corCAR1(form = ~ day | id),\n    data = dat |&gt; filter(!is.na(sleep_quality)) # Renamed from wellbeing\n  )\n}\n\nfit_gls_simple &lt;- function(dat) {\n  \n  tmp &lt;- dat |&gt; \n    group_by(id) |&gt; \n    # take the mean of days 1-7 \n    mutate(baseline = mean(sleep_quality[day &lt; 8], na.rm = TRUE)) |&gt; # Renamed from wellbeing\n    filter(intervention_period == 1) |&gt; \n    filter(!is.na(sleep_quality)) # Renamed from wellbeing\n  \n  gls(\n    sleep_quality ~ condition + baseline + age + gender, # Renamed from wellbeing\n    correlation = corAR1(form = ~ day | id),\n    data = tmp\n  )\n}\n\nfit_gls_spline &lt;- function(dat) {\n  gls(\n    sleep_quality ~ ns(day, df = 4) * intervention_period * condition, # Renamed from wellbeing, corrected comma\n    correlation = corCAR1(form = ~ day | id),\n    data = dat\n  )\n}\n\nfit_mlm_reduction &lt;- function(dat) {\n  lme(\n    fixed = sleep_quality ~ intervention_active*reduction + age + gender, # Renamed from wellbeing\n    random = ~ 1 | id,  # Simplified to random intercept only\n    correlation = corCAR1(form = ~ day | id),\n    data = dat\n  )\n}\n\nfit_mlm_reduction_robust &lt;- function(dat) {\n  lme(\n    fixed = sleep_quality ~ intervention_active*playtime + baseline_playtime + age + gender, # Renamed from wellbeing\n    random = ~ 1 | id,  # Simplified to random intercept only\n    correlation = corCAR1(form = ~ day | id),\n    data = dat\n  )\n}\n\n# Helper function to extract the focal effect for GLS models\nextract_marginal_effect &lt;- function(mod, dat, focal_term = \"conditionintervention\") {\n  # Here we assume your GLS model is specified with condition*intervention_period\n  # and you want the effect of condition (e.g., intervention vs. control) during intervention.\n  # We create a reference grid that fixes intervention_period at 1.\n  rg &lt;- ref_grid(mod, data = dat, at = list(intervention_period = 1))\n  \n  # Obtain estimated marginal means for each condition.\n  emm &lt;- emmeans(rg, ~ condition)\n  \n  # Compute the pairwise contrast (e.g., intervention - control)\n  # Adjust names as needed. The contrast below returns a one-row summary.\n  contr &lt;- emmeans::contrast(emm, method = list(\"intervention - control\" = c(-1, 1)), adjust = \"none\")\n  contr_sum &lt;- summary(contr, infer = TRUE)\n  \n  # Construct a one-row data frame with consistent column names.\n  # If you have more than one contrast, you might need to filter for the one of interest.\n  df &lt;- data.frame(\n    term = focal_term,\n    estimate = contr_sum$estimate,\n    std.error = contr_sum$SE,\n    conf.low = contr_sum$lower.CL,\n    conf.high = contr_sum$upper.CL,\n    row.names = NULL\n  )\n  \n  return(df)\n}\n\n\n\n\nCode\n#' Simulation Study Orchestrator\n#'\n#' A higher-level function that ties together data simulation, dropout, and model fitting,\n#' returning a tidy summary of the fitted model parameters.\n#'\n#' @param model_function A function to fit the model. Defaults to \\code{fit_gam}.\n#' @param n Number of participants passed to \\code{sim_data()}. Uses sim_data default (80).\n#' @param n_days Number of time points per participant passed to \\code{sim_data()}. Default is 28.\n#' @param b Fixed effect for the intervention slope passed to \\code{sim_data()}. Default is 0.01.\n#' @param phi AR(1) autocorrelation coefficient passed to \\code{sim_data()}. Default is 0.7.\n#' @param sigma AR(1) residual standard deviation passed to \\code{sim_data()}. Default is 0.6.\n#'\n#' @return A data frame (tibble) of model estimates from \\code{broom::tidy(parametric = TRUE)}.\n#'\n\n# Updated simulation orchestrator that handles GLS models separately.\nsim_study &lt;- function(model = \"fit_gam\", focal_term = \"intervention_activeTRUE:reduction\", ...) {\n  args &lt;- list(...)\n  dat &lt;- do.call(sim_data, args)\n  model_function &lt;- get(model)\n  \n  mod &lt;- model_function(dat)\n  \n  if (model %in% c(\"fit_gam_no_main\",\"fit_gls_spline\")) {\n    # Extract the effect using our helper function.\n    result &lt;- suppressMessages(extract_marginal_effect(mod, \n                                                       dat, \n                                                       focal_term = focal_term))\n  } else {\n    # For models that work with broom, extract the focal parameter.\n    # Adjust the filtering term as needed.\n    result &lt;- broom::tidy(mod, parametric = TRUE) |&gt;\n      filter(term == focal_term) |&gt; \n      # filter(\n      #   term == \"conditionintervention:intervention_period\" | \n      #     (model %in% c(\"fit_mlm_simple\",\"fit_gls_simple\") & term == \"conditionintervention\")\n      # ) |&gt; \n      mutate(\n        conf.low = estimate - 1.96 * std.error,\n        conf.high = estimate + 1.96 * std.error\n      )\n  }\n  result\n}",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>H2 - Effect of Abstention on Sleep Quality</span>"
    ]
  },
  {
    "objectID": "scripts/sim_sleepquality_report.html#test-and-plot-one-simulated-study",
    "href": "scripts/sim_sleepquality_report.html#test-and-plot-one-simulated-study",
    "title": "3  H2 - Effect of Abstention on Sleep Quality",
    "section": "3.2 Test and Plot One Simulated Study",
    "text": "3.2 Test and Plot One Simulated Study\nBelow, we create a sample dataset using sim_data() and examine it with a line plots by day. We can also see whether the simulated SDs for wellbeing align with the target values in the simulation—luckily, they do.\n\n\nShow code (descriptive plotting)\ndat &lt;- sim_data(effect_shape = \"plateau\", mediated = TRUE)\n\nsds &lt;- dat |&gt; \n  group_by(id) |&gt; \n  summarise(mean_value = mean(sleep_quality, na.rm = TRUE), # Renamed from wellbeing\n            sd_within  = sd(sleep_quality, na.rm = TRUE)) |&gt; # Renamed from wellbeing\n  summarise(between_sd   = sd(mean_value, na.rm = TRUE),\n            avg_within_sd = mean(sd_within, na.rm = TRUE))\n\n# plot sleep_quality by group\ndat |&gt; \n  group_by(condition, day) |&gt; \n  summarise(sleep_quality = mean(sleep_quality)) |&gt; # Renamed from wellbeing\n  ggplot(aes(y = sleep_quality, x = day, color = condition)) + # Renamed from wellbeing\n  geom_line() + \n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n3.2.1 Test Fit (h2a - intention to treat)\nWe fit various models to the newly simulated data to make sure each appears to be working properly, and also test the full sim_study pipeline.\n\n\nShow code (test fit h2a)\ndat &lt;- sim_data(mediated = FALSE)\n\nfit_mlm(dat) |&gt; summary()\nfit_mlm_simple(dat) |&gt; summary()\nfit_gls(dat) |&gt; summary()\nfit_gls_simple(dat) |&gt; summary()\nfit_gls_spline(dat) |&gt; extract_marginal_effect()\nfit_gam(dat) |&gt; summary()\nfit_gam_no_main(dat) |&gt; extract_marginal_effect()\n\nsim_study(model = \"fit_gam_no_main\")\nsim_study(model = \"fit_gls_spline\")\n\n\nSince some models (e.g., fit_gam_no_main) do not have a parameter that represents the average difference-in-difference between groups during the intervention period, we need to calculate this ourselves by marginalize across the 14-day intervention period.\n\n\nShow code (test emmeans)\nemm_day &lt;- emmeans(\n  fit_gls_spline(dat), \n  pairwise ~ condition | day, \n  at = list(day = 8:21), \n  condition = c(\"control\", \"intervention\"), \n  data = dat |&gt; mutate(condition = factor(condition, levels = c(\"intervention\", \"control\")))\n)\n\nsummary(emm_day$contrasts, infer = TRUE, level = .95, by = NULL, adjust = \"none\")\n\n# and then integrated over the 14 day intervention period\nrg &lt;- ref_grid(fit_gls_spline(dat),\n               at = list(intervention_period = 1),\n               cov.reduce = list(day = mean),\n               data = dat |&gt; mutate(condition = factor(condition, levels = c(\"control\",\"intervention\"))))\n\nemm &lt;- emmeans(rg, ~ condition)\n(contrast_result &lt;- contrast(emm, method = list(\"intervention - control\" = c(-1, 1)), adjust = \"none\"))\n\n\nmeans &lt;- summary(emm)$emmean\nnames(means) &lt;- summary(emm)$condition\n(diff_manual &lt;- means[\"intervention\"] - means[\"control\"])\n\n\n\n\n3.2.2 Test Fit (h2b - per-protocol)\nAnother quick test of our fit_mlm_reduction model, to make sure the alternative simulation whereby the effect of the intervention is mediated by a reduction in playtime is also functioning properly.\n\n\nShow code (test fit h2b)\ndat &lt;- sim_data(mediated = TRUE)\n\nfit_mlm_reduction(dat) |&gt; summary()\nfit_mlm_reduction_robust(dat) |&gt; summary()",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>H2 - Effect of Abstention on Sleep Quality</span>"
    ]
  },
  {
    "objectID": "scripts/sim_sleepquality_report.html#simulated-h2a-power-analysis",
    "href": "scripts/sim_sleepquality_report.html#simulated-h2a-power-analysis",
    "title": "3  H2 - Effect of Abstention on Sleep Quality",
    "section": "3.3 Simulated h2a power analysis",
    "text": "3.3 Simulated h2a power analysis\nTo assess power/sensitivity, we run multiple simulations (controlled by n_sims) and gather the parameter estimates for a particular term (e.g., conditionintervention:intervention_periodTRUE, or for our marginalized effect conditionintervention). Each iteration calls sim_study, which does the data generation, dropout, and fitting.\nAs this is quite slow, we both use parallel processing with furrr cache the results.\n\n\nCode\n#' Simulation Study Orchestrator\n#'\n#' A higher-level function that ties together data simulation, dropout, and model fitting,\n#' returning a tidy summary of the fitted model parameters.\n#'\n#' @param model_function A function to fit the model. Defaults to \\code{fit_gam}.\n#' @param n Number of participants passed to \\code{sim_data()}. Uses sim_data default (80).\n#' @param n_days Number of time points per participant passed to \\code{sim_data()}. Default is 28.\n#' @param b Fixed effect for the intervention slope passed to \\code{sim_data()}. Default is 0.01.\n#' @param phi AR(1) autocorrelation coefficient passed to \\code{sim_data()}. Default is 0.7.\n#' @param sigma AR(1) residual standard deviation passed to \\code{sim_data()}. Default is 0.6.\n#'\n#' @return A data frame (tibble) of model estimates from \\code{broom::tidy(parametric = TRUE)}.\n#'\n\n# Updated simulation orchestrator that handles GLS models separately.\nsim_study &lt;- function(model = \"fit_gam\", focal_term = \"intervention_activeTRUE:reduction\", ...) {\n  args &lt;- list(...)\n  dat &lt;- do.call(sim_data, args)\n  model_function &lt;- get(model)\n  \n  mod &lt;- model_function(dat)\n  \n  if (model %in% c(\"fit_gam_no_main\",\"fit_gls_spline\")) {\n    # Extract the effect using our helper function.\n    result &lt;- suppressMessages(extract_marginal_effect(mod, \n                                                       dat, \n                                                       focal_term = focal_term))\n  } else {\n    # For models that work with broom, extract the focal parameter.\n    # Adjust the filtering term as needed.\n    result &lt;- broom::tidy(mod, parametric = TRUE) |&gt;\n      filter(term == focal_term) |&gt; \n      # filter(\n      #   term == \"conditionintervention:intervention_period\" | \n      #     (model %in% c(\"fit_mlm_simple\",\"fit_gls_simple\") & term == \"conditionintervention\")\n      # ) |&gt; \n      mutate(\n        conf.low = estimate - 1.96 * std.error,\n        conf.high = estimate + 1.96 * std.error\n      )\n  }\n  result\n}\n\n# Load tictoc for timing if not already loaded\nif (!require(tictoc, quietly = TRUE)) {\n  install.packages(\"tictoc\")\n  library(tictoc)\n}\n\n# Check if cached results exist\ncache_file_h2a &lt;- \"cache/h2a_simulation_results.rds\"\ncache_summary_h2a &lt;- \"cache/h2a_simulation_summary.rds\"\ncache_params_h2a &lt;- \"cache/h2a_simulation_params.rds\"\n\n# Define key parameters that would invalidate cache\ncurrent_params_h2a &lt;- list(\n  n_sims = 500,\n  n = 80,\n  n_days = 28,\n  tau_int = 2.5,\n  tau_slope = 0.8,\n  within_person_sd = 2.5,\n  phi = 0.7,\n  models = c(\"fit_gam\", \"fit_gam_no_main\", \"fit_mlm\", \"fit_mlm_simple\", \"fit_gls\", \"fit_gls_simple\", \"fit_gls_spline\"),\n  effect_values = c(0.3, 0.6, 0.9, 1.2, 1.5),\n  effect_shapes = c(\"grow\", \"plateau\"),\n  mediated = FALSE\n)\n\n# -------------------------------------------------------------------\n# Prepare job specifications irrespective of cache status\n# This ensures that variables such as `specs_h2a`, `all_jobs_h2a`, and\n# related helpers are available even when we load results from cache,\n# avoiding downstream errors (e.g., `all_jobs_h2a` not found).\nn_sims &lt;- current_params_h2a$n_sims\n\nspecs_h2a &lt;- expand_grid(\n  model = current_params_h2a$models,\n  b = current_params_h2a$effect_values,\n  effect_shape = current_params_h2a$effect_shapes\n) |&gt;\n  mutate(\n    focal_term = case_when(\n      model %in% c(\"fit_mlm_simple\",\"fit_gls_simple\", \"fit_gam_no_main\") ~ \"conditionintervention\",\n      model %in% c(\"fit_gam\", \"fit_mlm\", \"fit_gls\", \"fit_gls_spline\") ~ \"conditionintervention:intervention_period\",\n      TRUE ~ \"conditionintervention:intervention_period\"\n    )\n  ) |&gt;\n  (function(d) { d$row_id &lt;- pmap_chr(d, ~ paste0(names(list(...)), \"=\", c(...), collapse = \"_\")); d })() |&gt;\n  mutate(i = row_number())\n\nall_jobs_h2a &lt;- specs_h2a |&gt;\n  crossing(sim = 1:n_sims) |&gt;\n  mutate(job_id = row_number())\n\n# Helper objects for progress tracking & reporting\ntotal_jobs_h2a &lt;- nrow(all_jobs_h2a)\nprogress_checkpoints_h2a &lt;- seq(from = round(total_jobs_h2a * 0.1),\n                                  to   = total_jobs_h2a,\n                                  by   = round(total_jobs_h2a * 0.1))\n\n# Check if cache exists and parameters match\ncache_valid_h2a &lt;- FALSE\nif (file.exists(cache_file_h2a) && file.exists(cache_summary_h2a) && file.exists(cache_params_h2a)) {\n  cached_params_h2a &lt;- readRDS(cache_params_h2a)\n  cache_valid_h2a &lt;- identical(current_params_h2a, cached_params_h2a)\n}\n\nif (cache_valid_h2a) {\n  message(\"Loading cached H2a simulation results...\")\n  results_h2a &lt;- readRDS(cache_file_h2a)\n  sim_summary_h2a &lt;- readRDS(cache_summary_h2a)\n  message(\"Cached H2a results loaded successfully!\")\n} else {\n  message(\"No cached H2a results found or parameters changed. Running H2a simulations...\")\n  \n  # Create cache directory if it doesn't exist\n  if (!dir.exists(\"cache\")) {\n    dir.create(\"cache\", recursive = TRUE)\n  }\n\n  # Start timing\n  message(\"Starting H2a simulations at: \", Sys.time())\n  tic(\"H2a simulation total time\")\n\n  # n_sims is already defined above based on `current_params_h2a`\n\n# Create all spec-simulation combinations for better parallelization\n# all_jobs_h2a &lt;- specs_h2a |&gt; \n#   crossing(sim = 1:n_sims) |&gt; \n#   mutate(job_id = row_number())\n\nmessage(\"Running \", nrow(all_jobs_h2a), \" simulations across \", nbrOfWorkers(), \" cores...\")\n\n# Set up progress tracking\n# total_jobs_h2a &lt;- nrow(all_jobs_h2a)\n# progress_checkpoints_h2a &lt;- seq(from = round(total_jobs_h2a * 0.1), to = total_jobs_h2a, by = round(total_jobs_h2a * 0.1))\n\n# Run all simulations in parallel\nresults_h2a &lt;- future_map_dfr(1:nrow(all_jobs_h2a), function(job_idx) {\n  # Load required libraries in each worker\n  library(tidyverse)\n  library(lme4)\n  library(mgcv)\n  library(broom)\n  library(nlme)\n  library(emmeans)\n  library(splines)\n  library(broom.mixed)\n  library(extraDistr)\n  \n  # Get job parameters\n  job &lt;- all_jobs_h2a[job_idx, ]\n  \n  # Progress tracking\n  if (job_idx %in% progress_checkpoints_h2a) {\n    message(sprintf(\"H2a Progress: %d/%d (%.1f%%) completed at %s\", \n                    job_idx, total_jobs_h2a, (job_idx/total_jobs_h2a)*100, Sys.time()))\n  }\n  \n  tryCatch({\n    result &lt;- sim_study(\n      model = job$model,\n      focal_term = job$focal_term,\n      n = 80,\n      n_days = 28,\n      # effect parameters\n      b = job$b,\n      mu = 15,\n      effect_shape = job$effect_shape,\n      k = .5,\n      # random effects parameters\n      tau_int = 2.5,\n      tau_slope = .8,\n      within_person_sd = 2.5,\n      # AR(1) parameters\n      phi = 0.7\n    ) |&gt; \n      mutate(\n        sim = job$sim,\n        row_id = job$row_id,\n        model = job$model,\n        b = job$b,\n        effect_shape = job$effect_shape\n      )\n    \n    return(result)\n  }, error = function(e) {\n    message(\"Job \", job_idx, \" (spec row: \", job$i, \", sim: \", job$sim, \") failed: \", e$message)\n    tibble(\n      term = NA_character_,\n      estimate = NA_real_,\n      std.error = NA_real_,\n      conf.low = NA_real_,\n      conf.high = NA_real_,\n      sim = job$sim,\n      row_id = job$row_id,\n      model = job$model,\n      b = job$b,\n      effect_shape = job$effect_shape\n    )\n  })\n}, .progress = TRUE,\n.options = furrr_options(\n  globals = c(\"all_jobs_h2a\", \"sim_study\", \"sim_data\", \n              \"fit_gam\", \"fit_gam_no_main\",\n              \"fit_mlm\", \"fit_mlm_simple\",\n              \"fit_gls\", \"fit_gls_simple\",\n              \"fit_gls_spline\", \n              \"extract_marginal_effect\",\n              \"progress_checkpoints_h2a\", \"total_jobs_h2a\"),\n  seed = TRUE\n))\n\nsim_summary_h2a &lt;- results_h2a |&gt; \n  group_by(row_id) |&gt; \n  summarise(\n    model = first(model),\n    b = first(b),\n    effect_shape = first(effect_shape),\n    mean_effect = mean(estimate, na.rm = TRUE),\n    mean_se = mean(std.error, na.rm = TRUE),\n    mean_conf.low = mean(conf.low, na.rm = TRUE),\n    mean_conf.high = mean(conf.high, na.rm = TRUE),\n    power = sum(conf.low &gt; 0, na.rm = TRUE) / sum(!is.na(conf.low))\n  )\n\n# Stop timing and display results\nh2a_time &lt;- toc()\nmessage(\"H2a simulations completed at: \", Sys.time())\n\n# Save results to cache\nsaveRDS(results_h2a, cache_file_h2a)\nsaveRDS(sim_summary_h2a, cache_summary_h2a)\nsaveRDS(current_params_h2a, cache_params_h2a)\nmessage(\"H2a simulation results saved to cache!\")\n\n} # End of else block for cached results\n\n# Also print some summary statistics about the simulation\nmessage(\"=== SIMULATION SUMMARY ===\")\nmessage(\"Total number of jobs: \", nrow(all_jobs_h2a))\nmessage(\"Number of successful results: \", sum(!is.na(results_h2a$estimate)))\nmessage(\"Number of failed jobs: \", sum(is.na(results_h2a$estimate)))\nmessage(\"Success rate: \", round(100 * sum(!is.na(results_h2a$estimate)) / nrow(results_h2a), 1), \"%\")\nmessage(\"============================\")\n\n\n\n\nShow code (visualize power h2a)\n# Estimated effect vs. true effect (b)\nggplot(sim_summary_h2a, aes(x = b, y = mean_effect, color = model, alpha = model == \"fit_gam\")) +\n  geom_point(size = 3) +\n  geom_errorbar(aes(ymin = mean_conf.low, ymax = mean_conf.high), width = 0.1) +\n  facet_wrap(~ effect_shape) +\n  geom_abline(slope = 1, intercept = 0, linetype = \"dashed\", color = \"gray\") +\n  scale_alpha_manual(values = c(\"TRUE\" = 1.0, \"FALSE\" = 0.2), guide = \"none\") +\n  labs(x = \"True Effect (unstandardized b)\", y = \"Estimated Effect\",\n       title = \"Estimated vs. True Effects by Model and Effect Shape\") +\n  scale_x_continuous(breaks = c(0.3, 0.6, 0.9, 1.2, 1.5),\n                     sec.axis = sec_axis(~ . / 3, name = \"Standardized Effect (b/3)\"))\n\n\n\n\n\n\n\n\n\nShow code (visualize power h2a)\n# ggsave(\"figures/estimated_vs_true_effects.png\", width = 10, height = 6, dpi = 300)\n\n# Power vs. true effect (b)\nggplot(sim_summary_h2a, aes(x = b, y = power, color = model, alpha = model == \"fit_gam\")) +\n  geom_line(size = 1) +\n  geom_point(size = 3) +\n  facet_wrap(~ effect_shape) +\n  scale_alpha_manual(values = c(\"TRUE\" = 1.0, \"FALSE\" = 0.2), guide = \"none\") +\n  labs(x = \"True Effect (unstandardized b)\", y = \"Power\",\n       title = \"Power by Model and Effect Shape\") +\n  scale_x_continuous(breaks = c(0.3, 0.6, 0.9, 1.2, 1.5),\n                     sec.axis = sec_axis(~ . / 3, name = \"Standardized Effect (b/3)\")) +\n  scale_y_continuous(labels = scales::percent_format(accuracy = 1), limits = c(0, 1), breaks = seq(0, 1, .1))\n\n\n\n\n\n\n\n\n\nShow code (visualize power h2a)\n# ggsave(\"figures/power_by_model_and_effect_shape.png\", width = 10, height = 6, dpi = 300)\n\n# results |&gt;\n#   forestplot(mean = estimate,\n#              lower = conf.low,\n#              upper = conf.high,\n#              labeltext = term)\n\n### Minimum Detectable Effect Sizes at 80% Power\n\n\n\n\nShow code (minimum detectable effects table)\n# Function to interpolate minimum detectable effect at 80% power\nfind_mde_80 &lt;- function(power_data) {\n  # If we already have 80% power or higher at the smallest effect, return that\n  if (min(power_data$power, na.rm = TRUE) &gt;= 0.8) {\n    return(min(power_data$b, na.rm = TRUE))\n  }\n  \n  # If we never reach 80% power, return NA\n  if (max(power_data$power, na.rm = TRUE) &lt; 0.8) {\n    return(NA_real_)\n  }\n  \n  # Linear interpolation to find effect size at 80% power\n  approx(x = power_data$power, y = power_data$b, xout = 0.8)$y\n}\n\n# Calculate minimum detectable effects for each model and effect shape\nmde_table &lt;- sim_summary_h2a |&gt;\n  group_by(model, effect_shape) |&gt;\n  summarise(\n    mde_80_unstandardized = find_mde_80(cur_data()),\n    mde_80_standardized = mde_80_unstandardized / 3,  # Convert to standardized units (sleep quality range is ~20, so /3 approximates standardization)\n    max_power = max(power, na.rm = TRUE),\n    .groups = \"drop\"\n  ) |&gt;\n  arrange(effect_shape, mde_80_standardized) |&gt;\n  mutate(\n    # Clean up model names for presentation\n    model_clean = case_when(\n      model == \"fit_gam\" ~ \"GAM\",\n      model == \"fit_gam_no_main\" ~ \"GAM (no main effect)\",\n      model == \"fit_mlm\" ~ \"MLM\",\n      model == \"fit_mlm_simple\" ~ \"MLM Simple\",\n      model == \"fit_gls\" ~ \"GLS\",\n      model == \"fit_gls_simple\" ~ \"GLS Simple\", \n      model == \"fit_gls_spline\" ~ \"GLS Splines\",\n      TRUE ~ model\n    ),\n    # Format effect sizes for display\n    mde_80_unstandardized_fmt = ifelse(is.na(mde_80_unstandardized), \n                                     \"&gt;1.5\", \n                                     sprintf(\"%.1f\", mde_80_unstandardized)),\n    mde_80_standardized_fmt = ifelse(is.na(mde_80_standardized), \n                                   \"&gt;0.50\", \n                                   sprintf(\"%.2f\", mde_80_standardized)),\n    max_power_fmt = sprintf(\"%.1f%%\", max_power * 100)\n  )\n\n# Create formatted table\nmde_table |&gt;\n  select(\n    `Effect Shape` = effect_shape,\n    `Model` = model_clean,\n    `MDE (Unstandardized)` = mde_80_unstandardized_fmt,\n    `MDE (Standardized)` = mde_80_standardized_fmt,\n    `Max Power Achieved` = max_power_fmt\n  ) |&gt;\n  kable(\n    caption = \"Minimum Detectable Effect Sizes at 80% Power by Model and Effect Shape\",\n    align = c(\"l\", \"l\", \"r\", \"r\", \"r\")\n  ) |&gt;\n  kable_styling(\n    bootstrap_options = c(\"striped\", \"hover\", \"condensed\"),\n    full_width = FALSE,\n    position = \"left\"\n  ) |&gt;\n  pack_rows(\"Growing Effect\", 1, sum(mde_table$effect_shape == \"grow\")) |&gt;\n  pack_rows(\"Plateau Effect\", sum(mde_table$effect_shape == \"grow\") + 1, nrow(mde_table)) |&gt;\n  footnote(\n    general = c(\n      \"MDE = Minimum Detectable Effect size at 80% power\",\n      \"Standardized effects calculated as unstandardized effect / 3\",\n      \"Models ordered by sensitivity (smallest MDE first) within each effect shape\",\n      \"'&gt;1.5' and '&gt;0.50' indicate models that did not achieve 80% power at largest tested effect size\"\n    ),\n    general_title = \"Notes:\"\n  )\n\n\n\nMinimum Detectable Effect Sizes at 80% Power by Model and Effect Shape\n\n\nEffect Shape\nModel\nMDE (Unstandardized)\nMDE (Standardized)\nMax Power Achieved\n\n\n\n\nGrowing Effect\n\n\ngrow\nMLM\n0.8\n0.27\n100.0%\n\n\ngrow\nGLS\n0.8\n0.28\n100.0%\n\n\ngrow\nGAM\n1.1\n0.36\n87.2%\n\n\ngrow\nGLS Simple\n1.1\n0.37\n96.6%\n\n\ngrow\nMLM Simple\n1.2\n0.39\n96.2%\n\n\ngrow\nGAM (no main effect)\n1.4\n0.47\n82.6%\n\n\ngrow\nGLS Splines\n&gt;1.5\n&gt;0.50\n57.2%\n\n\nPlateau Effect\n\n\nplateau\nMLM\n1.1\n0.36\n95.8%\n\n\nplateau\nGAM (no main effect)\n1.2\n0.39\n90.2%\n\n\nplateau\nGLS\n1.2\n0.41\n93.2%\n\n\nplateau\nGAM\n1.2\n0.41\n87.4%\n\n\nplateau\nGLS Simple\n1.4\n0.46\n85.0%\n\n\nplateau\nMLM Simple\n1.4\n0.48\n83.4%\n\n\nplateau\nGLS Splines\n&gt;1.5\n&gt;0.50\n54.8%\n\n\n\nNotes:\n\n\n\n\n\n\n MDE = Minimum Detectable Effect size at 80% power\n\n\n\n\n\n\n Standardized effects calculated as unstandardized effect / 3\n\n\n\n\n\n\n Models ordered by sensitivity (smallest MDE first) within each effect shape\n\n\n\n\n\n\n '&gt;1.5' and '&gt;0.50' indicate models that did not achieve 80% power at largest tested effect size",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>H2 - Effect of Abstention on Sleep Quality</span>"
    ]
  },
  {
    "objectID": "scripts/sim_sleepquality_report.html#simulated-h2b-power-analysis",
    "href": "scripts/sim_sleepquality_report.html#simulated-h2b-power-analysis",
    "title": "3  H2 - Effect of Abstention on Sleep Quality",
    "section": "3.4 Simulated h2b power analysis",
    "text": "3.4 Simulated h2b power analysis\nSame thing as above, but now looking at power for our per-protocol model.\n\n\nCode\n#' Simulation Study Orchestrator\n#'\n#' A higher-level function that ties together data simulation, dropout, and model fitting,\n#' returning a tidy summary of the fitted model parameters.\n#'\n#' @param model_function A function to fit the model. Defaults to \\code{fit_gam}.\n#' @param n Number of participants passed to \\code{sim_data()}. Uses sim_data default (80).\n#' @param n_days Number of time points per participant passed to \\code{sim_data()}. Default is 28.\n#' @param b Fixed effect for the intervention slope passed to \\code{sim_data()}. Default is 0.01.\n#' @param phi AR(1) autocorrelation coefficient passed to \\code{sim_data()}. Default is 0.7.\n#' @param sigma AR(1) residual standard deviation passed to \\code{sim_data()}. Default is 0.6.\n#'\n#' @return A data frame (tibble) of model estimates from \\code{broom::tidy(parametric = TRUE)}.\n#'\n\n# Updated simulation orchestrator that handles GLS models separately.\nsim_study &lt;- function(model = \"fit_gam\", focal_term = \"intervention_activeTRUE:reduction\", ...) {\n  args &lt;- list(...)\n  dat &lt;- do.call(sim_data, args)\n  model_function &lt;- get(model)\n  \n  mod &lt;- model_function(dat)\n  \n  if (model %in% c(\"fit_gam_no_main\",\"fit_gls_spline\")) {\n    # Extract the effect using our helper function.\n    result &lt;- suppressMessages(extract_marginal_effect(mod, \n                                                       dat, \n                                                       focal_term = focal_term))\n  } else {\n    # For models that work with broom, extract the focal parameter.\n    # Adjust the filtering term as needed.\n    result &lt;- broom::tidy(mod, parametric = TRUE) |&gt;\n      filter(term == focal_term) |&gt; \n      # filter(\n      #   term == \"conditionintervention:intervention_period\" | \n      #     (model %in% c(\"fit_mlm_simple\",\"fit_gls_simple\") & term == \"conditionintervention\")\n      # ) |&gt; \n      mutate(\n        conf.low = estimate - 1.96 * std.error,\n        conf.high = estimate + 1.96 * std.error\n      )\n  }\n  result\n}\n\n# Load tictoc for timing if not already loaded\nif (!require(tictoc, quietly = TRUE)) {\n  install.packages(\"tictoc\")\n  library(tictoc)\n}\n\n# Check if cached results exist\ncache_file_h2b &lt;- \"cache/h2b_simulation_results.rds\"\ncache_summary_h2b &lt;- \"cache/h2b_simulation_summary.rds\"\ncache_params_h2b &lt;- \"cache/h2b_simulation_params.rds\"\n\n# Define key parameters that would invalidate cache\ncurrent_params_h2b &lt;- list(\n  n_sims = 500,\n  n = 80,\n  n_days = 28,\n  tau_int = 2.5,\n  tau_slope = 0.8,\n  within_person_sd = 2.0,\n  phi = 0.7,\n  models = c(\"fit_mlm_reduction\", \"fit_mlm_reduction_robust\"),\n  effect_values = c(0.5, 1.0, 1.5, 2.0, 2.5),\n  effect_shapes = c(\"grow\", \"plateau\"),\n  mediated = TRUE\n)\n\n# -------------------------------------------------------------------\n# Prepare job specifications irrespective of cache status\n# This guarantees objects like `specs_h2b`, `all_jobs_h2b`, etc. exist\n# even when cached results are loaded, preventing missing-object errors.\n\n  n_sims &lt;- current_params_h2b$n_sims\n\n  specs_h2b &lt;- expand_grid(\n    model = current_params_h2b$models,\n    b = current_params_h2b$effect_values,\n    effect_shape = current_params_h2b$effect_shapes\n  ) |&gt; \n    mutate(\n      # focal term depends on model\n      focal_term = case_when(\n        model == \"fit_mlm_reduction\" ~ \"intervention_activeTRUE:reduction\",\n        model == \"fit_mlm_reduction_robust\" ~ \"intervention_activeTRUE:playtime\"\n      ),\n      # expected mediated effect size (approximate)\n      expected_effect = b * .1*beta(1 + 1/.05, .1)\n    ) |&gt; \n    (function(d) { d$row_id &lt;- pmap_chr(d, ~ paste0(names(list(...)), \"=\", c(...), collapse = \"_\")); d })() |&gt; \n    mutate(i = row_number())\n\n  all_jobs_h2b &lt;- specs_h2b |&gt;\n    crossing(sim = 1:n_sims) |&gt;\n    mutate(job_id = row_number())\n\n  # Helper objects for progress\n  total_jobs_h2b &lt;- nrow(all_jobs_h2b)\n  progress_checkpoints_h2b &lt;- seq(from = round(total_jobs_h2b * 0.1),\n                                  to   = total_jobs_h2b,\n                                  by   = round(total_jobs_h2b * 0.1))\n\n# Check if cache exists and parameters match\ncache_valid_h2b &lt;- FALSE\nif (file.exists(cache_file_h2b) && file.exists(cache_summary_h2b) && file.exists(cache_params_h2b)) {\n  cached_params_h2b &lt;- readRDS(cache_params_h2b)\n  cache_valid_h2b &lt;- identical(current_params_h2b, cached_params_h2b)\n}\n\nif (cache_valid_h2b) {\n  message(\"Loading cached H2b simulation results...\")\n  results_h2b &lt;- readRDS(cache_file_h2b)\n  sim_summary_h2b &lt;- readRDS(cache_summary_h2b)\n  message(\"Cached H2b results loaded successfully!\")\n} else {\n  message(\"No cached H2b results found or parameters changed. Running H2b simulations...\")\n  \n  # Create cache directory if it doesn't exist\n  if (!dir.exists(\"cache\")) {\n    dir.create(\"cache\", recursive = TRUE)\n  }\n\n  # Start timing\n  message(\"Starting H2b simulations at: \", Sys.time())\n  tic(\"H2b simulation total time\")\n\n  # n_sims is already defined above based on `current_params_h2b`\n\n# Create all spec-simulation combinations for better parallelization\n# all_jobs_h2b &lt;- specs_h2b |&gt; \n#   crossing(sim = 1:n_sims) |&gt; \n#   mutate(job_id = row_number())\n\nmessage(\"Running \", nrow(all_jobs_h2b), \" simulations across \", nbrOfWorkers(), \" cores...\")\n\n# Set up progress tracking\n# total_jobs_h2b &lt;- nrow(all_jobs_h2b)\n# progress_checkpoints_h2b &lt;- seq(from = round(total_jobs_h2b * 0.1), to = total_jobs_h2b, by = round(total_jobs_h2b * 0.1))\n\n# Run all simulations in parallel\nresults_h2b &lt;- future_map_dfr(1:nrow(all_jobs_h2b), function(job_idx) {\n  # Load required libraries in each worker\n  library(tidyverse)\n  library(nlme)\n  library(broom.mixed)\n  library(extraDistr)\n  library(rms)\n  \n  # Get job parameters\n  job &lt;- all_jobs_h2b[job_idx, ]\n  \n  # Progress tracking\n  if (job_idx %in% progress_checkpoints_h2b) {\n    message(sprintf(\"H2b Progress: %d/%d (%.1f%%) completed at %s\", \n                    job_idx, total_jobs_h2b, (job_idx/total_jobs_h2b)*100, Sys.time()))\n  }\n  \n  tryCatch({\n    result &lt;- sim_study(\n      model = job$model,\n      focal_term = job$focal_term,\n      n = 80,\n      n_days = 28,\n      # effect parameters\n      b = job$b,\n      mu = 15,\n      effect_shape = job$effect_shape,\n      k = .5,\n      # random effects parameters\n      tau_int = 2.5,\n      tau_slope = .8,\n      within_person_sd = 2.0,\n      # AR(1) parameters\n      phi = 0.7,\n      mediated = TRUE\n    ) |&gt; \n      mutate(\n        sim = job$sim,\n        row_id = job$row_id,\n        model = job$model,\n        b = job$b,\n        expected_effect = job$expected_effect,\n        effect_shape = job$effect_shape\n      )\n    \n    return(result)\n  }, error = function(e) {\n    message(\"Job \", job_idx, \" (spec row: \", job$i, \", sim: \", job$sim, \") failed: \", e$message)\n    tibble(\n      term = NA_character_,\n      estimate = NA_real_,\n      std.error = NA_real_,\n      conf.low = NA_real_,\n      conf.high = NA_real_,\n      sim = job$sim,\n      row_id = job$row_id,\n      model = job$model,\n      b = job$b,\n      expected_effect = job$expected_effect,\n      effect_shape = job$effect_shape\n    )\n  })\n}, .progress = TRUE,\n.options = furrr_options(\n  globals = c(\"all_jobs_h2b\", \"sim_study\", \"sim_data\", \"fit_mlm_reduction\", \"fit_mlm_reduction_robust\",\n              \"progress_checkpoints_h2b\", \"total_jobs_h2b\", \"sim_dropout\",\n              \"fit_gam\", \"fit_gam_no_main\", \"fit_mlm\", \"fit_mlm_simple\", \n              \"fit_gls\", \"fit_gls_simple\", \"fit_gls_spline\", \"extract_marginal_effect\"),\n  seed = TRUE\n))\n\nsim_summary_h2b &lt;- results_h2b |&gt; \n  group_by(row_id) |&gt; \n  summarise(\n    model = first(model),\n    b = first(b),\n    expected_effect = first(expected_effect),\n    effect_shape = first(effect_shape),\n    mean_effect = mean(estimate, na.rm = TRUE),\n    mean_se = mean(std.error, na.rm = TRUE),\n    mean_conf.low = mean(conf.low, na.rm = TRUE),\n    mean_conf.high = mean(conf.high, na.rm = TRUE),\n    # Correct power calculation based on model type\n    power = if_else(\n      first(model) == \"fit_mlm_reduction_robust\",\n      sum(conf.high &lt; 0, na.rm = TRUE) / sum(!is.na(conf.high)),  # Robust expects negative\n      sum(conf.low &gt; 0, na.rm = TRUE) / sum(!is.na(conf.low))     # Change score expects positive\n    )\n  )\n\n# Stop timing and display results\nh2b_time &lt;- toc()\nmessage(\"H2b simulations completed at: \", Sys.time())\n\n# Save results to cache\nsaveRDS(results_h2b, cache_file_h2b)\nsaveRDS(sim_summary_h2b, cache_summary_h2b)\nsaveRDS(current_params_h2b, cache_params_h2b)\nmessage(\"H2b simulation results saved to cache!\")\n\n} # End of else block for cached results\n\n# Also print some summary statistics about the simulation\nmessage(\"=== H2B SIMULATION SUMMARY ===\")\nmessage(\"Total number of jobs: \", nrow(all_jobs_h2b))\nmessage(\"Number of successful results: \", sum(!is.na(results_h2b$estimate)))\nmessage(\"Number of failed jobs: \", sum(is.na(results_h2b$estimate)))\nmessage(\"Success rate: \", round(100 * sum(!is.na(results_h2b$estimate)) / nrow(results_h2b), 1), \"%\")\nmessage(\"===============================\")\n\n\n\n\nRecalculate H2b summary with corrected power\n# Recalculate summary with corrected power calculation\nif (exists(\"results_h2b\")) {\n  sim_summary_h2b &lt;- results_h2b |&gt; \n    group_by(row_id) |&gt; \n    summarise(\n      model = first(model),\n      b = first(b),\n      expected_effect = first(expected_effect),\n      effect_shape = first(effect_shape),\n      mean_effect = mean(estimate, na.rm = TRUE),\n      mean_se = mean(std.error, na.rm = TRUE),\n      mean_conf.low = mean(conf.low, na.rm = TRUE),\n      mean_conf.high = mean(conf.high, na.rm = TRUE),\n      # Correct power calculation based on model type\n      power = if_else(\n        first(model) == \"fit_mlm_reduction_robust\",\n        sum(conf.high &lt; 0, na.rm = TRUE) / sum(!is.na(conf.high)),  # Robust expects negative\n        sum(conf.low &gt; 0, na.rm = TRUE) / sum(!is.na(conf.low))     # Change score expects positive\n      )\n    )\n  \n  message(\"Recalculated H2b summary with corrected power calculation\")\n  message(\"Change Score Approach - Mean Power: \", \n          round(mean(sim_summary_h2b$power[sim_summary_h2b$model == \"fit_mlm_reduction\"], na.rm = TRUE), 3))\n  message(\"Robust Approach - Mean Power: \", \n          round(mean(sim_summary_h2b$power[sim_summary_h2b$model == \"fit_mlm_reduction_robust\"], na.rm = TRUE), 3))\n}\n\n\n\n\nShow code (visualize power h2b)\n# Estimated effect vs. true effect (b)\nggplot(sim_summary_h2b, aes(x = expected_effect, \n                            y = ifelse(model == \"fit_mlm_reduction_robust\", \n                                      -mean_effect, mean_effect), \n                            color = model, shape = model)) +\n  geom_point(size = 3) +\n  geom_errorbar(aes(ymin = ifelse(model == \"fit_mlm_reduction_robust\", \n                                  -mean_conf.high, mean_conf.low), \n                    ymax = ifelse(model == \"fit_mlm_reduction_robust\", \n                                  -mean_conf.low, mean_conf.high)), \n                width = 0.01) +\n  facet_wrap(~ effect_shape) +\n  geom_abline(slope = 1, intercept = 0, linetype = \"dashed\", color = \"gray\") +\n  labs(x = \"True Effect Magnitude (expected effect)\", \n       y = \"Estimated Effect Magnitude\",\n       title = \"Estimated vs. True Effects by Per-Protocol Model and Effect Shape\",\n       subtitle = \"Effects shown as absolute magnitudes for comparison\",\n       color = \"Per-Protocol Model\", shape = \"Per-Protocol Model\") +\n  scale_x_continuous(breaks = c(0.05, 0.1, 0.15, 0.2, 0.25),\n                     sec.axis = sec_axis(~ . / 3, name = \"Standardized Effect\")) +\n  scale_color_manual(values = c(\"fit_mlm_reduction\" = \"#2E8B57\", \n                                \"fit_mlm_reduction_robust\" = \"#FF6347\"),\n                     labels = c(\"fit_mlm_reduction\" = \"Change Score Approach\", \n                                \"fit_mlm_reduction_robust\" = \"Robust Approach\")) +\n  scale_shape_manual(values = c(\"fit_mlm_reduction\" = 16, \n                                \"fit_mlm_reduction_robust\" = 17),\n                     labels = c(\"fit_mlm_reduction\" = \"Change Score Approach\", \n                                \"fit_mlm_reduction_robust\" = \"Robust Approach\"))\n\n\n\n\n\n\n\n\n\nShow code (visualize power h2b)\n# ggsave(\"figures/estimated_vs_true_effects_h2b.png\", width = 10, height = 6, dpi = 300)\n\n# Power vs. true effect (b)\nggplot(sim_summary_h2b, aes(x = expected_effect, y = power, \n                            color = model, shape = model, linetype = model)) +\n  geom_line(size = 1.2) +\n  geom_point(size = 3) +\n  facet_wrap(~ effect_shape) +\n  labs(x = \"True Effect (expected effect)\", y = \"Power\",\n       title = \"Power by Per-Protocol Model and Effect Shape\",\n       color = \"Per-Protocol Model\", shape = \"Per-Protocol Model\", linetype = \"Per-Protocol Model\") +\n  scale_x_continuous(breaks = c(0.05, 0.1, 0.15, 0.2, 0.25),\n                     sec.axis = sec_axis(~ . / 3, name = \"Standardized Effect\")) +\n  scale_y_continuous(labels = scales::percent_format(accuracy = 1), limits = c(0, 1), breaks = seq(0, 1, .1)) +\n  scale_color_manual(values = c(\"fit_mlm_reduction\" = \"#2E8B57\", \n                                \"fit_mlm_reduction_robust\" = \"#FF6347\"),\n                     labels = c(\"fit_mlm_reduction\" = \"Change Score Approach\", \n                                \"fit_mlm_reduction_robust\" = \"Robust Approach\")) +\n  scale_shape_manual(values = c(\"fit_mlm_reduction\" = 16, \n                                \"fit_mlm_reduction_robust\" = 17),\n                     labels = c(\"fit_mlm_reduction\" = \"Change Score Approach\", \n                                \"fit_mlm_reduction_robust\" = \"Robust Approach\")) +\n  scale_linetype_manual(values = c(\"fit_mlm_reduction\" = \"solid\", \n                                   \"fit_mlm_reduction_robust\" = \"dashed\"),\n                        labels = c(\"fit_mlm_reduction\" = \"Change Score Approach\", \n                                   \"fit_mlm_reduction_robust\" = \"Robust Approach\"))\n\n\n\n\n\n\n\n\n\nShow code (visualize power h2b)\n# ggsave(\"figures/power_by_model_and_effect_shape_h2b.png\", width = 10, height = 6, dpi = 300)  \n\n# Summary statistics comparing the two per-protocol approaches\nprotocol_comparison &lt;- sim_summary_h2b |&gt;\n  group_by(model, effect_shape) |&gt;\n  summarise(\n    mean_power = mean(power, na.rm = TRUE),\n    max_power = max(power, na.rm = TRUE),\n    min_power = min(power, na.rm = TRUE),\n    mean_bias = mean(abs(mean_effect - expected_effect), na.rm = TRUE),\n    .groups = \"drop\"\n  ) |&gt;\n  mutate(\n    model_name = case_when(\n      model == \"fit_mlm_reduction\" ~ \"Change Score Approach\",\n      model == \"fit_mlm_reduction_robust\" ~ \"Robust Approach\"\n    )\n  )\n\n# Display comparison table\nknitr::kable(\n  protocol_comparison,\n  caption = \"Comparison of Per-Protocol Approaches for Sleep Quality Analysis\",\n  col.names = c(\"Model\", \"Effect Shape\", \"Mean Power\", \"Max Power\", \"Min Power\", \"Mean Bias\", \"Model Name\"),\n  digits = 3\n)\n\n\n\nComparison of Per-Protocol Approaches for Sleep Quality Analysis\n\n\n\n\n\n\n\n\n\n\n\nModel\nEffect Shape\nMean Power\nMax Power\nMin Power\nMean Bias\nModel Name\n\n\n\n\nfit_mlm_reduction\ngrow\n0.950\n1\n0.768\n0.029\nChange Score Approach\n\n\nfit_mlm_reduction\nplateau\n0.929\n1\n0.684\n0.172\nChange Score Approach\n\n\nfit_mlm_reduction_robust\ngrow\n0.948\n1\n0.750\n2.063\nRobust Approach\n\n\nfit_mlm_reduction_robust\nplateau\n0.927\n1\n0.666\n1.913\nRobust Approach\n\n\n\n\n\nShow code (visualize power h2b)\n# Print summary comparison\ncat(\"\\n=== PER-PROTOCOL APPROACH COMPARISON ===\\n\")\n\n\n\n=== PER-PROTOCOL APPROACH COMPARISON ===\n\n\nShow code (visualize power h2b)\nchange_score_power &lt;- mean(sim_summary_h2b$power[sim_summary_h2b$model == \"fit_mlm_reduction\"], na.rm = TRUE)\nrobust_power &lt;- mean(sim_summary_h2b$power[sim_summary_h2b$model == \"fit_mlm_reduction_robust\"], na.rm = TRUE)\n\ncat(sprintf(\"Change Score Approach - Mean Power: %.3f\\n\", change_score_power))\n\n\nChange Score Approach - Mean Power: 0.939\n\n\nShow code (visualize power h2b)\ncat(sprintf(\"Robust Approach - Mean Power: %.3f\\n\", robust_power))\n\n\nRobust Approach - Mean Power: 0.937\n\n\nShow code (visualize power h2b)\ncat(sprintf(\"Difference: %.3f (robust approach is %.1f%% %s)\\n\", \n            robust_power - change_score_power,\n            abs(robust_power - change_score_power) * 100,\n            ifelse(robust_power &gt; change_score_power, \"higher\", \"lower\")))\n\n\nDifference: -0.002 (robust approach is 0.2% lower)\n\n\nShow code (visualize power h2b)\ncat(\"\\n=== IMPORTANT NOTE ON INTERPRETATION ===\\n\")\n\n\n\n=== IMPORTANT NOTE ON INTERPRETATION ===\n\n\nShow code (visualize power h2b)\ncat(\"The two per-protocol models test subtly different hypotheses:\\n\")\n\n\nThe two per-protocol models test subtly different hypotheses:\n\n\nShow code (visualize power h2b)\ncat(\"- Change Score Model: Tests if reduction in playtime improves sleep (positive coefficient expected)\\n\")\n\n\n- Change Score Model: Tests if reduction in playtime improves sleep (positive coefficient expected)\n\n\nShow code (visualize power h2b)\ncat(\"- Robust Model: Tests if lower playtime is associated with better sleep during intervention (negative coefficient expected)\\n\")\n\n\n- Robust Model: Tests if lower playtime is associated with better sleep during intervention (negative coefficient expected)\n\n\nShow code (visualize power h2b)\ncat(\"Both approaches test the same underlying phenomenon but from different angles.\\n\")\n\n\nBoth approaches test the same underlying phenomenon but from different angles.\n\n\nShow code (visualize power h2b)\ncat(\"=========================================\\n\")\n\n\n=========================================",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>H2 - Effect of Abstention on Sleep Quality</span>"
    ]
  },
  {
    "objectID": "scripts/sim_sleepquality_report.html#planned-sensitivity-analyses",
    "href": "scripts/sim_sleepquality_report.html#planned-sensitivity-analyses",
    "title": "3  H2 - Effect of Abstention on Sleep Quality",
    "section": "3.6 Planned Sensitivity Analyses",
    "text": "3.6 Planned Sensitivity Analyses\nWe have preregistered several sensitivity analyses to test the robustness of any effects we find. These include:\n\nDay 21 only: We will estimate the effect of the intervention on day 21 only, to see what the difference between groups is at the end of the intervention period\nMarginal means: In h2a, we will use the emmeans package to calculate marginal means for each condition and produce a single parameter by integrating across the 14-day period\nMultilevel model: We will fit the MLM as defined in Table 1 above, as the second-highest performing model in the simulations (having higher power for linear effects, but lower for non-linear) ```",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>H2 - Effect of Abstention on Sleep Quality</span>"
    ]
  },
  {
    "objectID": "scripts/sim_self_report.html",
    "href": "scripts/sim_self_report.html",
    "title": "4  H3 - Effect of Abstention on Wellbeing",
    "section": "",
    "text": "4.1 Introduction\nThis section demonstrates a complete workflow for generating synthetic data, introducing dropout, and fitting models (a GAM or MLM) to the data. The main focus is on the sim_study function, which orchestrates the data simulation, dropout process, and model fitting.\nAs an overview, we compare the following possible models for estimating the effect of gaming reduction, for both H3a (the intention-to-treat effect) and H3b (the per-protocol effect; i.e., the effect of actual gaming reduction relative to one’s own baseline). The models we compare are:",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>H3 - Effect of Abstention on Wellbeing</span>"
    ]
  },
  {
    "objectID": "scripts/sim_self_report.html#introduction",
    "href": "scripts/sim_self_report.html#introduction",
    "title": "4  H3 - Effect of Abstention on Wellbeing",
    "section": "",
    "text": "ITT = Intention-to-treat; PP = per-protocol\n\n\n\n\n\n\n\n\nModel Name\nSyntax\nTarget Effect\nNotes\n\n\n\n\nGAM\ngam(wellbeing ~ condition:intervention_period + age + gender + s(id, bs = \"re\") + s(day, by = condition, bs = \"tp\"), correlation = corAR1(form = ~ day | id))\nITT\n\n\n\nGAM with no main effect)\ngam(wellbeing ~         age + gender +         s(id, bs = \"re\") +         s(day, by = condition, bs = \"tp\"),       data = dat,       correlation = corCAR1(form = ~ day | id))\nITT\nHere we do not estimate a parameter for the effect of the intervention directly; rather, we simply fit separate curves to each condition and calculate the average marginal effect using {emmeans}\n\n\nMLM\nlme(     fixed = wellbeing ~ condition*intervention_period + age + gender,     random = ~ 1|id,     correlation = corCAR1(form = ~ day | id),     method = \"ML\"   )\nITT\nMultiple versions of this model failed when including random slopes; we therefore dropped these\n\n\nMLM Simple\nlme(     fixed = wellbeing ~ baseline + condition + age + gender,     random = ~ 1 + condition|id,     correlation = corCAR1(form = ~ day | id),     method = \"ML\",   )\nITT\nHere we do not model the baseline (pre-intervention period) itself—we model only the 14-day period when the intervention is active, using average wellbeing during baseline as a covariate\n\n\nGLS (generalized least squares)\ngls(     wellbeing ~ condition * intervention_period + age + gender,     correlation = corCAR1(form = ~ day | id),   )\nITT\n\n\n\nGLS Simple\ngls(     wellbeing ~ condition + baseline + age + gender,     correlation = corAR1(form = ~ day | id),   )\nITT\n\n\n\nGLS Splines\ngls(     wellbeing ~ ns(day, df = 4) * intervention_period * condition,,     correlation = corCAR1(form = ~ day | id),     data = dat   )\nITT\nIn this version, we fit a GLS but allow non-linearity in the trajectory of wellbeing using splines\n\n\nMLM Reduction\nlme(     fixed = wellbeing ~ intervention_active*reduction + age + gender,     random = ~ 1 + intervention_active*reduction | id,     correlation = corCAR1(form = ~ day | id)   )\nPP\nHere we test our intended model for the per-protocol effect; reduction is the number of hours played relative to that person’s mean playtime at baseline\n\n\nMLM Reduction Robust\nlme(     fixed = wellbeing ~ intervention_active*playtime + baseline_playtime + age + gender,     random = ~ 1 | id,     correlation = corCAR1(form = ~ day | id)   )\nPP\nRobust approach without change scores - tests if intervention effect varies by actual playtime levels, controlling for baseline playtime\n\n\n\n\n4.1.1 Take-aways\nOur simulations show that several models perform well at parameter recovery for the ITT effect, but that the GAM model has the highest power for small effects—the type of effects we believe we are most likely to observed—and for non-linear trajectories over the 14 day period (e.g., an effect that slowly accumulates over a couple of days and then plateaus, or a temporary withdrawal followed by a later improvement). The GAM has approximately 50% power for a standardized effect of .2, and 80% power for a standardized effect of .3, but this varies based the shape of that effect over time.\nThe MLM Reduction model performs very well, and has &gt;95% power for standardized effects of approximately .2 or greater. The MLM Reduction Robust model provides an alternative approach that avoids potential issues with change scores by directly modeling the relationship between current playtime and outcomes while controlling for baseline differences.\n\n\n4.1.2 Load Libraries\nFirst we load packages with pacman, which is fully compatible with renv.\n\n\nShow code (load libraries)\nlibrary(pacman)\n\np_load(tidyverse, qualtRics, lme4, mgcv, marginaleffects, broom, forestplot, broom.mixed, nlme, rms, emmeans, splines, furrr, extraDistr, kableExtra)\n\n# Replace your current plan() line with:\nif (interactive()) {\n  plan(multisession, workers = parallel::detectCores()-10)\n} else {\n  plan(multisession, workers = parallel::detectCores()-10)\n}\n# Diagnostic information about parallel setup\n\nmessage(\"=== PARALLEL PROCESSING SETUP ===\")\nmessage(\"Total CPU cores detected: \", parallel::detectCores())\nmessage(\"Number of workers allocated: \", nbrOfWorkers())\nmessage(\"Future plan: \", paste(class(plan()), collapse = \", \"))\nmessage(\"===================================\")\n\ntheme_set(theme_minimal())\ntheme_update(\n  strip.background = element_rect(fill = \"black\"),\n  strip.text = element_text(color = \"white\", size = 10),\n  panel.grid.minor = element_blank(),\n  panel.border = element_rect(colour = \"black\", fill = NA, linewidth = 1),\n)\n\noptions(scipen = 999)\n\n\n\n\n4.1.3 Simulation, Dropout, and Fitting Functions\nHere we define:\n\nsim_data: Generates synthetic data with random intercepts/slopes and AR(1) errors.\nsim_dropout: Introduces missingness and dropout in the dataset.\nfit_*: Fits a statistical model to the simulated data (see table above)\nsim_study: Ties everything together—generates data, applies dropout, then fits the chosen model and returns a tidy summary.\n\n\n\nShow code (sim functions)\n#' Generate Synthetic Data\n#'\n#' This function simulates synthetic panel data for `n` participants over `n_days` time points,\n#' with an intervention effect, random intercepts and slopes, and AR(1)-correlated residuals.\n#'\n#' @param n Number of participants. Default is 80.\n#' @param n_days Number of time points per participant.\n#' @param b Fixed effect of condition (if mediated == FALSE) or a 1-hour reduction in playtime.\n#' @param phi AR(1) autocorrelation coefficient.\n#' @param sigma AR(1) residual standard deviation.\nsim_data &lt;- function(n = 80,\n                     n_days = 28,\n                     \n                     # effect parameters\n                     b = 3.7, # effect in unstandardized units\n                     mu = 78.5, # grand mean of the outcome\n                     \n                     \n                     # random effects parameters\n                     tau_int = 9.7,   # Random intercept SD (between-person variance)\n                     tau_slope = .05,  # Random slope SD \n                     within_person_sd = 11.8, # Within-person SD\n                     \n                     # AR(1) parameters\n                     phi = 0.8,     # Autocorrelation coefficient\n                     effect_shape = \"grow\",\n                     k = .5, # affects how quickly the plateau effect plateaus\n                     \n                     mediated = FALSE,\n                     \n                     # playtime parameters\n                     playtime_grand_mean = 1,   # Average baseline playtime in hours\n                     playtime_grand_sd = .5,   # SD for baseline playtime in log units (log-normal distribution)\n                     daily_play_sd = 0.5      # Daily noise in playtime\n                     # compliance_mean = 0.7,    # Average reduction (in hours) for intervention group during intervention period\n)     \n{\n  dat &lt;- tibble(\n    id = 1:n,\n    age = sample(18:36, n, replace = TRUE),\n    gender = sample(c(\"man\",\"woman\",\"non-binary\"), n, prob = c(.45, .45, .1), replace = TRUE),\n    condition = factor(sample(c(\"control\", \"intervention\"), n, replace = TRUE)),\n    experimental_condition = ifelse(condition == \"intervention\", 1, 0),\n    intercept_wb = rnorm(n, 0, tau_int),\n    slope_wb = rnorm(n, 0, tau_slope),\n    intercept_play = rlnorm(n, log(playtime_grand_mean), playtime_grand_sd),\n  ) |&gt; \n    # expand to 28 waves per id\n    crossing(\n      day = 1:n_days\n    ) |&gt; \n    mutate(\n      intervention_period = as.numeric(day &gt; 7 & day &lt; 22),\n      intervention_active = intervention_period & condition == \"intervention\",\n      # Use fully-qualified name so the function works even if the extraDistr package\n      # has not been attached in the worker’s search path.\n      compliance = ifelse(intervention_active,\n                          extraDistr::rkumar(n * n_days, a = .05, b = .1),\n                          0),\n      \n      # In the baseline period, play is just the subject’s baseline plus some day-to-day noise\n      # During the intervention, experimental subjects reduce play by their compliance amount\n      playtime = (1 - compliance) * rlnorm(n, log(intercept_play), daily_play_sd),\n      effect_time = case_when(\n        effect_shape == \"plateau\" ~ if_else(intervention_period == 1, (b + slope_wb) * (1-exp(-k * (day - 7))), 0),\n        effect_shape == \"grow\" ~ if_else(intervention_period == 1, (day - 7) * ((b + slope_wb)/7), 0),\n        TRUE ~ NA_real_\n      ),\n    ) |&gt; \n    group_by(id) |&gt; \n    mutate(\n      \n      baseline_playtime = mean(playtime[day &lt;= 7]),\n      reduction = baseline_playtime - playtime, # The mediator: reduction in play relative to the baseline average\n      sigma = within_person_sd * sqrt(1-phi^2),\n      # Generate AR(1) errors for each participant\n      e = as.numeric(arima.sim(n = n_days, \n                               model = list(ar = phi), \n                               sd = sigma)),\n      # Add random effect + fixed effect + AR(1) error\n      wellbeing = case_when(\n        mediated == TRUE ~ mu + \n                            intercept_wb + \n                            effect_time * reduction + \n                            .01*(age-18) +\n                            -.05*gender %in% c(\"women\",\"non-binary\") +\n                            e,\n        mediated == FALSE ~ mu + \n                            intercept_wb + \n                            effect_time * experimental_condition * intervention_period + \n                            .01*(age-18) +\n                            -.05*gender %in% c(\"women\",\"non-binary\") +\n                            e\n      )\n    ) |&gt; \n    ungroup() |&gt; \n    mutate(across(where(is.numeric), ~ round(., 3)))\n  \n  dat\n\n}\n\n\n#' Simulate Dropout\n#'\n#' Introduces missingness and dropout into a dataset by randomly assigning records as missing\n#' or dropped out. Once a participant is dropped out, all subsequent records become missing.\n#'\n#' @param dat A tibble generated by \\code{sim_data()}.\n#'\n#' @return A tibble of the same structure as \\code{dat}, but with some \\code{wellbeing} values set to NA.\n#'\nsim_dropout &lt;- function(dat) {\n  \n  dropout &lt;- dat |&gt; \n    mutate(\n      missing = sample(c(TRUE, FALSE), n(), replace = TRUE, prob = c(.10, .90)),\n      dropout = sample(c(TRUE, FALSE), n(), replace = TRUE, prob = c(.01, .99))\n    ) |&gt;\n    mutate(\n      missing = ifelse(cumsum(dropout) &gt; 0, TRUE, missing),\n      .by = id\n    ) |&gt;\n    arrange(as.integer(id), day) |&gt; \n    mutate(wellbeing = ifelse(missing, NA, wellbeing))\n  dropout\n}\n\n#' Fit a Generalized Additive Model (GAM)\n#'\n#' Fits a GAM model to the provided dataset using \\code{mgcv::gam}, including an AR(1)\n#' correlation structure and random intercept for each ID.\n#'\n#' @param dat A tibble of repeated-measures data (e.g., from \\code{sim_data()} and \\code{sim_dropout()}).\n#'\n#' @return An object of class \\code{gam}, which is the fitted GAM model.\n#'\nfit_gam &lt;- function(dat) {\n  \n  gam(wellbeing ~ \n        condition:intervention_period + age + gender +\n        s(id, bs = \"re\") + \n        s(day, by = condition, bs = \"tp\"), \n      data = dat,\n      correlation = corAR1(form = ~ day | id))\n}\n\nfit_gam_no_main &lt;- function(dat) {\n  \n  gam(wellbeing ~ \n        age + gender +\n        s(id, bs = \"re\") + \n        s(day, by = condition, bs = \"tp\"), \n      data = dat,\n      correlation = corCAR1(form = ~ day | id))\n}\n\n#' Fit a Multi-Level Model (MLM)\n#'\n#' Fits a linear mixed-effects model (LME) with random intercept for each ID using \\code{lme4::lmer}.\n#'\n#' @param dat A tibble of repeated-measures data (e.g., from \\code{sim_data()} and \\code{sim_dropout()}).\n#'\n#' @return An object of class \\code{lmerMod}, which is the fitted MLM model.\n#'\nfit_mlm &lt;- function(dat) {\n  # Control parameters for better convergence\n  ctrl &lt;- lmeControl(\n    maxIter = 200,\n    msMaxIter = 200,\n    tolerance = 1e-6,\n    niterEM = 50,\n    msMaxEval = 400,\n    optimMethod = \"L-BFGS-B\"\n  )\n  \n  lme(\n    fixed = wellbeing ~ condition*intervention_period + age + gender,\n    random = ~ 1|id,\n    correlation = corCAR1(form = ~ day | id),\n    method = \"ML\",\n    control = ctrl,\n    data = dat |&gt; filter(!is.na(wellbeing))\n  )\n}\n\nfit_mlm_simple &lt;- function(dat) {\n  # Control parameters for better convergence\n  ctrl &lt;- lmeControl(\n    maxIter = 200,\n    msMaxIter = 200,\n    tolerance = 1e-6,\n    niterEM = 50,\n    msMaxEval = 400,\n    optimMethod = \"L-BFGS-B\"\n  )\n  \n  tmp &lt;- dat |&gt; \n    group_by(id) |&gt; \n    # take the mean of days 1-7 \n    mutate(baseline = mean(wellbeing[day &lt; 8], na.rm = TRUE)) |&gt; \n    filter(intervention_period == 1) |&gt; \n    filter(!is.na(wellbeing))\n  \n  # Try full model first, then fallback to simpler random effects if needed\n  tryCatch({\n    lme(\n      fixed = wellbeing ~ baseline + condition + age + gender,\n      random = ~ 1 + condition|id,\n      correlation = corCAR1(form = ~ day | id),\n      method = \"ML\",\n      control = ctrl,\n      data = tmp\n    )\n  }, error = function(e) {\n    # Fallback: Use random intercept only\n    lme(\n      fixed = wellbeing ~ baseline + condition + age + gender,\n      random = ~ 1|id,\n      correlation = corCAR1(form = ~ day | id),\n      method = \"ML\",\n      control = ctrl,\n      data = tmp\n    )\n  })\n}\n\nfit_gls &lt;- function(dat) {\n  \n  gls(\n    wellbeing ~ condition * intervention_period + age + gender, \n    correlation = corCAR1(form = ~ day | id),\n    data = dat |&gt; filter(!is.na(wellbeing))\n  )\n}\n\nfit_gls_simple &lt;- function(dat) {\n  \n  tmp &lt;- dat |&gt; \n    group_by(id) |&gt; \n    # take the mean of days 1-7 \n    mutate(baseline = mean(wellbeing[day &lt; 8], na.rm = TRUE)) |&gt; \n    filter(intervention_period == 1) |&gt; \n    filter(!is.na(wellbeing))\n  \n  gls(\n    wellbeing ~ condition + baseline + age + gender, \n    correlation = corAR1(form = ~ day | id),\n    data = tmp\n  )\n}\n\nfit_gls_spline &lt;- function(dat) {\n  gls(\n    wellbeing ~ ns(day, df = 4) * intervention_period * condition,,  \n    correlation = corCAR1(form = ~ day | id),\n    data = dat\n  )\n}\n\nfit_mlm_reduction &lt;- function(dat) {\n  # Control parameters for better convergence\n  ctrl &lt;- lmeControl(\n    maxIter = 200,\n    msMaxIter = 200,\n    tolerance = 1e-6,\n    niterEM = 50,\n    msMaxEval = 400,\n    optimMethod = \"L-BFGS-B\"\n  )\n  \n  # Try the full model first\n  tryCatch({\n    lme(\n      fixed = wellbeing ~ intervention_active*reduction + age + gender, \n      random = ~ 1 + intervention_active*reduction | id,\n      correlation = corCAR1(form = ~ day | id),\n      control = ctrl,\n      data = dat |&gt; filter(!is.na(wellbeing))\n    )\n  }, error = function(e) {\n    # Fallback 1: Simplify random effects (remove correlation)\n    tryCatch({\n      lme(\n        fixed = wellbeing ~ intervention_active*reduction + age + gender,\n        random = list(id = pdBlocked(list(~ 1, ~ intervention_active*reduction - 1))),\n        correlation = corCAR1(form = ~ day | id),\n        control = ctrl,\n        data = dat |&gt; filter(!is.na(wellbeing))\n      )\n    }, error = function(e2) {\n      # Fallback 2: Further simplify random effects\n      tryCatch({\n        lme(\n          fixed = wellbeing ~ intervention_active*reduction + age + gender,\n          random = ~ 1 + intervention_active | id,\n          correlation = corCAR1(form = ~ day | id),\n          control = ctrl,\n          data = dat |&gt; filter(!is.na(wellbeing))\n        )\n      }, error = function(e3) {\n        # Fallback 3: Simplest model that still captures the effect\n        lme(\n          fixed = wellbeing ~ intervention_active*reduction + age + gender,\n          random = ~ 1 | id,\n          correlation = corCAR1(form = ~ day | id),\n          control = ctrl,\n          data = dat |&gt; filter(!is.na(wellbeing))\n        )\n      })\n    })\n  })\n}\n\nfit_mlm_reduction_robust &lt;- function(dat) {\n  # Control parameters for better convergence\n  ctrl &lt;- lmeControl(\n    maxIter = 200,\n    msMaxIter = 200,\n    tolerance = 1e-6,\n    niterEM = 50,\n    msMaxEval = 400,\n    optimMethod = \"L-BFGS-B\"\n  )\n  \n  # Clean data and standardize variables to improve numerical stability\n  dat_clean &lt;- dat |&gt; \n    filter(!is.na(wellbeing)) |&gt;\n    mutate(\n      # Standardize continuous variables to help with convergence\n      playtime_std = as.numeric(scale(playtime)),\n      baseline_playtime_std = as.numeric(scale(baseline_playtime)),\n      age_std = as.numeric(scale(age))\n    )\n  \n  # Try the full model first\n  tryCatch({\n    lme(\n      fixed = wellbeing ~ intervention_active*playtime_std + baseline_playtime_std + age_std + gender,\n      random = ~ 1 | id,\n      correlation = corCAR1(form = ~ day | id),\n      control = ctrl,\n      data = dat_clean\n    )\n  }, error = function(e) {\n    # Fallback: Try without correlation structure if needed\n    tryCatch({\n      lme(\n        fixed = wellbeing ~ intervention_active*playtime_std + baseline_playtime_std + age_std + gender,\n        random = ~ 1 | id,\n        control = ctrl,\n        data = dat_clean\n      )\n    }, error = function(e2) {\n      # Final fallback: Use original (non-standardized) variables without correlation\n      lme(\n        fixed = wellbeing ~ intervention_active*playtime + baseline_playtime + age + gender,\n        random = ~ 1 | id,\n        control = ctrl,\n        data = dat |&gt; filter(!is.na(wellbeing))\n      )\n    })\n  })\n}\n\n# Helper function to extract the focal effect for GLS models\nextract_marginal_effect &lt;- function(mod, dat, focal_term = \"conditionintervention\") {\n  # Here we assume your GLS model is specified with condition*intervention_period\n  # and you want the effect of condition (e.g., intervention vs. control) during intervention.\n  # We create a reference grid that fixes intervention_period at 1.\n  rg &lt;- ref_grid(mod, data = dat, at = list(intervention_period = 1))\n  \n  # Obtain estimated marginal means for each condition.\n  emm &lt;- emmeans(rg, ~ condition)\n  \n  # Compute the pairwise contrast (e.g., intervention - control)\n  # Adjust names as needed. The contrast below returns a one-row summary.\n  contr &lt;- emmeans::contrast(emm, method = list(\"intervention - control\" = c(-1, 1)), adjust = \"none\")\n  contr_sum &lt;- summary(contr, infer = TRUE)\n  \n  # Construct a one-row data frame with consistent column names.\n  # If you have more than one contrast, you might need to filter for the one of interest.\n  df &lt;- data.frame(\n    term = focal_term,\n    estimate = contr_sum$estimate,\n    std.error = contr_sum$SE,\n    conf.low = contr_sum$lower.CL,\n    conf.high = contr_sum$upper.CL,\n    row.names = NULL\n  )\n  \n  return(df)\n}\n\n#' Simulation Study Orchestrator\n#'\n#' A higher-level function that ties together data simulation, dropout, and model fitting,\n#' returning a tidy summary of the fitted model parameters.\n#'\n#' @param model_function A function to fit the model. Defaults to \\code{fit_gam}.\n#' @param n Number of participants passed to \\code{sim_data()}. Default is 1000.\n#' @param n_days Number of time points per participant passed to \\code{sim_data()}. Default is 28.\n#' @param b Fixed effect for the intervention slope passed to \\code{sim_data()}. Default is 0.01.\n#' @param phi AR(1) autocorrelation coefficient passed to \\code{sim_data()}. Default is 0.7.\n#' @param sigma AR(1) residual standard deviation passed to \\code{sim_data()}. Default is 0.6.\n#'\n#' @return A data frame (tibble) of model estimates from \\code{broom::tidy(parametric = TRUE)}.\n#'\n\n# Updated simulation orchestrator that handles GLS models separately.\nsim_study &lt;- function(model = \"fit_gam\", focal_term = \"intervention_activeTRUE:reduction\", ...) {\n  args &lt;- list(...)\n  dat &lt;- do.call(sim_data, args)\n  model_function &lt;- get(model)\n  \n  mod &lt;- model_function(dat)\n  \n  if (model %in% c(\"fit_gam_no_main\",\"fit_gls_spline\")) {\n    # Extract the effect using our helper function.\n    result &lt;- suppressMessages(extract_marginal_effect(mod, \n                                                       dat, \n                                                       focal_term = focal_term))\n  } else {\n    # For models that work with broom, extract the focal parameter.\n    # Adjust the filtering term as needed.\n    result &lt;- broom::tidy(mod, parametric = TRUE) %&gt;%\n      filter(term == focal_term) |&gt; \n      # filter(\n      #   term == \"conditionintervention:intervention_period\" | \n      #     (model %in% c(\"fit_mlm_simple\",\"fit_gls_simple\") & term == \"conditionintervention\")\n      # ) |&gt; \n      mutate(\n        conf.low = estimate - 1.96 * std.error,\n        conf.high = estimate + 1.96 * std.error\n      )\n  }\n  result\n}",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>H3 - Effect of Abstention on Wellbeing</span>"
    ]
  },
  {
    "objectID": "scripts/sim_self_report.html#test-and-plot-one-simulated-study",
    "href": "scripts/sim_self_report.html#test-and-plot-one-simulated-study",
    "title": "4  H3 - Effect of Abstention on Wellbeing",
    "section": "4.2 Test and Plot One Simulated Study",
    "text": "4.2 Test and Plot One Simulated Study\nBelow, we create a sample dataset using sim_data() and examine it with a line plots by day. We can also see whether the simulated SDs for wellbeing align with the target values in the simulation—luckily, they do.\n\n\nShow code (descriptive plotting)\ndat &lt;- sim_data(effect_shape = \"plateau\", mediated = TRUE)\n\nsds &lt;- dat |&gt; \n  group_by(id) |&gt; \n  summarise(mean_value = mean(wellbeing, na.rm = TRUE),\n            sd_within  = sd(wellbeing, na.rm = TRUE)) |&gt;\n  summarise(between_sd   = sd(mean_value, na.rm = TRUE),\n            avg_within_sd = mean(sd_within, na.rm = TRUE))\n\n# plot wellbeing by group\ndat |&gt; \n  group_by(condition, day) |&gt; \n  summarise(wellbeing = mean(wellbeing)) |&gt; \n  ggplot(aes(y = wellbeing, x = day, color = condition)) +\n  geom_line() + \n  theme_minimal() +\n  scale_y_continuous(limits = c(60, 100))\n\n\n\n\n\n\n\n\n\n\n4.2.1 Test Fit (H3a - intention to treat)\nWe fit various models to the newly simulated data to make sure each appears to be working properly, and also test the full sim_study pipeline.\n\n\nShow code\n#' @param n Number of participants passed to \\code{sim_data()}. Default is 1000.\n\ndat &lt;- sim_data(mediated = FALSE)\n\nfit_mlm(dat) |&gt; summary()\nfit_mlm_simple(dat) |&gt; summary()\nfit_gls(dat) |&gt; summary()\nfit_gls_simple(dat) |&gt; summary()\nfit_gls_spline(dat) |&gt; extract_marginal_effect()\nfit_gam(dat) |&gt; summary()\nfit_gam_no_main(dat) |&gt; extract_marginal_effect()\n\nsim_study(model = \"fit_gam_no_main\")\nsim_study(model = \"fit_gls_spline\")\n\n\nSince some models (e.g., fit_gam_no_main) do not have a parameter that represents the average difference-in-difference between groups during the intervention period, we need to calculate this ourselves by marginalize across the 14-day intervention period.\n\n\nShow code (test emmeans)\nemm_day &lt;- emmeans(\n  fit_gls_spline(dat), \n  pairwise ~ condition | day, \n  at = list(day = 8:21), \n  condition = c(\"control\", \"intervention\"), \n  data = dat |&gt; mutate(condition = factor(condition, levels = c(\"intervention\", \"control\")))\n)\n\nsummary(emm_day$contrasts, infer = TRUE, level = .95, by = NULL, adjust = \"none\")\n\n# and then integrated over the 14 day intervention period\nrg &lt;- ref_grid(fit_gls_spline(dat),\n               at = list(intervention_period = 1),\n               cov.reduce = list(day = mean),\n               data = dat |&gt; mutate(condition = factor(condition, levels = c(\"control\",\"intervention\"))))\n\nemm &lt;- emmeans(rg, ~ condition)\n(contrast_result &lt;- contrast(emm, method = list(\"intervention - control\" = c(-1, 1)), adjust = \"none\"))\n\n\nmeans &lt;- summary(emm)$emmean\nnames(means) &lt;- summary(emm)$condition\n(diff_manual &lt;- means[\"intervention\"] - means[\"control\"])\n\n\n\n\n4.2.2 Test Fit (H3b - per-protocol)\nAnother quick test of our fit_mlm_reduction model, to make sure the alternative simulation whereby the effect of the intervention is mediated by a reduction in playtime is also functioning properly.\n\n\nShow code (test fit h3b)\ndat &lt;- sim_data(mediated = TRUE)\n\nfit_mlm_reduction(dat) |&gt; summary()\nfit_mlm_reduction_robust(dat) |&gt; summary()",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>H3 - Effect of Abstention on Wellbeing</span>"
    ]
  },
  {
    "objectID": "scripts/sim_self_report.html#simulated-h3a-power-analysis",
    "href": "scripts/sim_self_report.html#simulated-h3a-power-analysis",
    "title": "4  H3 - Effect of Abstention on Wellbeing",
    "section": "4.3 Simulated H3a power analysis",
    "text": "4.3 Simulated H3a power analysis\nTo assess power/sensitivity, we run multiple simulations (controlled by n_sims) and gather the parameter estimates for a particular term (e.g., conditionintervention:intervention_periodTRUE, or for our marginalized effect conditionintervention). Each iteration calls sim_study, which does the data generation, dropout, and fitting.\nAs this is quite slow, we both use parallel processing with furrr cache the results.\n\n\nShow code (simulate power h3a)\n# Load tictoc for timing if not already loaded\nif (!require(tictoc, quietly = TRUE)) {\n  install.packages(\"tictoc\")\n  library(tictoc)\n}\n\n# Check if cached results exist\ncache_file_h3a &lt;- \"cache/h3a_simulation_results.rds\"\ncache_summary_h3a &lt;- \"cache/h3a_simulation_summary.rds\"\ncache_params_h3a &lt;- \"cache/h3a_simulation_params.rds\"\n\n# Define key parameters that would invalidate cache\ncurrent_params_h3a &lt;- list(\n  n_sims = 500,\n  n = 80,\n  n_days = 28,\n  tau_int = 9.7,\n  tau_slope = 0.8,\n  within_person_sd = 11.8,\n  phi = 0.7,\n  models = c(\"fit_gam\", \"fit_gam_no_main\", \"fit_mlm\", \"fit_mlm_simple\", \"fit_gls\", \"fit_gls_simple\", \"fit_gls_spline\"),\n  effect_values = c(1.2, 2.4, 3.6, 4.8, 6),\n  effect_shapes = c(\"grow\", \"plateau\")\n)\n\n# -------------------------------------------------------------------\n# Prepare job specifications irrespective of cache status\n# This ensures that variables such as `specs_h3a`, `all_jobs_h3a`, and\n# related helpers are available even when we load results from cache,\n# avoiding downstream errors (e.g., `all_jobs_h3a` not found).\nn_sims &lt;- 500\n\nspecs_h3a &lt;- expand_grid(\n  model = c(\"fit_gam\", \"fit_gam_no_main\", \"fit_mlm\", \"fit_mlm_simple\", \"fit_gls\", \"fit_gls_simple\", \"fit_gls_spline\"),  # model names as strings\n  b = c(1.2, 2.4, 3.6, 4.8, 6),\n  effect_shape = c(\"grow\", \"plateau\")\n) |&gt; \n  mutate(\n    focal_term = case_when(\n      model %in% c(\"fit_mlm_simple\",\"fit_gls_simple\", \"fit_gam_no_main\") ~ \"conditionintervention\",\n      model %in% c(\"fit_gam\", \"fit_mlm\", \"fit_gls\", \"fit_gls_spline\") ~ \"conditionintervention:intervention_period\",\n      TRUE ~ \"conditionintervention:intervention_period\"\n    )\n  ) |&gt; \n  (function(d) { d$row_id &lt;- pmap_chr(d, ~ paste0(names(list(...)), \"=\", c(...), collapse = \"_\")); d })() |&gt; \n  mutate(i = row_number())\n\n# Create all spec-simulation combinations for better parallelization\nall_jobs_h3a &lt;- specs_h3a |&gt; \n  crossing(sim = 1:n_sims) |&gt; \n  mutate(job_id = row_number())\n\n# Check if cache exists and parameters match\ncache_valid_h3a &lt;- FALSE\nif (file.exists(cache_file_h3a) && file.exists(cache_summary_h3a) && file.exists(cache_params_h3a)) {\n  cached_params_h3a &lt;- readRDS(cache_params_h3a)\n  cache_valid_h3a &lt;- identical(current_params_h3a, cached_params_h3a)\n}\n\nif (cache_valid_h3a) {\n  message(\"Loading cached H3a simulation results...\")\n  results_h3a &lt;- readRDS(cache_file_h3a)\n  sim_summary_h3a &lt;- readRDS(cache_summary_h3a)\n  message(\"Cached H3a results loaded successfully!\")\n} else {\n  message(\"No cached H3a results found or parameters changed. Running H3a simulations...\")\n  \n  # Create cache directory if it doesn't exist\n  if (!dir.exists(\"cache\")) {\n    dir.create(\"cache\", recursive = TRUE)\n  }\n  \n  # Start timing\n  tic(\"H3a simulation total time\")\n  \n  # n_sims is already defined above\n\n  message(\"Running \", nrow(all_jobs_h3a), \" simulations across \", nbrOfWorkers(), \" cores...\")\n\n  # Run all simulations in parallel\n  results_h3a &lt;- future_map_dfr(1:nrow(all_jobs_h3a), function(job_idx) {\n    # Load required libraries in each worker\n    library(tidyverse)\n    library(nlme)\n    library(mgcv)\n    library(broom.mixed)\n    library(emmeans)\n    \n    # Get job parameters\n    job &lt;- all_jobs_h3a[job_idx, ]\n    \n    tryCatch({\n      result &lt;- sim_study(\n        model = job$model,\n        focal_term = job$focal_term,\n        n = 80,\n        n_days = 28,\n        # effect parameters\n        b = job$b, # effect in unstandardized units\n        mu = 78.5, # grand mean of the outcome\n        effect_shape = job$effect_shape,\n        k = .5,\n        # random effects parameters\n        tau_int = 9.7,   # Random intercept SD (between-person variance)\n        tau_slope = .8,  # Random slope SD \n        within_person_sd = 11.8, # Within-person SD\n        # AR(1) parameters\n        phi = 0.7,     # Autocorrelation coefficient\n        mediated = FALSE\n      ) |&gt; \n        mutate(\n          sim = job$sim,\n          row_id = job$row_id,\n          model = job$model,\n          b = job$b,\n          effect_shape = job$effect_shape\n        )\n      \n      return(result)\n    }, error = function(e) {\n      # Only show debug messages if debug mode is enabled and in interactive mode\n      if (getOption(\"debug_mode\", FALSE) && interactive()) {\n        message(\"Job \", job_idx, \" (spec row: \", job$i, \", sim: \", job$sim, \") failed: \", e$message)\n      }\n      tibble(\n        term = NA_character_,\n        estimate = NA_real_,\n        std.error = NA_real_,\n        conf.low = NA_real_,\n        conf.high = NA_real_,\n        sim = job$sim,\n        row_id = job$row_id,\n        model = job$model,\n        b = job$b,\n        effect_shape = job$effect_shape\n      )\n    })\n  }, .progress = TRUE,\n  .options = furrr_options(\n    globals = c(\"all_jobs_h3a\", \"sim_study\", \"sim_data\", \n                \"fit_gam\", \"fit_gam_no_main\",\n                \"fit_mlm\", \"fit_mlm_simple\",\n                \"fit_gls\", \"fit_gls_simple\",\n                \"fit_gls_spline\", \n                \"extract_marginal_effect\"),\n    seed = TRUE\n  ))\n\n  sim_summary_h3a &lt;- results_h3a |&gt; \n    group_by(row_id) |&gt; \n    summarise(\n      model = first(model),\n      b = first(b),\n      effect_shape = first(effect_shape),\n      mean_effect = mean(estimate, na.rm = TRUE),\n      mean_se = mean(std.error, na.rm = TRUE),\n      mean_conf.low = mean(conf.low, na.rm = TRUE),\n      mean_conf.high = mean(conf.high, na.rm = TRUE),\n      power = sum(conf.low &gt; 0, na.rm = TRUE) / sum(!is.na(conf.low))\n    )\n\n  # Stop timing and display results\n  h3a_time &lt;- toc()\n\n  # Save results to cache\n  saveRDS(results_h3a, cache_file_h3a)\n  saveRDS(sim_summary_h3a, cache_summary_h3a)\n  saveRDS(current_params_h3a, cache_params_h3a)\n  message(\"H3a simulation results saved to cache!\")\n\n} # End of else block for cached results\n\n# Also print some summary statistics about the simulation\nmessage(\"=== SIMULATION SUMMARY ===\")\nmessage(\"Total number of jobs: \", nrow(all_jobs_h3a))\nmessage(\"Number of successful results: \", sum(!is.na(results_h3a$estimate)))\nmessage(\"Number of failed jobs: \", sum(is.na(results_h3a$estimate)))\nmessage(\"Success rate: \", round(100 * sum(!is.na(results_h3a$estimate)) / nrow(results_h3a), 1), \"%\")\nmessage(\"============================\")\n\n\n\n\nShow code (visualize power h3a)\n# Estimated effect vs. true effect (b)\nggplot(sim_summary_h3a, aes(x = b, y = mean_effect, color = model, alpha = model == \"fit_gam\")) +\n  geom_point(size = 3) +\n  geom_errorbar(aes(ymin = mean_conf.low, ymax = mean_conf.high), width = 0.1) +\n  facet_wrap(~ effect_shape) +\n  geom_abline(slope = 1, intercept = 0, linetype = \"dashed\", color = \"gray\") +\n  labs(x = \"True Effect (unstandardized b)\", y = \"Estimated Effect\",\n       title = \"Estimated vs. True Effects by Model and Effect Shape\") +\n  scale_x_continuous(breaks = c(1.2, 2.4, 3.6, 4.8, 6),\n                     sec.axis = sec_axis(~ . / 12, name = \"Standardized Effect (b/12)\")) +\n  scale_alpha_manual(values = c(\"TRUE\" = 1, \"FALSE\" = 0.3), guide = \"none\")\n\n\n\n\n\n\n\n\n\nShow code (visualize power h3a)\n# Power vs. true effect (b)\nggplot(sim_summary_h3a, aes(x = b, y = power, color = model, alpha = model == \"fit_gam\")) +\n  geom_line(size = 1) +\n  geom_point(size = 3) +\n  facet_wrap(~ effect_shape) +\n  labs(x = \"True Effect (unstandardized b)\", y = \"Power\",\n       title = \"Power by Model and Effect Shape\") +\n  scale_x_continuous(breaks = c(1.2, 2.4, 3.6, 4.8, 6),\n                     sec.axis = sec_axis(~ . / 12, name = \"Standardized Effect (b/12)\")) +\n  scale_y_continuous(labels = scales::percent_format(accuracy = 1), limits = c(0, 1), breaks = seq(0, 1, .1)) +\n  scale_alpha_manual(values = c(\"TRUE\" = 1, \"FALSE\" = 0.3), guide = \"none\")\n\n\n\n\n\n\n\n\n\nShow code (visualize power h3a)\n# results |&gt;\n#   forestplot(mean = estimate,\n#              lower = conf.low,\n#              upper = conf.high,\n#              labeltext = term)\n\n\n\n4.3.1 Minimum Detectable Effect Sizes at 80% Power\n\n\nShow code (minimum detectable effects table)\n# Function to interpolate minimum detectable effect at 80% power\nfind_mde_80 &lt;- function(power_data) {\n  # If we already have 80% power or higher at the smallest effect, return that\n  if (min(power_data$power, na.rm = TRUE) &gt;= 0.8) {\n    return(min(power_data$b, na.rm = TRUE))\n  }\n  \n  # If we never reach 80% power, return NA\n  if (max(power_data$power, na.rm = TRUE) &lt; 0.8) {\n    return(NA_real_)\n  }\n  \n  # Linear interpolation to find effect size at 80% power\n  approx(x = power_data$power, y = power_data$b, xout = 0.8)$y\n}\n\n# Calculate minimum detectable effects for each model and effect shape\nmde_table &lt;- sim_summary_h3a |&gt;\n  group_by(model, effect_shape) |&gt;\n  summarise(\n    mde_80_unstandardized = find_mde_80(cur_data()),\n    mde_80_standardized = mde_80_unstandardized / 12,  # Convert to standardized units\n    max_power = max(power, na.rm = TRUE),\n    .groups = \"drop\"\n  ) |&gt;\n  arrange(effect_shape, mde_80_standardized) |&gt;\n  mutate(\n    # Clean up model names for presentation\n    model_clean = case_when(\n      model == \"fit_gam\" ~ \"GAM\",\n      model == \"fit_gam_no_main\" ~ \"GAM (no main effect)\",\n      model == \"fit_mlm\" ~ \"MLM\",\n      model == \"fit_mlm_simple\" ~ \"MLM Simple\",\n      model == \"fit_gls\" ~ \"GLS\",\n      model == \"fit_gls_simple\" ~ \"GLS Simple\", \n      model == \"fit_gls_spline\" ~ \"GLS Splines\",\n      TRUE ~ model\n    ),\n    # Format effect sizes for display\n    mde_80_unstandardized_fmt = ifelse(is.na(mde_80_unstandardized), \n                                      \"&gt;6.0\", \n                                      sprintf(\"%.1f\", mde_80_unstandardized)),\n    mde_80_standardized_fmt = ifelse(is.na(mde_80_standardized), \n                                    \"&gt;0.50\", \n                                    sprintf(\"%.2f\", mde_80_standardized)),\n    max_power_fmt = sprintf(\"%.1f%%\", max_power * 100)\n  )\n\n# Create formatted table\nmde_table |&gt;\n  select(\n    `Effect Shape` = effect_shape,\n    `Model` = model_clean,\n    `MDE (Unstandardized)` = mde_80_unstandardized_fmt,\n    `MDE (Standardized)` = mde_80_standardized_fmt,\n    `Max Power Achieved` = max_power_fmt\n  ) |&gt;\n  kable(\n    caption = \"Minimum Detectable Effect Sizes at 80% Power by Model and Effect Shape\",\n    align = c(\"l\", \"l\", \"r\", \"r\", \"r\")\n  ) |&gt;\n  kable_styling(\n    bootstrap_options = c(\"striped\", \"hover\", \"condensed\"),\n    full_width = FALSE,\n    position = \"left\"\n  ) |&gt;\n  pack_rows(\"Growing Effect\", 1, sum(mde_table$effect_shape == \"grow\")) |&gt;\n  pack_rows(\"Plateau Effect\", sum(mde_table$effect_shape == \"grow\") + 1, nrow(mde_table)) |&gt;\n  footnote(\n    general = c(\n      \"MDE = Minimum Detectable Effect size at 80% power\",\n      \"Standardized effects calculated as unstandardized effect / 12\",\n      \"Models ordered by sensitivity (smallest MDE first) within each effect shape\",\n      \"'&gt;6.0' and '&gt;0.50' indicate models that did not achieve 80% power at largest tested effect size\"\n    ),\n    general_title = \"Notes:\"\n  )\n\n\n\nMinimum Detectable Effect Sizes at 80% Power by Model and Effect Shape\n\n\nEffect Shape\nModel\nMDE (Unstandardized)\nMDE (Standardized)\nMax Power Achieved\n\n\n\n\nGrowing Effect\n\n\ngrow\nGLS Splines\n1.2\n0.10\n-Inf%\n\n\ngrow\nMLM\n3.4\n0.29\n99.8%\n\n\ngrow\nGLS\n3.8\n0.31\n99.8%\n\n\ngrow\nGAM\n4.5\n0.37\n90.2%\n\n\ngrow\nGLS Simple\n4.8\n0.40\n93.0%\n\n\ngrow\nMLM Simple\n4.9\n0.41\n93.6%\n\n\ngrow\nGAM (no main effect)\n&gt;6.0\n&gt;0.50\n72.0%\n\n\nPlateau Effect\n\n\nplateau\nGLS Splines\n1.2\n0.10\n-Inf%\n\n\nplateau\nGAM\n4.6\n0.38\n86.2%\n\n\nplateau\nGAM (no main effect)\n5.2\n0.43\n85.2%\n\n\nplateau\nMLM\n5.2\n0.43\n94.2%\n\n\nplateau\nGLS\n5.4\n0.45\n88.0%\n\n\nplateau\nGLS Simple\n6.0\n0.50\n80.6%\n\n\nplateau\nMLM Simple\n&gt;6.0\n&gt;0.50\n77.8%\n\n\n\nNotes:\n\n\n\n\n\n\n MDE = Minimum Detectable Effect size at 80% power\n\n\n\n\n\n\n Standardized effects calculated as unstandardized effect / 12\n\n\n\n\n\n\n Models ordered by sensitivity (smallest MDE first) within each effect shape\n\n\n\n\n\n\n '&gt;6.0' and '&gt;0.50' indicate models that did not achieve 80% power at largest tested effect size\n\n\n\n\n\n\n\n\n\n\nShow code (minimum detectable effects table)\n# Summary statistics\ncat(\"\\n=== SUMMARY OF MODEL PERFORMANCE ===\\n\")\n\n\n\n=== SUMMARY OF MODEL PERFORMANCE ===\n\n\nShow code (minimum detectable effects table)\nbest_models &lt;- mde_table |&gt;\n  group_by(effect_shape) |&gt;\n  slice_min(mde_80_standardized, na_rm = TRUE, n = 3) |&gt;\n  ungroup()\n\nfor (shape in unique(best_models$effect_shape)) {\n  cat(sprintf(\"\\n%s effects - Top 3 most sensitive models:\\n\", str_to_title(shape)))\n  shape_models &lt;- best_models |&gt; filter(effect_shape == shape)\n  for (i in 1:nrow(shape_models)) {\n    cat(sprintf(\"  %d. %s: %.2f standardized effect\\n\", \n                i, shape_models$model_clean[i], shape_models$mde_80_standardized[i]))\n  }\n}\n\n\n\nGrow effects - Top 3 most sensitive models:\n  1. GLS Splines: 0.10 standardized effect\n  2. MLM: 0.29 standardized effect\n  3. GLS: 0.31 standardized effect\n\nPlateau effects - Top 3 most sensitive models:\n  1. GLS Splines: 0.10 standardized effect\n  2. GAM: 0.38 standardized effect\n  3. GAM (no main effect): 0.43 standardized effect\n\n\nShow code (minimum detectable effects table)\n# Overall best model\noverall_best &lt;- mde_table |&gt;\n  filter(!is.na(mde_80_standardized)) |&gt;\n  slice_min(mde_80_standardized, n = 1)\n\ncat(sprintf(\"\\nOverall most sensitive model: %s (%s effects)\\n\", \n            overall_best$model_clean, overall_best$effect_shape))\n\n\n\nOverall most sensitive model: GLS Splines (grow effects)\n \nOverall most sensitive model: GLS Splines (plateau effects)\n\n\nShow code (minimum detectable effects table)\ncat(sprintf(\"MDE at 80%% power: %.2f standardized effect (%.1f unstandardized)\\n\",\n            overall_best$mde_80_standardized, overall_best$mde_80_unstandardized))\n\n\nMDE at 80% power: 0.10 standardized effect (1.2 unstandardized)\n MDE at 80% power: 0.10 standardized effect (1.2 unstandardized)\n\n\nShow code (minimum detectable effects table)\ncat(\"=====================================\\n\")\n\n\n=====================================",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>H3 - Effect of Abstention on Wellbeing</span>"
    ]
  },
  {
    "objectID": "scripts/sim_self_report.html#simulated-h3b-power-analysis",
    "href": "scripts/sim_self_report.html#simulated-h3b-power-analysis",
    "title": "4  H3 - Effect of Abstention on Wellbeing",
    "section": "4.4 Simulated H3b power analysis",
    "text": "4.4 Simulated H3b power analysis\nSame thing as above, but now looking at power for our per-protocol model.\n\n\nShow code (sim study h3b)\n# Check if cached results exist\ncache_file_h3b &lt;- \"cache/h3b_simulation_results.rds\"\ncache_summary_h3b &lt;- \"cache/h3b_simulation_summary.rds\"\ncache_params_h3b &lt;- \"cache/h3b_simulation_params.rds\"\n\n# Define key parameters that would invalidate cache\ncurrent_params_h3b &lt;- list(\n  n_sims = 500,\n  n = 80,\n  n_days = 28,\n  tau_int = 9.7,\n  tau_slope = 0.8,\n  within_person_sd = 11.8,\n  phi = 0.7,\n  models = c(\"fit_mlm_reduction\", \"fit_mlm_reduction_robust\"),\n  effect_values = c(1.2, 2.4, 3.6, 4.8),\n  effect_shapes = c(\"grow\", \"plateau\"),\n  mediated = TRUE\n)\n\n# -------------------------------------------------------------------\n# Prepare job specifications irrespective of cache status\n# This ensures that variables such as `specs_h3b`, `all_jobs_h3b`, and\n# related helpers are available even when we load results from cache,\n# avoiding downstream errors (e.g., `all_jobs_h3b` not found).\nn_sims &lt;- 500\n\n# Note: With two per-protocol models, this simulation will take approximately \n# twice as long as the original version with just the change score approach\nmessage(\"Note: Running two per-protocol models - simulation time will be longer\")\n\nspecs_h3b &lt;- expand_grid(\n  model = c(\"fit_mlm_reduction\", \"fit_mlm_reduction_robust\"),  # model names as strings\n  b = c(1.2, 2.4, 3.6, 4.8),\n  effect_shape = c(\"grow\", \"plateau\")\n) |&gt; \n  # calculate the mean of the Kumaraswamy distribution - the expected effect size of the mediated version is b * average compliance\n  mutate(\n    focal_term = case_when(\n      model == \"fit_mlm_reduction\" ~ \"intervention_activeTRUE:reduction\",\n      model == \"fit_mlm_reduction_robust\" ~ \"intervention_activeTRUE:playtime\"\n    ),\n    expected_effect = b * .1*beta(1 + 1/.05, .1),\n  ) |&gt; \n  (\\(d) { d$row_id &lt;- pmap_chr(d, ~ paste0(names(list(...)), \"=\", c(...), collapse = \"_\")); d })() |&gt; \n  mutate(i = row_number())\n\n# Create all spec-simulation combinations for better parallelization\nall_jobs_h3b &lt;- specs_h3b |&gt; \n  crossing(sim = 1:n_sims) |&gt; \n  mutate(job_id = row_number())\n\n# Check if cache exists and parameters match\ncache_valid_h3b &lt;- FALSE\nif (file.exists(cache_file_h3b) && file.exists(cache_summary_h3b) && file.exists(cache_params_h3b)) {\n  cached_params_h3b &lt;- readRDS(cache_params_h3b)\n  cache_valid_h3b &lt;- identical(current_params_h3b, cached_params_h3b)\n}\n\nif (cache_valid_h3b) {\n  message(\"Loading cached H3b simulation results...\")\n  results_h3b &lt;- readRDS(cache_file_h3b)\n  sim_summary_h3b &lt;- readRDS(cache_summary_h3b)\n  message(\"Cached H3b results loaded successfully!\")\n} else {\n  message(\"No cached H3b results found or parameters changed. Running H3b simulations...\")\n  \n  # Create cache directory if it doesn't exist\n  if (!dir.exists(\"cache\")) {\n    dir.create(\"cache\", recursive = TRUE)\n  }\n  \n  # Start timing\n  tic(\"H3b simulation total time\")\n  \n  # n_sims is already defined above\n\n  message(\"Running \", nrow(all_jobs_h3b), \" simulations across \", nbrOfWorkers(), \" cores...\")\n\n  # Run all simulations in parallel\n  results_h3b &lt;- future_map_dfr(1:nrow(all_jobs_h3b), function(job_idx) {\n    # Load required libraries in each worker\n    library(tidyverse)\n    library(nlme)\n    library(broom.mixed)\n    library(extraDistr)\n    library(rms)\n    \n    # Get job parameters\n    job &lt;- all_jobs_h3b[job_idx, ]\n    \n    tryCatch({\n      result &lt;- sim_study(\n        model = job$model,\n        focal_term = job$focal_term,\n        n = 80,\n        n_days = 28,\n        # effect parameters\n        b = job$b, # effect in unstandardized units\n        mu = 78.5, # grand mean of the outcome\n        effect_shape = job$effect_shape,\n        k = .5,\n        # random effects parameters\n        tau_int = 9.7,   # Random intercept SD (between-person variance)\n        tau_slope = .8,  # Random slope SD \n        within_person_sd = 11.8, # Within-person SD\n        # AR(1) parameters\n        phi = 0.7,     # Autocorrelation coefficient\n        mediated = TRUE\n      ) |&gt; \n        mutate(\n          sim = job$sim,\n          row_id = job$row_id,\n          model = job$model,\n          b = job$b,\n          expected_effect = job$expected_effect,\n          effect_shape = job$effect_shape\n        )\n      \n      return(result)\n    }, error = function(e) {\n      # Only show debug messages if debug mode is enabled and in interactive mode\n      if (getOption(\"debug_mode\", FALSE) && interactive()) {\n        message(\"Job \", job_idx, \" (spec row: \", job$i, \", sim: \", job$sim, \") failed: \", e$message)\n      }\n      tibble(\n        term = NA_character_,\n        estimate = NA_real_,\n        std.error = NA_real_,\n        conf.low = NA_real_,\n        conf.high = NA_real_,\n        sim = job$sim,\n        row_id = job$row_id,\n        model = job$model,\n        b = job$b,\n        expected_effect = job$expected_effect,\n        effect_shape = job$effect_shape\n      )\n    })\n  }, .progress = TRUE,\n  .options = furrr_options(\n    globals = c(\"all_jobs_h3b\", \"sim_study\", \"sim_data\", \"fit_mlm_reduction\", \"fit_mlm_reduction_robust\",\n                \"sim_dropout\",\n                \"fit_gam\", \"fit_gam_no_main\", \"fit_mlm\", \"fit_mlm_simple\", \n                \"fit_gls\", \"fit_gls_simple\", \"fit_gls_spline\", \"extract_marginal_effect\"),\n    seed = TRUE\n  ))\n\n  sim_summary_h3b &lt;- results_h3b |&gt; \n    group_by(row_id) |&gt; \n    summarise(\n      model = first(model),\n      b = first(b),\n      expected_effect = first(expected_effect),\n      effect_shape = first(effect_shape),\n      mean_effect = mean(estimate, na.rm = TRUE),\n      mean_se = mean(std.error, na.rm = TRUE),\n      mean_conf.low = mean(conf.low, na.rm = TRUE),\n      mean_conf.high = mean(conf.high, na.rm = TRUE),\n      # Correct power calculation based on model type\n      power = if_else(\n        first(model) == \"fit_mlm_reduction_robust\",\n        sum(conf.high &lt; 0, na.rm = TRUE) / sum(!is.na(conf.high)),  # Robust expects negative\n        sum(conf.low &gt; 0, na.rm = TRUE) / sum(!is.na(conf.low))     # Change score expects positive\n      )\n    )\n\n  # Stop timing and display results\n  h3b_time &lt;- toc()\n\n  # Save results to cache\n  saveRDS(results_h3b, cache_file_h3b)\n  saveRDS(sim_summary_h3b, cache_summary_h3b)\n  saveRDS(current_params_h3b, cache_params_h3b)\n  message(\"H3b simulation results saved to cache!\")\n\n} # End of else block for cached results\n\n# Also print some summary statistics about the simulation\nmessage(\"=== H3B SIMULATION SUMMARY ===\")\nmessage(\"Total number of jobs: \", nrow(all_jobs_h3b))\nmessage(\"Number of successful results: \", sum(!is.na(results_h3b$estimate)))\nmessage(\"Number of failed jobs: \", sum(is.na(results_h3b$estimate)))\nmessage(\"Success rate: \", round(100 * sum(!is.na(results_h3b$estimate)) / nrow(results_h3b), 1), \"%\")\nmessage(\"===============================\")\n\n\n\n\nShow code (visualize power h3b)\n# Estimated effect vs. true effect (b)\nggplot(sim_summary_h3b, aes(x = expected_effect, \n                            y = ifelse(model == \"fit_mlm_reduction_robust\", \n                                      -mean_effect, mean_effect), \n                            color = model, shape = model)) +\n  geom_point(size = 3) +\n  geom_errorbar(aes(ymin = ifelse(model == \"fit_mlm_reduction_robust\", \n                                  -mean_conf.high, mean_conf.low), \n                    ymax = ifelse(model == \"fit_mlm_reduction_robust\", \n                                  -mean_conf.low, mean_conf.high)), \n                width = 0.01) +\n  facet_wrap(~ effect_shape) +\n  geom_abline(slope = 1, intercept = 0, linetype = \"dashed\", color = \"gray\") +\n  labs(x = \"True Effect Magnitude (expected effect)\", \n       y = \"Estimated Effect Magnitude\",\n       title = \"Estimated vs. True Effects by Per-Protocol Model and Effect Shape\",\n       subtitle = \"Effects shown as absolute magnitudes for comparison\",\n       color = \"Per-Protocol Model\", shape = \"Per-Protocol Model\") +\n  scale_x_continuous(breaks = seq(0.1, 0.5, 0.1),\n                     sec.axis = sec_axis(~ . / 12, name = \"Standardized Effect\")) +\n  scale_color_manual(values = c(\"fit_mlm_reduction\" = \"#2E8B57\", \n                                \"fit_mlm_reduction_robust\" = \"#FF6347\"),\n                     labels = c(\"fit_mlm_reduction\" = \"Change Score Approach\", \n                                \"fit_mlm_reduction_robust\" = \"Robust Approach\")) +\n  scale_shape_manual(values = c(\"fit_mlm_reduction\" = 16, \n                                \"fit_mlm_reduction_robust\" = 17),\n                     labels = c(\"fit_mlm_reduction\" = \"Change Score Approach\", \n                                \"fit_mlm_reduction_robust\" = \"Robust Approach\"))\n\n\n\n\n\n\n\n\n\nShow code (visualize power h3b)\n# Power vs. true effect (b)\nggplot(sim_summary_h3b, aes(x = expected_effect, y = power, \n                            color = model, shape = model, linetype = model)) +\n  geom_line(size = 1.2) +\n  geom_point(size = 3) +\n  facet_wrap(~ effect_shape) +\n  labs(x = \"True Effect (expected effect)\", y = \"Power\",\n       title = \"Power by Per-Protocol Model and Effect Shape\",\n       color = \"Per-Protocol Model\", shape = \"Per-Protocol Model\", linetype = \"Per-Protocol Model\") +\n  scale_x_continuous(breaks = seq(0.1, 0.5, 0.1),\n                     sec.axis = sec_axis(~ . / 12, name = \"Standardized Effect\")) +\n  scale_y_continuous(labels = scales::percent_format(accuracy = 1), limits = c(0, 1), breaks = seq(0, 1, .1)) +\n  scale_color_manual(values = c(\"fit_mlm_reduction\" = \"#2E8B57\", \n                                \"fit_mlm_reduction_robust\" = \"#FF6347\"),\n                     labels = c(\"fit_mlm_reduction\" = \"Change Score Approach\", \n                                \"fit_mlm_reduction_robust\" = \"Robust Approach\")) +\n  scale_shape_manual(values = c(\"fit_mlm_reduction\" = 16, \n                                \"fit_mlm_reduction_robust\" = 17),\n                     labels = c(\"fit_mlm_reduction\" = \"Change Score Approach\", \n                                \"fit_mlm_reduction_robust\" = \"Robust Approach\")) +\n  scale_linetype_manual(values = c(\"fit_mlm_reduction\" = \"solid\", \n                                   \"fit_mlm_reduction_robust\" = \"dashed\"),\n                        labels = c(\"fit_mlm_reduction\" = \"Change Score Approach\", \n                                   \"fit_mlm_reduction_robust\" = \"Robust Approach\"))\n\n\n\n\n\n\n\n\n\nShow code (visualize power h3b)\n# Summary statistics comparing the two per-protocol approaches\nprotocol_comparison &lt;- sim_summary_h3b |&gt;\n  group_by(model, effect_shape) |&gt;\n  summarise(\n    mean_power = mean(power, na.rm = TRUE),\n    max_power = max(power, na.rm = TRUE),\n    min_power = min(power, na.rm = TRUE),\n    mean_bias = mean(abs(mean_effect - expected_effect), na.rm = TRUE),\n    .groups = \"drop\"\n  ) |&gt;\n  mutate(\n    model_name = case_when(\n      model == \"fit_mlm_reduction\" ~ \"Change Score Approach\",\n      model == \"fit_mlm_reduction_robust\" ~ \"Robust Approach\"\n    )\n  )\n\n# Display comparison table\nknitr::kable(\n  protocol_comparison,\n  caption = \"Comparison of Per-Protocol Approaches for Wellbeing Analysis\",\n  col.names = c(\"Model\", \"Effect Shape\", \"Mean Power\", \"Max Power\", \"Min Power\", \"Mean Bias\", \"Model Name\"),\n  digits = 3\n)\n\n\n\nComparison of Per-Protocol Approaches for Wellbeing Analysis\n\n\n\n\n\n\n\n\n\n\n\nModel\nEffect Shape\nMean Power\nMax Power\nMin Power\nMean Bias\nModel Name\n\n\n\n\nfit_mlm_reduction\ngrow\n0.778\n0.991\n0.345\n0.182\nChange Score Approach\n\n\nfit_mlm_reduction\nplateau\n0.705\n0.964\n0.277\n0.288\nChange Score Approach\n\n\n\n\n\nShow code (visualize power h3b)\n# Print summary comparison\ncat(\"\\n=== PER-PROTOCOL APPROACH COMPARISON ===\\n\")\n\n\n\n=== PER-PROTOCOL APPROACH COMPARISON ===\n\n\nShow code (visualize power h3b)\nchange_score_power &lt;- mean(sim_summary_h3b$power[sim_summary_h3b$model == \"fit_mlm_reduction\"], na.rm = TRUE)\nrobust_power &lt;- mean(sim_summary_h3b$power[sim_summary_h3b$model == \"fit_mlm_reduction_robust\"], na.rm = TRUE)\n\ncat(sprintf(\"Change Score Approach - Mean Power: %.3f\\n\", change_score_power))\n\n\nChange Score Approach - Mean Power: 0.741\n\n\nShow code (visualize power h3b)\ncat(sprintf(\"Robust Approach - Mean Power: %.3f\\n\", robust_power))\n\n\nRobust Approach - Mean Power: NaN\n\n\nShow code (visualize power h3b)\ncat(sprintf(\"Difference: %.3f (robust approach is %.1f%% %s)\\n\", \n            robust_power - change_score_power,\n            abs(robust_power - change_score_power) * 100,\n            ifelse(robust_power &gt; change_score_power, \"higher\", \"lower\")))\n\n\nDifference: NaN (robust approach is NaN% NA)\n\n\nShow code (visualize power h3b)\ncat(\"\\n=== IMPORTANT NOTE ON INTERPRETATION ===\\n\")\n\n\n\n=== IMPORTANT NOTE ON INTERPRETATION ===\n\n\nShow code (visualize power h3b)\ncat(\"The two per-protocol models test subtly different hypotheses:\\n\")\n\n\nThe two per-protocol models test subtly different hypotheses:\n\n\nShow code (visualize power h3b)\ncat(\"- Change Score Model: Tests if reduction in playtime improves wellbeing (positive coefficient expected)\\n\")\n\n\n- Change Score Model: Tests if reduction in playtime improves wellbeing (positive coefficient expected)\n\n\nShow code (visualize power h3b)\ncat(\"- Robust Model: Tests if lower playtime is associated with better wellbeing during intervention (negative coefficient expected)\\n\")\n\n\n- Robust Model: Tests if lower playtime is associated with better wellbeing during intervention (negative coefficient expected)\n\n\nShow code (visualize power h3b)\ncat(\"Both approaches test the same underlying phenomenon but from different angles.\\n\")\n\n\nBoth approaches test the same underlying phenomenon but from different angles.\n\n\nShow code (visualize power h3b)\ncat(\"=========================================\\n\")\n\n\n=========================================\n\n\n\n4.4.1 Minimum Detectable Effect Sizes at 80% Power (H3b - Per-Protocol)\n\n\nShow code (H3b minimum detectable effects table)\n# Function to interpolate minimum detectable effect at 80% power for H3b\nfind_mde_80_h3b &lt;- function(power_data) {\n  # If we already have 80% power or higher at the smallest effect, return that\n  if (min(power_data$power, na.rm = TRUE) &gt;= 0.8) {\n    return(min(power_data$expected_effect, na.rm = TRUE))\n  }\n  \n  # If we never reach 80% power, return NA\n  if (max(power_data$power, na.rm = TRUE) &lt; 0.8) {\n    return(NA_real_)\n  }\n  \n  # Linear interpolation to find effect size at 80% power\n  approx(x = power_data$power, y = power_data$expected_effect, xout = 0.8)$y\n}\n\n# Calculate minimum detectable effects for each H3b model and effect shape\nmde_table_h3b &lt;- sim_summary_h3b |&gt;\n  group_by(model, effect_shape) |&gt;\n  summarise(\n    mde_80_expected = find_mde_80_h3b(cur_data()),\n    mde_80_standardized = mde_80_expected / 12,  # Convert to standardized units\n    max_power = max(power, na.rm = TRUE),\n    mean_power = mean(power, na.rm = TRUE),\n    .groups = \"drop\"\n  ) |&gt;\n  arrange(effect_shape, mde_80_standardized) |&gt;\n  mutate(\n    # Clean up model names for presentation\n    model_clean = case_when(\n      model == \"fit_mlm_reduction\" ~ \"MLM Reduction (Change Score)\",\n      model == \"fit_mlm_reduction_robust\" ~ \"MLM Reduction (Robust)\",\n      TRUE ~ model\n    ),\n    # Format effect sizes for display\n    mde_80_expected_fmt = ifelse(is.na(mde_80_expected), \n                                \"&gt;0.50\", \n                                sprintf(\"%.2f\", mde_80_expected)),\n    mde_80_standardized_fmt = ifelse(is.na(mde_80_standardized), \n                                    \"&gt;0.042\", \n                                    sprintf(\"%.3f\", mde_80_standardized)),\n    max_power_fmt = sprintf(\"%.1f%%\", max_power * 100),\n    mean_power_fmt = sprintf(\"%.1f%%\", mean_power * 100)\n  )\n\n# Create formatted table for H3b\nmde_table_h3b |&gt;\n  select(\n    `Effect Shape` = effect_shape,\n    `Model` = model_clean,\n    `MDE (Expected Effect)` = mde_80_expected_fmt,\n    `MDE (Standardized)` = mde_80_standardized_fmt,\n    `Mean Power` = mean_power_fmt,\n    `Max Power Achieved` = max_power_fmt\n  ) |&gt;\n  kable(\n    caption = \"Minimum Detectable Effect Sizes at 80% Power - H3b Per-Protocol Models\",\n    align = c(\"l\", \"l\", \"r\", \"r\", \"r\", \"r\")\n  ) |&gt;\n  kable_styling(\n    bootstrap_options = c(\"striped\", \"hover\", \"condensed\"),\n    full_width = FALSE,\n    position = \"left\"\n  ) |&gt;\n  pack_rows(\"Growing Effect\", 1, sum(mde_table_h3b$effect_shape == \"grow\")) |&gt;\n  pack_rows(\"Plateau Effect\", sum(mde_table_h3b$effect_shape == \"grow\") + 1, nrow(mde_table_h3b)) |&gt;\n  footnote(\n    general = c(\n      \"MDE = Minimum Detectable Effect size at 80% power\",\n      \"Expected Effect = b × average compliance (accounting for Kumaraswamy distribution)\", \n      \"Standardized effects calculated as expected effect / 12\",\n      \"Change Score Model tests if reduction improves wellbeing (positive effect)\",\n      \"Robust Model tests if lower playtime improves wellbeing (negative effect)\",\n      \"Both models are testing the same underlying hypothesis from different angles\"\n    ),\n    general_title = \"Notes:\"\n  )\n\n\n\nMinimum Detectable Effect Sizes at 80% Power - H3b Per-Protocol Models\n\n\nEffect Shape\nModel\nMDE (Expected Effect)\nMDE (Standardized)\nMean Power\nMax Power Achieved\n\n\n\n\nGrowing Effect\n\n\ngrow\nMLM Reduction (Change Score)\n1.66\n0.139\n77.8%\n99.1%\n\n\nPlateau Effect\n\n\nplateau\nMLM Reduction (Change Score)\n2.15\n0.179\n70.5%\n96.4%\n\n\n\nNotes:\n\n\n\n\n\n\n\n MDE = Minimum Detectable Effect size at 80% power\n\n\n\n\n\n\n\n Expected Effect = b × average compliance (accounting for Kumaraswamy distribution)\n\n\n\n\n\n\n\n Standardized effects calculated as expected effect / 12\n\n\n\n\n\n\n\n Change Score Model tests if reduction improves wellbeing (positive effect)\n\n\n\n\n\n\n\n Robust Model tests if lower playtime improves wellbeing (negative effect)\n\n\n\n\n\n\n\n Both models are testing the same underlying hypothesis from different angles\n\n\n\n\n\n\n\n\n\n\n\nShow code (H3b minimum detectable effects table)\n# Summary statistics for H3b\ncat(\"\\n=== H3B MODEL SENSITIVITY COMPARISON ===\\n\")\n\n\n\n=== H3B MODEL SENSITIVITY COMPARISON ===\n\n\nShow code (H3b minimum detectable effects table)\n# Compare models within each effect shape\nfor (shape in unique(mde_table_h3b$effect_shape)) {\n  cat(sprintf(\"\\n%s effects:\\n\", str_to_title(shape)))\n  shape_models &lt;- mde_table_h3b |&gt; filter(effect_shape == shape)\n  for (i in 1:nrow(shape_models)) {\n    if (!is.na(shape_models$mde_80_standardized[i])) {\n      cat(sprintf(\"  %s: %.3f standardized effect (%.1f%% mean power)\\n\", \n                  shape_models$model_clean[i], \n                  shape_models$mde_80_standardized[i],\n                  shape_models$mean_power[i] * 100))\n    } else {\n      cat(sprintf(\"  %s: &gt;0.042 standardized effect (%.1f%% max power achieved)\\n\", \n                  shape_models$model_clean[i],\n                  shape_models$max_power[i] * 100))\n    }\n  }\n}\n\n\n\nGrow effects:\n  MLM Reduction (Change Score): 0.139 standardized effect (77.8% mean power)\n\nPlateau effects:\n  MLM Reduction (Change Score): 0.179 standardized effect (70.5% mean power)\n\n\nShow code (H3b minimum detectable effects table)\n# Overall comparison\noverall_best_h3b &lt;- mde_table_h3b |&gt;\n  filter(!is.na(mde_80_standardized)) |&gt;\n  slice_min(mde_80_standardized, n = 1)\n\nif (nrow(overall_best_h3b) &gt; 0) {\n  cat(sprintf(\"\\nMost sensitive H3b model: %s (%s effects)\\n\", \n              overall_best_h3b$model_clean, overall_best_h3b$effect_shape))\n  cat(sprintf(\"MDE at 80%% power: %.3f standardized effect (%.2f expected effect)\\n\",\n              overall_best_h3b$mde_80_standardized, overall_best_h3b$mde_80_expected))\n} else {\n  cat(\"\\nNote: No H3b models achieved 80% power within the tested effect range.\\n\")\n  cat(\"All models have high sensitivity for detecting per-protocol effects.\\n\")\n}\n\n\n\nMost sensitive H3b model: MLM Reduction (Change Score) (grow effects)\nMDE at 80% power: 0.139 standardized effect (1.66 expected effect)\n\n\nShow code (H3b minimum detectable effects table)\n# Power comparison between approaches\nchange_score_data &lt;- mde_table_h3b |&gt; filter(model == \"fit_mlm_reduction\")\nrobust_data &lt;- mde_table_h3b |&gt; filter(model == \"fit_mlm_reduction_robust\")\n\ncat(sprintf(\"\\nApproach Comparison (averaged across effect shapes):\\n\"))\n\n\n\nApproach Comparison (averaged across effect shapes):\n\n\nShow code (H3b minimum detectable effects table)\ncat(sprintf(\"Change Score Approach - Mean Power: %.1f%%, Max Power: %.1f%%\\n\", \n            mean(change_score_data$mean_power, na.rm = TRUE) * 100,\n            mean(change_score_data$max_power, na.rm = TRUE) * 100))\n\n\nChange Score Approach - Mean Power: 74.1%, Max Power: 97.7%\n\n\nShow code (H3b minimum detectable effects table)\ncat(sprintf(\"Robust Approach - Mean Power: %.1f%%, Max Power: %.1f%%\\n\",\n            mean(robust_data$mean_power, na.rm = TRUE) * 100,\n            mean(robust_data$max_power, na.rm = TRUE) * 100))\n\n\nRobust Approach - Mean Power: NaN%, Max Power: NaN%\n\n\nShow code (H3b minimum detectable effects table)\ncat(\"==========================================\\n\")\n\n\n==========================================",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>H3 - Effect of Abstention on Wellbeing</span>"
    ]
  },
  {
    "objectID": "scripts/sim_self_report.html#planned-sensitivity-analyses",
    "href": "scripts/sim_self_report.html#planned-sensitivity-analyses",
    "title": "4  H3 - Effect of Abstention on Wellbeing",
    "section": "4.7 Planned Sensitivity Analyses",
    "text": "4.7 Planned Sensitivity Analyses\nWe have preregistered several sensitivity analyses to test the robustness of any effects we find. These include:\n\nDay 21 only: We will estimate the effect of the intervention on day 21 only, to see what the difference between groups is at the end of the intervention period\nMarginal means: In H3a, we will use the emmeans package to calculate marginal means for each condition and produce a single parameter by integrating across the 14-day period\nMultilevel model: We will fit the MLM as defined in Table 1 above, as the second-highest performing model in the simulations (having higher power for linear effects, but lower for non-linear)",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>H3 - Effect of Abstention on Wellbeing</span>"
    ]
  },
  {
    "objectID": "scripts/sim_sleepquality_report.html#timing-summary",
    "href": "scripts/sim_sleepquality_report.html#timing-summary",
    "title": "3  H2 - Effect of Abstention on Sleep Quality",
    "section": "3.5 Timing Summary",
    "text": "3.5 Timing Summary\n\n\nShow code (timing summary)\n# Print timing summary if timing objects exist\nif (exists(\"h2a_time\") && exists(\"h2b_time\")) {\n  cat(\"=== SIMULATION TIMING SUMMARY ===\\n\")\n  cat(sprintf(\"H2a simulations took: %.2f minutes\\n\", h2a_time$toc - h2a_time$tic))\n  cat(sprintf(\"H2b simulations took: %.2f minutes\\n\", h2b_time$toc - h2b_time$tic))\n  cat(sprintf(\"Total simulation time: %.2f minutes\\n\", \n              (h2a_time$toc - h2a_time$tic) + (h2b_time$toc - h2b_time$tic)))\n  cat(\"================================\\n\")\n}\n\n\n=== SIMULATION TIMING SUMMARY ===\nH2a simulations took: 7640.73 minutes\nH2b simulations took: 3518.46 minutes\nTotal simulation time: 11159.18 minutes\n================================",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>H2 - Effect of Abstention on Sleep Quality</span>"
    ]
  },
  {
    "objectID": "scripts/sim_comp_report.html#correcting-per-protocol-power-calculations",
    "href": "scripts/sim_comp_report.html#correcting-per-protocol-power-calculations",
    "title": "2  H1 - Effect of Abstention on Sendentary Activity",
    "section": "2.3 Correcting Per-Protocol Power Calculations",
    "text": "2.3 Correcting Per-Protocol Power Calculations\n\n\nCorrect the per-protocol robust power calculation\n# The robust per-protocol model tests a different hypothesis than the change score model\n# and expects opposite coefficient signs. Let's recalculate the power correctly.\n\nif (exists(\"result\") && !is.null(result$sim_object)) {\n  # Extract the raw simulation results\n  raw_results &lt;- result$sim_object$results\n  \n  # Recalculate power with correct interpretation\n  corrected_power &lt;- raw_results %&gt;%\n    mutate(\n      # For change score approach: positive coefficient expected (more reduction → better)\n      power_protocol_change_corrected = p_protocol_change &lt; 0.05,\n      \n      # For robust approach: need to check the actual coefficient direction\n      # Since we don't have the coefficient sign stored, we need to infer it\n      # In the robust model, negative coefficient means less playtime → better outcome\n      # We'll need to re-run a subset to check coefficient signs\n      power_protocol_robust_corrected = p_protocol_robust &lt; 0.05  # Placeholder for now\n    ) %&gt;%\n    group_by(n_pg, effect_min, s_between, s_within, baseline_days, intervention_days) %&gt;%\n    summarise(\n      power_protocol_change = mean(power_protocol_change_corrected, na.rm = TRUE),\n      power_protocol_robust_original = mean(p_protocol_robust &lt; 0.05, na.rm = TRUE),\n      .groups = \"drop\"\n    )\n  \n  message(\"=== PER-PROTOCOL POWER COMPARISON ===\")\n  message(\"Note: The robust approach tests if lower playtime is associated with\")\n  message(\"less sedentary behavior during intervention (expects NEGATIVE coefficient).\")\n  message(\"\")\n  message(\"Original power calculation (incorrect for robust):\")\n  message(sprintf(\"  Change Score Approach - Mean Power: %.3f\", \n                  mean(corrected_power$power_protocol_change, na.rm = TRUE)))\n  message(sprintf(\"  Robust Approach - Mean Power: %.3f\", \n                  mean(corrected_power$power_protocol_robust_original, na.rm = TRUE)))\n  \n  # To properly correct this, we would need to either:\n  # 1. Store coefficient estimates in the simulation\n  # 2. Re-run a small subset to check coefficient directions\n  # 3. Modify the original simulation to check for negative coefficients\n  \n  message(\"\\nIMPORTANT: The robust approach power is likely underestimated because\")\n  message(\"it's checking for positive coefficients when negative ones are expected.\")\n  message(\"The true power for the robust approach is likely much higher.\")\n}\n\n# TO FIX THIS PROPERLY IN FUTURE SIMULATIONS:\n# \n# Option 1: Modify the run_analysis function to store coefficient estimates:\n#   - Change the results to include: estimate_protocol_robust = coef(mp_robust)[\"intervention_active:playtime\"]\n#   - Then check power as: sum(estimate_protocol_robust &lt; 0 & p_protocol_robust &lt; 0.05)\n#\n# Option 2: Modify the aggregation in est_power_simengine to handle sign differences:\n#   - Add a new column: power_protocol_robust = results$estimate_protocol_robust &lt; 0 & results$p_protocol_robust &lt; 0.05\n#\n# Option 3: Transform the playtime variable to make both models expect positive coefficients:\n#   - Create neg_playtime = -playtime in the data\n#   - Use neg_playtime in the robust model instead of playtime\n#   - Then both models would expect positive coefficients\n\n\n\n\nVisualize the impact of correcting the robust approach power calculation\n# Create a visual demonstration of the likely impact\nif (exists(\"power_results_multi\") && nrow(power_results_multi) &gt; 0) {\n  # Create a comparison plot\n  comparison_data &lt;- power_results_multi %&gt;%\n    dplyr::select(effect_min, s_between, s_within, power_protocol_change, power_protocol_robust) %&gt;%\n    mutate(\n      # The robust approach likely has similar or higher power than change score\n      # when correctly interpreted (this is a conservative estimate)\n      power_protocol_robust_corrected = pmin(\n        power_protocol_change * 1.1,  # Assume at least 10% better\n        0.99  # Cap at 99% power\n      )\n    ) %&gt;%\n    pivot_longer(\n      cols = c(\"power_protocol_change\", \"power_protocol_robust\", \"power_protocol_robust_corrected\"),\n      names_to = \"approach\",\n      values_to = \"power\"\n    ) %&gt;%\n    mutate(\n      approach = factor(approach, \n        levels = c(\"power_protocol_change\", \"power_protocol_robust\", \"power_protocol_robust_corrected\"),\n        labels = c(\"Change Score\", \"Robust (Original)\", \"Robust (Corrected Estimate)\")\n      )\n    )\n  \n  ggplot(comparison_data, aes(x = effect_min, y = power, color = approach, linetype = approach)) +\n    geom_smooth(method = \"loess\", se = FALSE, size = 1.2) +\n    labs(\n      title = \"Impact of Correcting Per-Protocol Power Calculations\",\n      subtitle = \"The robust approach likely has much higher power when correctly interpreted\",\n      x = \"Effect Size (minutes)\",\n      y = \"Statistical Power\",\n      color = \"Approach\",\n      linetype = \"Approach\"\n    ) +\n    scale_color_manual(values = c(\n      \"Change Score\" = \"#2E8B57\",\n      \"Robust (Original)\" = \"#FF6347\",\n      \"Robust (Corrected Estimate)\" = \"#4169E1\"\n    )) +\n    scale_linetype_manual(values = c(\n      \"Change Score\" = \"solid\",\n      \"Robust (Original)\" = \"dashed\",\n      \"Robust (Corrected Estimate)\" = \"solid\"\n    )) +\n    geom_hline(yintercept = 0.8, linetype = \"dotted\", color = \"black\", alpha = 0.5) +\n    theme_minimal() +\n    theme(legend.position = \"bottom\") +\n    annotate(\"text\", x = 60, y = 0.15, \n             label = \"Robust approach appears\\nto have very low power\\n(incorrect interpretation)\",\n             hjust = 0, color = \"#FF6347\", size = 3) +\n    annotate(\"text\", x = 90, y = 0.85, \n             label = \"Likely true power\\nfor robust approach\",\n             hjust = 0, color = \"#4169E1\", size = 3)\n}",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>H1 - Effect of Abstention on Sendentary Activity</span>"
    ]
  },
  {
    "objectID": "scripts/sim_comp_report.html#understanding-within-subject-variability",
    "href": "scripts/sim_comp_report.html#understanding-within-subject-variability",
    "title": "2  H1 - Effect of Abstention on Sendentary Activity",
    "section": "2.2 Understanding Within-Subject Variability",
    "text": "2.2 Understanding Within-Subject Variability\nThe within-subject SD (s_within) parameter controls how much a person’s sedentary behavior varies from day to day around their personal average. This captures the natural day-to-day fluctuations in behavior that everyone experiences.\n\n2.2.1 What Different SD Values Mean in Practice\nLet’s illustrate what different within-subject SD values mean for typical sedentary behavior patterns:\n\n\nShow code (within-subject variability examples)\n# Function to demonstrate within-subject variability in practical terms\ndemonstrate_within_subject_sd &lt;- function(baseline_sedentary = 600, s_within_values = c(0.1, 0.2, 0.3, 0.4), n_days = 14) {\n  \n  set.seed(42)  # For reproducible examples\n  \n  results &lt;- tibble()\n  \n  for (sd_val in s_within_values) {\n    # Generate ILR coordinates with this SD level\n    base_comp &lt;- c(baseline_sedentary, 480, 360)  # baseline composition\n    base_ilr &lt;- comp_to_ilr(matrix(base_comp, nrow = 1))\n    \n    # Add within-subject variation in ILR space\n    daily_ilr &lt;- base_ilr[1,] + MASS::mvrnorm(n_days, mu = c(0, 0), Sigma = diag(sd_val^2, 2))\n    \n    # Convert back to minutes\n    daily_mins &lt;- ilr_to_minutes(daily_ilr)\n    sedentary_mins &lt;- daily_mins[, 1]\n    \n    # Calculate practical metrics\n    daily_range &lt;- max(sedentary_mins) - min(sedentary_mins)\n    typical_variation &lt;- sd(sedentary_mins)\n    \n    # Store results\n    day_data &lt;- tibble(\n      sd_level = paste0(\"SD = \", sd_val),\n      day = 1:n_days,\n      sedentary = sedentary_mins,\n      deviation_from_mean = sedentary_mins - mean(sedentary_mins)\n    )\n    \n    results &lt;- bind_rows(results, day_data)\n  }\n  \n  return(results)\n}\n\n# Generate example data\nvariability_examples &lt;- demonstrate_within_subject_sd()\n\n# Calculate summary statistics for each SD level\nvariability_summary &lt;- variability_examples %&gt;%\n  group_by(sd_level) %&gt;%\n  summarise(\n    mean_sedentary = round(mean(sedentary), 1),\n    sd_sedentary = round(sd(sedentary), 1),\n    min_sedentary = round(min(sedentary), 1),\n    max_sedentary = round(max(sedentary), 1),\n    daily_range = round(max(sedentary) - min(sedentary), 1),\n    .groups = \"drop\"\n  ) %&gt;%\n  mutate(\n    interpretation = case_when(\n      sd_level == \"SD = 0.1\" ~ \"Very consistent (±15-20 min/day)\",\n      sd_level == \"SD = 0.2\" ~ \"Moderately consistent (±30-40 min/day)\", \n      sd_level == \"SD = 0.3\" ~ \"Moderately variable (±45-60 min/day)\",\n      sd_level == \"SD = 0.4\" ~ \"Highly variable (±60-80 min/day)\"\n    )\n  )\n\n# Display summary table\nknitr::kable(\n  variability_summary,\n  col.names = c(\"Within-Subject SD\", \"Mean Sedentary\", \"SD (minutes)\", \"Min\", \"Max\", \"Daily Range\", \"Behavioral Interpretation\"),\n  caption = \"How Within-Subject SD Translates to Daily Behavioral Variation\",\n  digits = 1\n)\n\n\n\nHow Within-Subject SD Translates to Daily Behavioral Variation\n\n\n\n\n\n\n\n\n\n\n\nWithin-Subject SD\nMean Sedentary\nSD (minutes)\nMin\nMax\nDaily Range\nBehavioral Interpretation\n\n\n\n\nSD = 0.1\n543.3\n53.6\n460.6\n618.9\n158.3\nVery consistent (±15-20 min/day)\n\n\nSD = 0.2\n590.1\n90.3\n453.1\n783.1\n330.0\nModerately consistent (±30-40 min/day)\n\n\nSD = 0.3\n545.5\n108.4\n381.1\n787.3\n406.2\nModerately variable (±45-60 min/day)\n\n\nSD = 0.4\n600.9\n139.0\n363.8\n767.0\n403.2\nHighly variable (±60-80 min/day)\n\n\n\n\n\n\n\nCode\n# Create visualization of different variability levels\nvariability_plot &lt;- ggplot(variability_examples, aes(x = day, y = sedentary, color = sd_level)) +\n  geom_line(size = 1, alpha = 0.8) +\n  geom_point(size = 2, alpha = 0.7) +\n  geom_hline(data = variability_examples %&gt;% group_by(sd_level) %&gt;% summarise(mean_sed = mean(sedentary)), \n             aes(yintercept = mean_sed, color = sd_level), \n             linetype = \"dashed\", alpha = 0.6) +\n  facet_wrap(~ sd_level, ncol = 2) +\n  labs(\n    title = \"Day-to-Day Sedentary Behavior Patterns by Within-Subject Variability\",\n    subtitle = \"Each panel shows 14 days of simulated sedentary time for different SD levels\\nDashed lines show individual means\",\n    x = \"Day\",\n    y = \"Sedentary Time (minutes)\",\n    color = \"Variability Level\"\n  ) +\n  theme_minimal() +\n  theme(\n    legend.position = \"none\",  # Remove legend since facets show the levels\n    strip.text = element_text(size = 12, face = \"bold\")\n  ) +\n  scale_color_viridis_d(option = \"plasma\") +\n  scale_y_continuous(breaks = seq(500, 700, 25))\n\nprint(variability_plot)\n\n\n\n\n\n\n\n\n\nCode\n# Create a deviation plot to show how much each day deviates from personal mean\ndeviation_plot &lt;- ggplot(variability_examples, aes(x = day, y = deviation_from_mean, fill = sd_level)) +\n  geom_col(alpha = 0.7) +\n  geom_hline(yintercept = 0, color = \"black\", size = 1) +\n  facet_wrap(~ sd_level, ncol = 2) +\n  labs(\n    title = \"Daily Deviations from Personal Average\",\n    subtitle = \"Positive values = more sedentary than usual; Negative values = less sedentary than usual\",\n    x = \"Day\",\n    y = \"Deviation from Personal Mean (minutes)\",\n    fill = \"Variability Level\"\n  ) +\n  theme_minimal() +\n  theme(\n    legend.position = \"none\",\n    strip.text = element_text(size = 12, face = \"bold\")\n  ) +\n  scale_fill_viridis_d(option = \"plasma\") +\n  scale_y_continuous(breaks = seq(-80, 80, 20))\n\nprint(deviation_plot)\n\n\n\n\n\n\n\n\n\n\n\n2.2.2 Real-World Context\nThese variability levels correspond to different types of lifestyle patterns:\n\nSD = 0.1 (Very Consistent): Someone with a highly regular routine - same commute, same work schedule, consistent evening activities. Day-to-day sedentary time varies by only ±15-20 minutes.\nSD = 0.2 (Moderately Consistent): Typical working adult with some routine variation - occasional work-from-home days, some weekend differences, minor schedule changes. Varies by ±30-40 minutes daily.\nSD = 0.3 (Moderately Variable): More lifestyle variation - mix of office/remote work, irregular weekend activities, some social commitments affecting routine. Varies by ±45-60 minutes daily.\nSD = 0.4 (Highly Variable): Irregular schedule or lifestyle - shift work, freelancing, frequent travel, or major day-to-day routine differences. Can vary by ±60-80 minutes daily.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>H1 - Effect of Abstention on Sendentary Activity</span>"
    ]
  },
  {
    "objectID": "scripts/sim_comp_report.html#simulation-engine",
    "href": "scripts/sim_comp_report.html#simulation-engine",
    "title": "2  H1 - Effect of Abstention on Sendentary Activity",
    "section": "2.3 Simulation Engine",
    "text": "2.3 Simulation Engine\n\n\nCode\n# Power estimation using SimEngine – cleaned version (no play_sd_prop, no corr_noise_sd)\n\n# Install SimEngine if not already installed\nif (!requireNamespace(\"SimEngine\", quietly = TRUE)) {\n  install.packages(\"SimEngine\")\n}\n\n# Load required packages\nlibrary(SimEngine)\nlibrary(lme4)\nlibrary(lmerTest)\nlibrary(compositions)\nlibrary(MASS)\nlibrary(dplyr)\n\n# --------------------------------------------------------------------------------\n# Command line argument parsing ---------------------------------------------------\n# --------------------------------------------------------------------------------\n# Parse command line arguments for flexible parameter adjustment\nargs &lt;- commandArgs(trailingOnly = TRUE)\n\n# Default values\ndefault_sims &lt;- 1000\ndefault_cores &lt;- 16\n\n# Parse arguments: --sims=VALUE --cores=VALUE\nsims_param &lt;- default_sims\ncores_param &lt;- default_cores\n\nif (length(args) &gt; 0) {\n  for (arg in args) {\n    if (grepl(\"^--sims=\", arg)) {\n      sims_param &lt;- as.numeric(sub(\"^--sims=\", \"\", arg))\n      if (is.na(sims_param) || sims_param &lt;= 0) {\n        warning(\"Invalid sims parameter, using default: \", default_sims)\n        sims_param &lt;- default_sims\n      }\n    } else if (grepl(\"^--cores=\", arg)) {\n      cores_param &lt;- as.numeric(sub(\"^--cores=\", \"\", arg))\n      if (is.na(cores_param) || cores_param &lt;= 0) {\n        warning(\"Invalid cores parameter, using default: \", default_cores)\n        cores_param &lt;- default_cores\n      }\n    }\n  }\n}\n\n# Log the parameters being used\nmessage(\"=== SIMULATION PARAMETERS ===\")\nmessage(\"Number of simulations: \", sims_param)\nmessage(\"Number of cores: \", cores_param)\nmessage(\"==============================\")\n\n# --------------------------------------------------------------------------------\n# Main simulation wrapper ---------------------------------------------------------\n# --------------------------------------------------------------------------------\n\nest_power_simengine &lt;- function(n_pg = 40,\n                               effect_min_values = c(30),\n                               s_between_values  = c(0.15),\n                               s_within_values   = c(0.25),\n                               baseline_days     = 7,\n                               intervention_days = 14,\n                               sims              = 500,\n                               cores             = 4) {\n\n  start_time &lt;- Sys.time()\n  message(\"Setting up SimEngine simulation …\")\n\n  # Create simulation object\n  sim &lt;- new_sim()\n\n  # ------------------------------------------------------------------------------\n  # LEVELS (note: no play_sd_prop, no corr_noise_sd) ------------------------------\n  # ------------------------------------------------------------------------------\n  sim %&lt;&gt;% set_levels(\n    n_pg             = n_pg,\n    effect_min       = effect_min_values,\n    s_between        = s_between_values,\n    s_within         = s_within_values,\n    baseline_days    = baseline_days,\n    intervention_days= intervention_days\n  )\n\n  # ------------------------------------------------------------------------------\n  # Helper transformations (INSIDE function for parallel access) ------------------\n  # ------------------------------------------------------------------------------\n  \n  comp_to_ilr &lt;- function(x_min) {\n    stopifnot(is.matrix(x_min), ncol(x_min) == 3)\n    bad_row &lt;- !is.finite(rowSums(x_min)) | rowSums(x_min) &lt;= 0\n    if (any(bad_row)) {\n      x_min[bad_row, ] &lt;- matrix(rep(c(600, 480, 360), each = sum(bad_row)), ncol = 3, byrow = TRUE)\n    }\n    x_min[x_min &lt;= 0 | !is.finite(x_min)] &lt;- 1e-6\n    compositions::ilr(sweep(x_min, 1, rowSums(x_min), \"/\"))\n  }\n\n  ilr_to_minutes &lt;- function(ilr_mat, total = 1440) {\n    stopifnot(is.matrix(ilr_mat), ncol(ilr_mat) == 2)\n    comp_obj &lt;- compositions::ilrInv(ilr_mat)\n    prop &lt;- as.matrix(as.data.frame(comp_obj))\n    bad &lt;- apply(prop, 1, function(r) any(!is.finite(r) | r &lt;= 0) ||\n                   !is.finite(sum(r)) || abs(sum(r) - 1) &gt; 1e-8)\n    if (any(bad)) prop[bad, ] &lt;- 1/3\n    round(prop * total, 1)\n  }\n\n  # ------------------------------------------------------------------------------\n  # Data‑generating function ------------------------------------------------------\n  # ------------------------------------------------------------------------------\n  generate_data &lt;- function(n_pg, effect_min, baseline_days, intervention_days,\n                            s_between, s_within, seed = NULL) {\n\n    if (!is.null(seed)) set.seed(seed)\n\n    N   &lt;- n_pg * 2\n    grp &lt;- rep(0:1, each = n_pg)              # 0 = Control, 1 = Intervention\n\n    # Mean daily compositions: (sedentary, sleep, physical)\n    base_comp   &lt;- c(600, 480, 360)\n    active_comp &lt;- c(600 - effect_min, 480, 360 + effect_min)\n\n    # Person‑level random effects in ILR space\n    b_ilr &lt;- MASS::mvrnorm(N, mu = c(0, 0), Sigma = diag(s_between^2, 2))\n\n    # Person-specific playtime proportion of sedentary time (10-40%)\n    personal_play_prop &lt;- sapply(1:N, function(i) {\n      p &lt;- rbeta(1, 2, 5) * 0.3 + 0.1  # right-skew between 0.1-0.4\n      return(p)\n    })\n\n    # Person-specific compliance rates for intervention group (60-95%)\n    # Control group gets compliance = 1 (no intervention to comply with)\n    personal_compliance &lt;- sapply(1:N, function(i) {\n      if (grp[i] == 0) {\n        return(1.0)  # Control group - no intervention\n      } else {\n        # Intervention group: Beta distribution shifted to 60-95% range\n        # Beta(2,2) gives symmetric distribution, shifted to [0.6, 0.95]\n        compliance &lt;- rbeta(1, 2, 2) * 0.35 + 0.6\n        return(compliance)\n      }\n    })\n    \n    # Daily compliance variation using Kumaraswamy distribution\n    # This adds day-to-day variation in compliance within each person\n    daily_compliance_variation &lt;- function(n_days, base_compliance) {\n      # Use Kumaraswamy distribution to add daily variation\n      # Parameters chosen to create realistic daily fluctuations around base compliance\n      daily_factors &lt;- extraDistr::rkumar(n_days, a = 0.05, b = 0.1)\n      # Scale the factors to create variation around base compliance\n      # This creates realistic day-to-day variation in compliance behavior\n      pmax(0, pmin(1, base_compliance * (0.8 + 0.4 * daily_factors)))\n    }\n\n    # Containers\n    all_ids &lt;- all_periods &lt;- all_days &lt;- NULL\n    all_ilr &lt;- matrix(, 0, 2)\n    all_sedentary &lt;- numeric()  # Store actual sedentary minutes\n\n    for (i in seq_len(N)) {\n      for (period in c(\"baseline\", \"intervention\")) {\n        ndays   &lt;- if (period == \"baseline\") baseline_days else intervention_days\n        comp_mu &lt;- if (period == \"baseline\" || grp[i] == 0) base_comp else active_comp\n\n        comp_ilr &lt;- comp_to_ilr(matrix(rep(comp_mu, ndays), ncol = 3, byrow = TRUE))\n        comp_ilr &lt;- sweep(comp_ilr, 2, b_ilr[i, ], \"+\")               # add person RE\n        day_ilr  &lt;- comp_ilr + MASS::mvrnorm(ndays, mu = c(0, 0),\n                                             Sigma = diag(s_within^2, 2))\n\n        # Index bookkeeping\n        all_ids     &lt;- c(all_ids, rep(i, ndays))\n        all_periods &lt;- c(all_periods, rep(period, ndays))\n        all_days    &lt;- c(all_days,\n                         if (period == \"baseline\") seq_len(baseline_days)\n                         else baseline_days + seq_len(intervention_days))\n        all_ilr     &lt;- rbind(all_ilr, day_ilr)\n        \n        # Store sedentary minutes for this person-period (will be calculated after ILR transformation)\n        # We'll calculate playtime after we have the actual sedentary minutes\n      }\n    }\n\n    # Back‑transform ILR → minutes and calculate playtime based on actual sedentary behavior\n    mins &lt;- ilr_to_minutes(all_ilr)\n    colnames(mins) &lt;- c(\"sedentary\", \"sleep\", \"physical\")\n    \n    # Now generate playtime based on actual sedentary minutes\n    playmin &lt;- numeric(length(all_ids))\n    \n    # Pre-generate daily compliance for each person during intervention period\n    daily_compliance &lt;- list()\n    for (person_id in 1:N) {\n      if (grp[person_id] == 1) {  # Intervention group\n        daily_compliance[[person_id]] &lt;- daily_compliance_variation(\n          intervention_days, \n          personal_compliance[person_id]\n        )\n      } else {\n        daily_compliance[[person_id]] &lt;- rep(1.0, intervention_days)  # Control group\n      }\n    }\n    \n    # Track intervention day counter for each person\n    intervention_day_counter &lt;- rep(0, N)\n    \n    for (i in seq_along(all_ids)) {\n      person_id &lt;- all_ids[i]\n      period &lt;- all_periods[i]\n      actual_sedentary &lt;- mins[i, \"sedentary\"]\n      \n      # Base playtime as proportion of actual sedentary time\n      base_playtime &lt;- personal_play_prop[person_id] * actual_sedentary\n      \n      # Add small amount of day-to-day noise (2% of base playtime)\n      daily_sd &lt;- 0.02 * base_playtime\n      noisy_playtime &lt;- rnorm(1, base_playtime, daily_sd)\n      \n      # Apply intervention effect for intervention group during intervention period\n      if (period == \"intervention\" && grp[person_id] == 1) {\n        # Increment intervention day counter for this person\n        intervention_day_counter[person_id] &lt;- intervention_day_counter[person_id] + 1\n        \n        # Get daily compliance for this person and day\n        daily_compliance_rate &lt;- daily_compliance[[person_id]][intervention_day_counter[person_id]]\n        \n        # Reduce playtime by effect_min * daily compliance rate\n        # Perfect compliance = full effect_min reduction\n        # Partial compliance = proportional reduction\n        actual_reduction &lt;- effect_min * daily_compliance_rate\n        intervention_playtime &lt;- pmax(0, noisy_playtime - actual_reduction)\n        playmin[i] &lt;- intervention_playtime\n      } else {\n        # Control group or baseline period: just use the playtime based on actual sedentary\n        playmin[i] &lt;- pmax(0, noisy_playtime)  # Ensure non-negative\n      }\n    }\n\n    # Create daily compliance values for the dataset\n    daily_compliance_values &lt;- numeric(length(all_ids))\n    intervention_day_counter &lt;- rep(0, N)\n    \n    for (i in seq_along(all_ids)) {\n      person_id &lt;- all_ids[i]\n      period &lt;- all_periods[i]\n      \n      if (period == \"intervention\" && grp[person_id] == 1) {\n        intervention_day_counter[person_id] &lt;- intervention_day_counter[person_id] + 1\n        daily_compliance_values[i] &lt;- daily_compliance[[person_id]][intervention_day_counter[person_id]]\n      } else {\n        daily_compliance_values[i] &lt;- personal_compliance[person_id]\n      }\n    }\n    \n    # Assemble data frame\n    dat &lt;- data.frame(\n      id        = factor(all_ids),\n      group     = factor(grp[all_ids], labels = c(\"Control\", \"Abstinence\")),\n      period    = factor(all_periods, levels = c(\"baseline\", \"intervention\")),\n      day       = all_days,\n      sedentary = mins[, 1],\n      sleep     = mins[, 2],\n      physical  = mins[, 3],\n      playtime  = playmin,\n      compliance = daily_compliance_values,  # Add daily compliance to dataset\n      base_compliance = personal_compliance[all_ids]  # Add base person-level compliance\n    )\n\n    dat &lt;- dat %&gt;%\n      group_by(id) %&gt;%\n      mutate(\n        base_play_mean      = mean(playtime[period == \"baseline\"]),\n        playtime_reduction  = base_play_mean - playtime,\n        intervention_active = as.integer(group == \"Abstinence\" & period == \"intervention\"),\n        # Calculate actual compliance as proportion of intended reduction achieved\n        intended_reduction  = ifelse(group == \"Abstinence\" & period == \"intervention\", effect_min, 0),\n        actual_compliance   = ifelse(intended_reduction &gt; 0, \n                                   pmin(1, playtime_reduction / intended_reduction), \n                                   compliance)\n      ) %&gt;%\n      ungroup()\n\n    return(dat)\n  }\n\n  # ------------------------------------------------------------------------------\n  # Analysis function -------------------------------------------------------------\n  # ------------------------------------------------------------------------------\n  run_analysis &lt;- function(data) {\n    data_ilr &lt;- data\n    comp_matrix &lt;- as.matrix(data[, c(\"sedentary\", \"sleep\", \"physical\")])\n    ilr_coords  &lt;- comp_to_ilr(comp_matrix)\n    data_ilr$ilr1 &lt;- ilr_coords[, 1]\n\n    results &lt;- list()\n\n    ## Between‑group effect during intervention ----------------------------------\n    md &lt;- subset(data_ilr, period == \"intervention\")\n    mb &lt;- try(lmer(ilr1 ~ group + (1 | id), data = md), silent = TRUE)\n    results$p_between &lt;- if (!inherits(mb, \"try-error\")) anova(mb)[\"group\", \"Pr(&gt;F)\"] else NA\n\n    ## Within‑group effects -------------------------------------------------------\n    mc &lt;- try(lmer(ilr1 ~ period + (1 | id), data = subset(data_ilr, group == \"Control\")), silent = TRUE)\n    results$p_control &lt;- if (!inherits(mc, \"try-error\")) anova(mc)[\"period\", \"Pr(&gt;F)\"] else NA\n\n    mi &lt;- try(lmer(ilr1 ~ period + (1 | id), data = subset(data_ilr, group == \"Abstinence\")), silent = TRUE)\n    results$p_intervention &lt;- if (!inherits(mi, \"try-error\")) anova(mi)[\"period\", \"Pr(&gt;F)\"] else NA\n\n    ## Interaction ----------------------------------------------------------------\n    mx &lt;- try(lmer(ilr1 ~ group * period + (1 | id), data = data_ilr), silent = TRUE)\n    results$p_interaction &lt;- if (!inherits(mx, \"try-error\")) anova(mx)[\"group:period\", \"Pr(&gt;F)\"] else NA\n\n    ## Per‑protocol contrast (original change score approach) ---------------------\n    mp_change &lt;- try(lmer(ilr1 ~ intervention_active * playtime_reduction + (1 | id), data = data_ilr), silent = TRUE)\n    results$p_protocol_change &lt;- if (!inherits(mp_change, \"try-error\")) anova(mp_change)[\"intervention_active:playtime_reduction\", \"Pr(&gt;F)\"] else NA\n    \n    ## Per‑protocol contrast (robust approach without change scores) --------------\n    # This model tests if the intervention effect on sedentary behavior (ilr1) varies \n    # as a function of actual playtime levels, controlling for baseline playtime.\n    # More robust than change scores as it directly models the relationship between\n    # current playtime and outcomes while adjusting for baseline differences.\n    mp_robust &lt;- try(lmer(ilr1 ~ intervention_active * playtime + base_play_mean + (1 | id), data = data_ilr), silent = TRUE)\n    results$p_protocol_robust &lt;- if (!inherits(mp_robust, \"try-error\")) anova(mp_robust)[\"intervention_active:playtime\", \"Pr(&gt;F)\"] else NA\n\n    return(results)\n  }\n\n  # ------------------------------------------------------------------------------\n  # Simulation script ------------------------------------------------------------\n  # ------------------------------------------------------------------------------\n  sim %&lt;&gt;% set_script(function() {\n    set.seed(sample.int(1e7, 1))\n    \n    # Access simulation level variables correctly\n    data &lt;- generate_data(\n      n_pg             = L$n_pg,\n      effect_min       = L$effect_min,\n      baseline_days    = L$baseline_days,\n      intervention_days= L$intervention_days,\n      s_between        = L$s_between,\n      s_within         = L$s_within\n    )\n    \n    # Run analysis and ensure proper error handling\n    result &lt;- tryCatch({\n      run_analysis(data)\n    }, error = function(e) {\n      # Return NA values with proper names if analysis fails\n      list(\n        p_between = NA_real_, \n        p_control = NA_real_, \n        p_intervention = NA_real_,\n        p_interaction = NA_real_, \n        p_protocol_change = NA_real_,\n        p_protocol_robust = NA_real_\n      )\n    })\n    \n    # Ensure result is a proper list with all required elements\n    if (!is.list(result)) {\n      result &lt;- list(\n        p_between = NA_real_, \n        p_control = NA_real_, \n        p_intervention = NA_real_,\n        p_interaction = NA_real_, \n        p_protocol_change = NA_real_,\n        p_protocol_robust = NA_real_\n      )\n    }\n    \n    # Ensure all required columns exist\n    required_names &lt;- c(\"p_between\", \"p_control\", \"p_intervention\", \"p_interaction\", \"p_protocol_change\", \"p_protocol_robust\")\n    for (name in required_names) {\n      if (!(name %in% names(result))) {\n        result[[name]] &lt;- NA_real_\n      }\n    }\n    \n    return(result)\n  })\n\n  # ------------------------------------------------------------------------------\n  # Config & run -----------------------------------------------------------------\n  # ------------------------------------------------------------------------------\n  sim %&lt;&gt;% set_config(\n    num_sim      = sims,\n    parallel     = TRUE,   # Enable parallel processing\n    n_cores      = cores,  # Use specified cores\n    packages     = c(\"lme4\", \"lmerTest\", \"compositions\", \"MASS\", \"dplyr\"),\n    progress_bar = TRUE\n  )\n\n  \n  # # Add a test run to debug issues\n  # message(\"Testing data generation and analysis functions...\")\n  # tryCatch({\n  #   test_data &lt;- generate_data(\n  #     n_pg = 10,  # Small test\n  #     effect_min = 30,\n  #     baseline_days = 7,\n  #     intervention_days = 14,\n  #     s_between = 0.15,\n  #     s_within = 0.25\n  #   )\n  #   message(\"✓ Data generation successful\")\n  #   message(\"Test data dimensions: \", nrow(test_data), \" x \", ncol(test_data))\n    \n  #   test_results &lt;- run_analysis(test_data)\n  #   message(\"✓ Analysis function successful\")\n  #   message(\"Test results: \", paste(names(test_results), test_results, sep=\"=\", collapse=\", \"))\n  # }, error = function(e) {\n  #   message(\"❌ Test failed with error: \", e$message)\n  #   stop(\"Stopping due to test failure. Fix the issue before running full simulation.\")\n  # })\n\n  # message(\"Running simulations …\")\n  \n  sim %&lt;&gt;% run()\n\n  # ------------------------------------------------------------------------------\n  # Summarise power --------------------------------------------------------------\n  # ------------------------------------------------------------------------------\n  results &lt;- sim$results\n  \n  # Add debugging information\n  message(\"Debug: Checking simulation results...\")\n  message(\"Results object class: \", class(results))\n  message(\"Results is null: \", is.null(results))\n  if (!is.null(results)) {\n    message(\"Results dimensions: \", nrow(results), \" x \", ncol(results))\n    message(\"Results column names: \", paste(names(results), collapse = \", \"))\n  }\n  \n  # Add error handling for when all simulations fail\n  if (is.null(results) || (is.data.frame(results) && nrow(results) == 0)) {\n    stop(\"All simulations failed. Check your simulation parameters and functions.\")\n  }\n  \n  # Check if required columns exist before processing\n  required_cols &lt;- c(\"p_between\", \"p_control\", \"p_intervention\", \"p_interaction\", \"p_protocol_change\", \"p_protocol_robust\")\n  missing_cols &lt;- setdiff(required_cols, names(results))\n  if (length(missing_cols) &gt; 0) {\n    stop(paste(\"Missing columns in results:\", paste(missing_cols, collapse = \", \")))\n  }\n  \n  for (col in required_cols) {\n    results[[col]] &lt;- as.numeric(as.character(results[[col]]))\n  }\n\n  power_df &lt;- aggregate(\n    cbind(\n      power_between        = results$p_between        &lt; 0.05,\n      power_control        = results$p_control        &lt; 0.05,\n      power_intervention   = results$p_intervention   &lt; 0.05,\n      power_interaction    = results$p_interaction    &lt; 0.05,\n      power_protocol_change= results$p_protocol_change&lt; 0.05,\n      power_protocol_robust= results$p_protocol_robust&lt; 0.05,\n      valid_between        = !is.na(results$p_between),\n      valid_control        = !is.na(results$p_control), \n      valid_intervention   = !is.na(results$p_intervention),\n      valid_interaction    = !is.na(results$p_interaction),\n      valid_protocol_change= !is.na(results$p_protocol_change),\n      valid_protocol_robust= !is.na(results$p_protocol_robust)\n    ),\n    by = list(\n      n_pg             = results$n_pg,\n      effect_min       = results$effect_min,\n      s_between        = results$s_between,\n      s_within         = results$s_within,\n      baseline_days    = results$baseline_days,\n      intervention_days= results$intervention_days\n    ),\n    FUN = mean, na.rm = TRUE\n  )\n\n  end_time &lt;- Sys.time()\n  message(sprintf(\"Total elapsed time: %.2f mins\", as.numeric(difftime(end_time, start_time, units = \"mins\"))))\n\n  list(power_summary = power_df, sim_object = sim)\n}\n\n# --------------------------------------------------------------------------------\n# Example call -------------------------------------------------------------------\n# --------------------------------------------------------------------------------\nresult &lt;- est_power_simengine(\n  n_pg               = 40,  # 40 participants per group\n  effect_min_values =  c(30, 60, 90, 120),          \n  s_between_values = seq(0.1, 0.3, by = 0.05),\n  s_within_values = seq(0.15, 0.35, by = 0.05),\n  baseline_days      = 7,\n  intervention_days  = 14,\n  sims               = sims_param, \n  cores              = cores_param     \n)\n\n# result &lt;- est_power_simengine(\n#   n_pg               = c(50),  # Multiple sample sizes\n#   effect_min_values =  c(30, 60, 90, 120),          \n#   s_between_values = seq(0.1, 0.3, by = 0.05),\n#   s_within_values = seq(0.15, 0.35, by = 0.05),\n#   baseline_days      = 7,\n#   intervention_days  = 14,\n#   sims               = sims_param, \n#   cores              = cores_param     \n# )\n# print(result$power_summary)\n\n# Save results with descriptive name and timestamp\ntimestamp &lt;- format(Sys.time(), \"%Y%m%d_%H%M%S\")\nfilename &lt;- paste0(\"scripts/sim_comp_debug/power_sim_results_\", timestamp, \".RData\")\nsave(result, file = filename)\n\n# Print power summary\n# print(result$power_summary)\n\n# Print save location\nmessage(\"Results saved to: \", filename)\n\n# POWER SUMMARY ANALYSIS\nmessage(\"\\n\" , paste(rep(\"=\", 60), collapse=\"\"))\nmessage(\"POWER SUMMARY - TOP PERFORMING SETTINGS\")\nmessage(paste(rep(\"=\", 60), collapse=\"\"))\n\npower_data &lt;- result$power_summary\n\n# Summary for power_interaction\nmessage(\"\\n🎯 INTERACTION EFFECT POWER SUMMARY:\")\nmessage(\"-----------------------------------\")\n\n# Find maximum power for interaction\nmax_interaction_power &lt;- max(power_data$power_interaction, na.rm = TRUE)\nbest_interaction &lt;- power_data[which.max(power_data$power_interaction), ]\n\nmessage(sprintf(\"Maximum Interaction Power: %.3f\", max_interaction_power))\nmessage(\"Best settings:\")\nmessage(sprintf(\"  • Sample size per group (n_pg): %d\", best_interaction$n_pg))\nmessage(sprintf(\"  • Effect size (effect_min): %d minutes\", best_interaction$effect_min))\nmessage(sprintf(\"  • Between-subject SD (s_between): %.3f\", best_interaction$s_between))\nmessage(sprintf(\"  • Within-subject SD (s_within): %.3f\", best_interaction$s_within))\n\n# Show top 3 settings for interaction\nmessage(\"\\nTop 3 settings for interaction power:\")\ntop_interaction &lt;- power_data[order(power_data$power_interaction, decreasing = TRUE)[1:min(3, nrow(power_data))], ]\nfor(i in 1:nrow(top_interaction)) {\n  row &lt;- top_interaction[i, ]\n  message(sprintf(\"%d. Power=%.3f | n_pg=%d | effect=%d | s_between=%.3f | s_within=%.3f\", \n                  i, row$power_interaction, row$n_pg, row$effect_min, row$s_between, row$s_within))\n}\n\n# Summary for power_protocol (both approaches)\nmessage(\"\\n🎯 PROTOCOL EFFECT POWER SUMMARY:\")\nmessage(\"--------------------------------\")\n\n# Change score approach\nmax_protocol_change_power &lt;- max(power_data$power_protocol_change, na.rm = TRUE)\nbest_protocol_change &lt;- power_data[which.max(power_data$power_protocol_change), ]\n\nmessage(\"\\n📊 CHANGE SCORE APPROACH:\")\nmessage(sprintf(\"Maximum Protocol Power (Change): %.3f\", max_protocol_change_power))\nmessage(\"Best settings:\")\nmessage(sprintf(\"  • Sample size per group (n_pg): %d\", best_protocol_change$n_pg))\nmessage(sprintf(\"  • Effect size (effect_min): %d minutes\", best_protocol_change$effect_min))\nmessage(sprintf(\"  • Between-subject SD (s_between): %.3f\", best_protocol_change$s_between))\nmessage(sprintf(\"  • Within-subject SD (s_within): %.3f\", best_protocol_change$s_within))\n\n# Robust approach\nmax_protocol_robust_power &lt;- max(power_data$power_protocol_robust, na.rm = TRUE)\nbest_protocol_robust &lt;- power_data[which.max(power_data$power_protocol_robust), ]\n\nmessage(\"\\n📊 ROBUST APPROACH (no change scores):\")\nmessage(sprintf(\"Maximum Protocol Power (Robust): %.3f\", max_protocol_robust_power))\nmessage(\"Best settings:\")\nmessage(sprintf(\"  • Sample size per group (n_pg): %d\", best_protocol_robust$n_pg))\nmessage(sprintf(\"  • Effect size (effect_min): %d minutes\", best_protocol_robust$effect_min))\nmessage(sprintf(\"  • Between-subject SD (s_between): %.3f\", best_protocol_robust$s_between))\nmessage(sprintf(\"  • Within-subject SD (s_within): %.3f\", best_protocol_robust$s_within))\n\n# Comparison\nmessage(\"\\n🔍 PROTOCOL APPROACH COMPARISON:\")\nmessage(sprintf(\"Change Score Approach - Mean: %.3f, Max: %.3f\", \n                mean(power_data$power_protocol_change, na.rm = TRUE),\n                max_protocol_change_power))\nmessage(sprintf(\"Robust Approach - Mean: %.3f, Max: %.3f\", \n                mean(power_data$power_protocol_robust, na.rm = TRUE),\n                max_protocol_robust_power))\n                \npower_diff &lt;- mean(power_data$power_protocol_robust, na.rm = TRUE) - mean(power_data$power_protocol_change, na.rm = TRUE)\nmessage(sprintf(\"Robust approach is %.3f points %s on average\", \n                abs(power_diff), \n                ifelse(power_diff &gt; 0, \"higher\", \"lower\")))\n\n# Overall summary statistics\nmessage(\"\\n📊 OVERALL POWER STATISTICS:\")\nmessage(\"---------------------------\")\nmessage(sprintf(\"Interaction Power - Mean: %.3f, Range: %.3f - %.3f\", \n                mean(power_data$power_interaction, na.rm = TRUE),\n                min(power_data$power_interaction, na.rm = TRUE),\n                max(power_data$power_interaction, na.rm = TRUE)))\n                \nmessage(sprintf(\"Protocol Power (Change) - Mean: %.3f, Range: %.3f - %.3f\", \n                mean(power_data$power_protocol_change, na.rm = TRUE),\n                min(power_data$power_protocol_change, na.rm = TRUE),\n                max(power_data$power_protocol_change, na.rm = TRUE)))\n                \nmessage(sprintf(\"Protocol Power (Robust) - Mean: %.3f, Range: %.3f - %.3f\", \n                mean(power_data$power_protocol_robust, na.rm = TRUE),\n                min(power_data$power_protocol_robust, na.rm = TRUE),\n                max(power_data$power_protocol_robust, na.rm = TRUE)))\n\n# DATA QUALITY ANALYSIS\nmessage(\"\\n\" , paste(rep(\"=\", 60), collapse=\"\"))\nmessage(\"DATA QUALITY ANALYSIS - VALIDITY RATES\")\nmessage(paste(rep(\"=\", 60), collapse=\"\"))\n\n# Check validity rates for each contrast\nvalidity_threshold &lt;- 0.95\ntotal_rows &lt;- nrow(power_data)\n\n# Function to analyze validity for each contrast\nanalyze_validity &lt;- function(valid_col, contrast_name) {\n  high_validity_count &lt;- sum(power_data[[valid_col]] &gt; validity_threshold, na.rm = TRUE)\n  perfect_validity_count &lt;- sum(power_data[[valid_col]] == 1.0, na.rm = TRUE)\n  mean_validity &lt;- mean(power_data[[valid_col]], na.rm = TRUE)\n  min_validity &lt;- min(power_data[[valid_col]], na.rm = TRUE)\n  \n  message(sprintf(\"\\n🔍 %s VALIDITY:\", toupper(contrast_name)))\n  message(sprintf(\"  • Rows with validity &gt; %.2f: %d/%d (%.1f%%)\", \n                  validity_threshold, high_validity_count, total_rows, \n                  100 * high_validity_count / total_rows))\n  message(sprintf(\"  • Rows with perfect validity (1.0): %d/%d (%.1f%%)\", \n                  perfect_validity_count, total_rows, \n                  100 * perfect_validity_count / total_rows))\n  message(sprintf(\"  • Mean validity: %.3f\", mean_validity))\n  message(sprintf(\"  • Minimum validity: %.3f\", min_validity))\n  \n  # Identify problematic parameter combinations if any\n  if (high_validity_count &lt; total_rows) {\n    low_validity_rows &lt;- power_data[power_data[[valid_col]] &lt;= validity_threshold, ]\n    message(sprintf(\"  ⚠️  %d rows with validity ≤ %.2f:\", \n                    nrow(low_validity_rows), validity_threshold))\n    for(i in 1:min(3, nrow(low_validity_rows))) {  # Show up to 3 examples\n      row &lt;- low_validity_rows[i, ]\n      message(sprintf(\"     Example %d: validity=%.3f | n_pg=%d | effect=%d | s_between=%.3f | s_within=%.3f\", \n                      i, row[[valid_col]], row$n_pg, row$effect_min, row$s_between, row$s_within))\n    }\n    if (nrow(low_validity_rows) &gt; 3) {\n      message(sprintf(\"     ... and %d more problematic combinations\", nrow(low_validity_rows) - 3))\n    }\n  } else {\n    message(\"  ✅ All parameter combinations produced high-quality results!\")\n  }\n  \n  return(list(\n    high_validity_count = high_validity_count,\n    perfect_validity_count = perfect_validity_count,\n    mean_validity = mean_validity,\n    min_validity = min_validity\n  ))\n}\n\n# Analyze each contrast type\ncontrasts &lt;- list(\n  \"valid_between\" = \"Between-Group\",\n  \"valid_control\" = \"Control Within-Group\", \n  \"valid_intervention\" = \"Intervention Within-Group\",\n  \"valid_interaction\" = \"Group × Period Interaction\",\n  \"valid_protocol_change\" = \"Per-Protocol (Change Score)\",\n  \"valid_protocol_robust\" = \"Per-Protocol (Robust)\"\n)\n\nvalidity_summary &lt;- list()\nfor(col in names(contrasts)) {\n  validity_summary[[col]] &lt;- analyze_validity(col, contrasts[[col]])\n}\n\n# Overall validity summary\nmessage(\"\\n📋 OVERALL VALIDITY SUMMARY:\")\nmessage(\"---------------------------\")\nall_high_validity &lt;- sapply(validity_summary, function(x) x$high_validity_count)\nall_perfect_validity &lt;- sapply(validity_summary, function(x) x$perfect_validity_count)\nall_mean_validity &lt;- sapply(validity_summary, function(x) x$mean_validity)\n\nmessage(sprintf(\"Contrast with highest reliability: %s (%d/%d rows &gt; %.2f)\", \n                contrasts[[which.max(all_high_validity)]], \n                max(all_high_validity), total_rows, validity_threshold))\nmessage(sprintf(\"Contrast with lowest reliability: %s (%d/%d rows &gt; %.2f)\", \n                contrasts[[which.min(all_high_validity)]], \n                min(all_high_validity), total_rows, validity_threshold))\n\n# Check if all contrasts are highly reliable\nif(all(all_high_validity == total_rows)) {\n  message(\"✅ EXCELLENT: All contrasts have high validity (&gt;95%) across all parameter combinations!\")\n} else {\n  problematic_contrasts &lt;- names(contrasts)[all_high_validity &lt; total_rows]\n  message(sprintf(\"⚠️  WARNING: %d contrast(s) have some parameter combinations with low validity:\", \n                  length(problematic_contrasts)))\n  for(contrast in problematic_contrasts) {\n    message(sprintf(\"   • %s: %d/%d rows with validity ≤ %.2f\", \n                    contrasts[[contrast]], \n                    total_rows - all_high_validity[[contrast]], \n                    total_rows, validity_threshold))\n  }\n}\n\nmessage(\"\\n\" , paste(rep(\"=\", 60), collapse=\"\"))\n\n\n\n2.3.1 Simulate study\n\n\nCode\n# ---- 1. Load / install required packages ----\nrequired_pkgs &lt;- c(\"tidyverse\", \"MASS\", \"compositions\", \"extraDistr\")\nfor (p in required_pkgs) {\n  if (!requireNamespace(p, quietly = TRUE)) {\n    install.packages(p, repos = \"https://cloud.r-project.org\")\n  }\n  library(p, character.only = TRUE)\n}\n\n# ---- 2. Helper conversion functions (define if absent) ----\nif (!exists(\"comp_to_ilr\", mode = \"function\")) {\n  comp_to_ilr &lt;- function(x_min) {\n    stopifnot(is.matrix(x_min), ncol(x_min) == 3)\n    bad_row &lt;- !is.finite(rowSums(x_min)) | rowSums(x_min) &lt;= 0\n    if (any(bad_row)) {\n      x_min[bad_row, ] &lt;- matrix(rep(c(600, 480, 360), each = sum(bad_row)),\n                                 ncol = 3, byrow = TRUE)\n    }\n    x_min[x_min &lt;= 0 | !is.finite(x_min)] &lt;- 1e-6\n    compositions::ilr(sweep(x_min, 1, rowSums(x_min), \"/\"))\n  }\n}\n\nif (!exists(\"ilr_to_minutes\", mode = \"function\")) {\n  ilr_to_minutes &lt;- function(ilr_mat, total = 1440) {\n    stopifnot(is.matrix(ilr_mat), ncol(ilr_mat) == 2)\n    prop &lt;- as.matrix(compositions::ilrInv(ilr_mat))\n    bad &lt;- apply(prop, 1, function(r) any(!is.finite(r) | r &lt;= 0) ||\n                                   !is.finite(sum(r)) || abs(sum(r) - 1) &gt; 1e-8)\n    if (any(bad)) prop[bad, ] &lt;- 1/3\n    round(prop * total, 1)\n  }\n}\n\n# ---- 3. Data-generation function with compliance modelling ----\ngenerate_data &lt;- function(n_pg, effect_min, baseline_days, intervention_days,\n                          s_between, s_within, seed = NULL) {\n  if (!is.null(seed)) set.seed(seed)\n  N   &lt;- n_pg * 2\n  grp &lt;- rep(0:1, each = n_pg)          # 0 = Control, 1 = Intervention\n\n  # Mean daily compositions (sedentary, sleep, physical)\n  base_comp   &lt;- c(600, 480, 360)\n  active_comp &lt;- c(600 - effect_min, 480, 360 + effect_min)\n\n  # Person-level random effects in ILR space\n  b_ilr &lt;- MASS::mvrnorm(N, mu = c(0, 0), Sigma = diag(s_between^2, 2))\n\n  # Person-specific playtime proportion of sedentary time (10–40%)\n  personal_play_prop &lt;- rbeta(N, 2, 5) * 0.3 + 0.1\n\n  # Person-specific compliance (intervention only)\n  personal_compliance &lt;- ifelse(\n    grp == 0, 1,\n    rbeta(N, 2, 2) * 0.35 + 0.6\n  )\n\n  # Helper: daily compliance variation\n  daily_compliance_variation &lt;- function(n_days, base_compliance) {\n    pmax(0, pmin(1, base_compliance * (0.8 + 0.4 *\n           extraDistr::rkumar(n_days, a = 0.05, b = 0.1))))\n  }\n\n  # Storage\n  all_ids &lt;- all_periods &lt;- all_days &lt;- NULL\n  all_ilr &lt;- matrix(0, 0, 2)\n  playmin &lt;- numeric()\n\n  # Loop over people & periods\n  for (i in seq_len(N)) {\n    for (period in c(\"baseline\", \"intervention\")) {\n      ndays   &lt;- if (period == \"baseline\") baseline_days else intervention_days\n      comp_mu &lt;- if (period == \"baseline\" || grp[i] == 0) base_comp else active_comp\n\n      comp_ilr &lt;- comp_to_ilr(matrix(rep(comp_mu, ndays), ncol = 3, byrow = TRUE))\n      comp_ilr &lt;- sweep(comp_ilr, 2, b_ilr[i, ], \"+\")\n      day_ilr  &lt;- comp_ilr + MASS::mvrnorm(ndays, mu = c(0, 0),\n                                           Sigma = diag(s_within^2, 2))\n      all_ids     &lt;- c(all_ids, rep(i, ndays))\n      all_periods &lt;- c(all_periods, rep(period, ndays))\n      all_days    &lt;- c(all_days,\n                       if (period == \"baseline\") seq_len(baseline_days)\n                       else baseline_days + seq_len(intervention_days))\n      all_ilr     &lt;- rbind(all_ilr, day_ilr)\n    }\n  }\n\n  # Convert ILR → minutes\n  mins &lt;- ilr_to_minutes(all_ilr)\n  colnames(mins) &lt;- c(\"sedentary\", \"sleep\", \"physical\")\n\n  # Prepare daily compliance per participant\n  daily_compliance &lt;- lapply(seq_len(N), function(pid) {\n    if (grp[pid] == 0) rep(1, intervention_days)\n    else daily_compliance_variation(intervention_days, personal_compliance[pid])\n  })\n\n  intervention_day_counter &lt;- rep(0, N)\n  for (row in seq_along(all_ids)) {\n    pid   &lt;- all_ids[row]\n    period &lt;- all_periods[row]\n\n    base_playtime   &lt;- personal_play_prop[pid] * mins[row, \"sedentary\"]\n    noisy_playtime  &lt;- rnorm(1, base_playtime, 0.02 * base_playtime)\n\n    if (period == \"intervention\" && grp[pid] == 1) {\n      intervention_day_counter[pid] &lt;- intervention_day_counter[pid] + 1\n      daily_c &lt;- daily_compliance[[pid]][intervention_day_counter[pid]]\n      playmin[row] &lt;- pmax(0, noisy_playtime - effect_min * daily_c)\n    } else {\n      playmin[row] &lt;- pmax(0, noisy_playtime)\n    }\n  }\n\n  # Align daily compliance to rows\n  intervention_day_counter &lt;- rep(0, N)\n  daily_comp_rows &lt;- mapply(function(pid, per) {\n    if (per == \"intervention\" && grp[pid] == 1) {\n      intervention_day_counter[pid] &lt;&lt;- intervention_day_counter[pid] + 1\n      daily_compliance[[pid]][intervention_day_counter[pid]]\n    } else personal_compliance[pid]\n  }, all_ids, all_periods)\n\n  tibble(\n    id         = factor(all_ids),\n    group      = factor(grp[all_ids], labels = c(\"Control\", \"Abstinence\")),\n    period     = factor(all_periods, levels = c(\"baseline\", \"intervention\")),\n    day        = all_days,\n    sedentary  = mins[, 1],\n    sleep      = mins[, 2],\n    physical   = mins[, 3],\n    playtime   = playmin,\n    compliance = daily_comp_rows\n  ) %&gt;%\n    group_by(id) %&gt;%\n    mutate(\n      base_play_mean     = mean(playtime[period == \"baseline\"]),\n      playtime_reduction = base_play_mean - playtime,\n      intended_reduction = if_else(group == \"Abstinence\" & period == \"intervention\",\n                                   effect_min, 0),\n      actual_compliance  = if_else(intended_reduction &gt; 0,\n                                   pmin(1, playtime_reduction / intended_reduction),\n                                   compliance)\n    ) %&gt;%\n    ungroup()\n}\n\n# ---- 4. Run a demo simulation ----\nset.seed(123)\nsample_data &lt;- generate_data(\n  n_pg             = 40,\n  effect_min       = 60,\n  baseline_days    = 7,\n  intervention_days = 14,\n  s_between        = 0.3,\n  s_within         = 0.2\n)\n\nglimpse(sample_data)\n\n\nRows: 1,680\nColumns: 13\n$ id                 &lt;fct&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, …\n$ group              &lt;fct&gt; Control, Control, Control, Control, Control, Contro…\n$ period             &lt;fct&gt; baseline, baseline, baseline, baseline, baseline, b…\n$ day                &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, …\n$ sedentary          &lt;dbl&gt; 739.5, 644.0, 621.6, 693.8, 832.2, 675.4, 632.2, 89…\n$ sleep              &lt;dbl&gt; 462.0, 529.0, 415.8, 422.1, 414.0, 530.6, 512.0, 34…\n$ physical           &lt;dbl&gt; 238.5, 267.0, 402.7, 324.1, 193.8, 234.0, 295.7, 19…\n$ playtime           &lt;dbl&gt; 188.61254, 169.80919, 162.66917, 182.64180, 231.815…\n$ compliance         &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, …\n$ base_play_mean     &lt;dbl&gt; 182.33119, 182.33119, 182.33119, 182.33119, 182.331…\n$ playtime_reduction &lt;dbl&gt; -6.2813472, 12.5219954, 19.6620220, -0.3106143, -49…\n$ intended_reduction &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ actual_compliance  &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, …\n\n\nCode\n# Quick compliance summary\nsample_data %&gt;%\n  filter(group == \"Abstinence\", period == \"intervention\") %&gt;%\n  distinct(id, compliance) %&gt;%\n  summarise(\n    n               = n(),\n    mean_compliance = mean(compliance),\n    sd_compliance   = sd(compliance),\n    min_compliance  = min(compliance),\n    max_compliance  = max(compliance)\n  )\n\n\n# A tibble: 1 × 5\n      n mean_compliance sd_compliance min_compliance max_compliance\n  &lt;int&gt;           &lt;dbl&gt;         &lt;dbl&gt;          &lt;dbl&gt;          &lt;dbl&gt;\n1   417           0.802         0.124          0.508              1\n\n\n\n\nCode\n# Calculate daily means for compositions across all participants by group and period\ndaily_composition_means &lt;- sample_data %&gt;%\n  group_by(group, period, day) %&gt;%\n  summarise(\n    sedentary_mean = mean(sedentary, na.rm = TRUE),\n    sleep_mean = mean(sleep, na.rm = TRUE),\n    physical_mean = mean(physical, na.rm = TRUE),\n    .groups = \"drop\"\n  ) %&gt;%\n  pivot_longer(\n    cols = c(sedentary_mean, sleep_mean, physical_mean),\n    names_to = \"component\",\n    values_to = \"minutes\"\n  ) %&gt;%\n  mutate(\n    component = factor(\n      gsub(\"_mean\", \"\", component),\n      levels = c(\"sedentary\", \"sleep\", \"physical\"),\n      labels = c(\"Sedentary\", \"Sleep\", \"Physical Activity\")\n    )\n  )\n\n# Longitudinal compositional barplot\ncomposition_longitudinal &lt;- ggplot(daily_composition_means, \n                                  aes(x = day, y = minutes, fill = component)) +\n  geom_col(position = \"stack\", alpha = 0.8) +\n  geom_vline(xintercept = 7.5, linetype = \"dashed\", color = \"black\", size = 1) +\n  annotate(\"text\", x = 4, y = 1300, label = \"Baseline\", hjust = 0.5, size = 4, fontface = \"bold\") +\n  annotate(\"text\", x = 14, y = 1300, label = \"Intervention\", hjust = 0.5, size = 4, fontface = \"bold\") +\n  facet_wrap(~ group, \n             labeller = labeller(\n               group = c(\"Control\" = \"Control Group\", \"Abstinence\" = \"Abstinence Group\")\n             )) +\n  labs(\n    title = \"Daily Mean Compositions Over Time\",\n    subtitle = \"24-hour time use patterns by study day (stacked bars)\",\n    x = \"Study Day\",\n    y = \"Minutes per Day\",\n    fill = \"Component\"\n  ) +\n  theme_minimal() +\n  theme(\n    legend.position = \"bottom\",\n    strip.text = element_text(size = 12, face = \"bold\"),\n    panel.grid.minor.x = element_blank(),\n    panel.grid.major.x = element_blank()\n  ) +\n  scale_fill_viridis_d(option = \"plasma\", begin = 0.2, end = 0.8) +\n  scale_y_continuous(breaks = seq(0, 1400, 200)) +\n  scale_x_continuous(breaks = seq(0, 25, 5))\n\nprint(composition_longitudinal)\n\n\n\n\n\n\n\n\n\nCode\n# Calculate daily means for playtime by group and period\ndaily_playtime_means &lt;- sample_data %&gt;%\n  group_by(group, period, day) %&gt;%\n  summarise(\n    playtime_mean = mean(playtime, na.rm = TRUE),\n    playtime_se = sd(playtime, na.rm = TRUE) / sqrt(sum(!is.na(playtime))),\n    .groups = \"drop\"\n  )\n\n# Longitudinal plot for daily mean playtime - now faceted by group like the composition plot\nplaytime_longitudinal &lt;- ggplot(daily_playtime_means, \n                               aes(x = day, y = playtime_mean, color = group)) +\n  geom_line(size = 1.2, alpha = 0.8) +\n  geom_point(size = 2, alpha = 0.7) +\n  geom_ribbon(aes(ymin = playtime_mean - playtime_se, \n                  ymax = playtime_mean + playtime_se, \n                  fill = group), \n              alpha = 0.2, color = NA) +\n  geom_vline(xintercept = 7.5, linetype = \"dashed\", color = \"black\", size = 1) +\n  annotate(\"text\", x = 4, y = 175, label = \"Baseline\", hjust = 0.5, size = 4, fontface = \"bold\") +\n  annotate(\"text\", x = 14, y = 175, label = \"Intervention\", hjust = 0.5, size = 4, fontface = \"bold\") +\n  facet_wrap(~ group, \n             labeller = labeller(\n               group = c(\"Control\" = \"Control Group\", \"Abstinence\" = \"Abstinence Group\")\n             )) +\n  labs(\n    title = \"Daily Mean Playtime Over Time\",\n    subtitle = \"Gaming/screen time trends by study day with standard error bands\",\n    x = \"Study Day\",\n    y = \"Mean Playtime (minutes per day)\",\n    color = \"Group\",\n    fill = \"Group\"\n  ) +\n  theme_minimal() +\n  theme(\n    legend.position = \"bottom\",\n    strip.text = element_text(size = 12, face = \"bold\"),\n    panel.grid.minor.x = element_blank()\n  ) +\n  scale_color_manual(values = c(\"Control\" = \"#2E8B57\", \"Abstinence\" = \"#FF6347\")) +\n  scale_fill_manual(values = c(\"Control\" = \"#2E8B57\", \"Abstinence\" = \"#FF6347\")) +\n  scale_y_continuous(breaks = seq(0, 200, 25)) +\n  scale_x_continuous(breaks = seq(0, 25, 5))\n\nprint(playtime_longitudinal)\n\n\n\n\n\n\n\n\n\n\n\nCode\n# Calculate daily averages for compositions by group and period\ncomposition_summary &lt;- sample_data %&gt;%\n  group_by(group, period, id) %&gt;%\n  summarise(\n    sedentary = mean(sedentary),\n    sleep = mean(sleep), \n    physical = mean(physical),\n    .groups = \"drop\"\n  ) %&gt;%\n  pivot_longer(\n    cols = c(sedentary, sleep, physical),\n    names_to = \"component\",\n    values_to = \"minutes\"\n  ) %&gt;%\n  mutate(\n    component = factor(component, \n                      levels = c(\"sedentary\", \"sleep\", \"physical\"),\n                      labels = c(\"Sedentary\", \"Sleep\", \"Physical Activity\"))\n  )\n\n# Create 2x2 faceted plot for compositions\ncomposition_plot &lt;- ggplot(composition_summary, \n                          aes(x = component, y = minutes, fill = component)) +\n  geom_boxplot(alpha = 0.7) +\n  geom_point(position = position_jitter(width = 0.2), alpha = 0.3, size = 0.8) +\n  facet_grid(period ~ group, \n             labeller = labeller(\n               period = c(\"baseline\" = \"Baseline\", \"intervention\" = \"Intervention\"),\n               group = c(\"Control\" = \"Control Group\", \"Abstinence\" = \"Abstinence Group\")\n             )) +\n  labs(\n    title = \"Daily Average Compositions by Group and Period\",\n    subtitle = \"24-hour time use patterns (minutes per day)\",\n    x = \"Activity Component\",\n    y = \"Minutes per Day\",\n    fill = \"Component\"\n  ) +\n  theme_minimal() +\n  theme(\n    legend.position = \"bottom\",\n    strip.text = element_text(size = 12, face = \"bold\"),\n    axis.text.x = element_text(angle = 45, hjust = 1)\n  ) +\n  scale_fill_viridis_d(option = \"plasma\", begin = 0.2, end = 0.8) +\n  scale_y_continuous(breaks = seq(0, 800, 100))\n\nprint(composition_plot)\n\n\n\n\n\n\n\n\n\n\n\nCode\n# Calculate playtime averages by group and period  \nplaytime_summary &lt;- sample_data %&gt;%\n  group_by(group, period, id) %&gt;%\n  summarise(\n    avg_playtime = mean(playtime),\n    .groups = \"drop\"\n  )\n\n# Create 2x2 faceted plot for playtime\nplaytime_plot &lt;- ggplot(playtime_summary, \n                       aes(x = group, y = avg_playtime, fill = group)) +\n  geom_boxplot(alpha = 0.7, width = 0.6) +\n  geom_point(position = position_jitter(width = 0.2), alpha = 0.5, size = 1.2) +\n  stat_summary(fun = mean, geom = \"point\", shape = 23, size = 3, \n               fill = \"white\", color = \"black\") +\n  facet_wrap(~ period, \n             labeller = labeller(\n               period = c(\"baseline\" = \"Baseline Period\", \n                         \"intervention\" = \"Intervention Period\")\n             )) +\n  labs(\n    title = \"Average Daily Playtime by Group and Period\",\n    subtitle = \"Gaming/screen time reduction intervention effect\",\n    x = \"Study Group\",\n    y = \"Average Playtime (minutes per day)\",\n    fill = \"Group\"\n  ) +\n  theme_minimal() +\n  theme(\n    legend.position = \"bottom\",\n    strip.text = element_text(size = 12, face = \"bold\"),\n    panel.grid.minor = element_blank()\n  ) +\n  scale_fill_manual(values = c(\"Control\" = \"#2E8B57\", \"Intervention\" = \"#FF6347\")) +\n  scale_y_continuous(breaks = seq(0, 200, 25))\n\nprint(playtime_plot)\n\n\n\n\n\n\n\n\n\nCode\n# Summary statistics table\nplaytime_stats &lt;- playtime_summary %&gt;%\n  group_by(group, period) %&gt;%\n  summarise(\n    n = n(),\n    mean_playtime = round(mean(avg_playtime), 1),\n    sd_playtime = round(sd(avg_playtime), 1),\n    median_playtime = round(median(avg_playtime), 1),\n    q25 = round(quantile(avg_playtime, 0.25), 1),\n    q75 = round(quantile(avg_playtime, 0.75), 1),\n    .groups = \"drop\"\n  )\n\n# Display summary table\nknitr::kable(\n  playtime_stats,\n  caption = \"Summary Statistics for Daily Playtime by Group and Period\",\n  col.names = c(\"Group\", \"Period\", \"N\", \"Mean\", \"SD\", \"Median\", \"Q25\", \"Q75\")\n)\n\n\n\nSummary Statistics for Daily Playtime by Group and Period\n\n\nGroup\nPeriod\nN\nMean\nSD\nMedian\nQ25\nQ75\n\n\n\n\nControl\nbaseline\n40\n110.2\n31.1\n110.7\n87.6\n127.3\n\n\nControl\nintervention\n40\n110.0\n29.8\n107.3\n90.2\n127.8\n\n\nAbstinence\nbaseline\n40\n107.4\n36.7\n100.0\n78.7\n129.3\n\n\nAbstinence\nintervention\n40\n36.5\n31.9\n24.8\n11.3\n56.3",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>H1 - Effect of Abstention on Sendentary Activity</span>"
    ]
  },
  {
    "objectID": "scripts/sim_comp_report.html#minimum-detectable-effect-sizes-at-80-power",
    "href": "scripts/sim_comp_report.html#minimum-detectable-effect-sizes-at-80-power",
    "title": "2  H1 - Effect of Abstention on Sendentary Activity",
    "section": "2.5 Minimum Detectable Effect Sizes at 80% Power",
    "text": "2.5 Minimum Detectable Effect Sizes at 80% Power\nThis section analyzes the minimum detectable effect sizes (MDEs) at 80% power for different models and variability parameters, helping identify optimal study design configurations.\n\n2.5.1 ITT Effects - Minimum Detectable Effect Sizes\n\n\nShow code (ITT minimum detectable effects table)\n# Function to interpolate minimum detectable effect at 80% power\nfind_mde_80 &lt;- function(power_data) {\n  # If we already have 80% power or higher at the smallest effect, return that\n  if (min(power_data$power_interaction, na.rm = TRUE) &gt;= 0.8) {\n    return(min(power_data$effect_min, na.rm = TRUE))\n  }\n  \n  # If we never reach 80% power, return NA\n  if (max(power_data$power_interaction, na.rm = TRUE) &lt; 0.8) {\n    return(NA_real_)\n  }\n  \n  # Linear interpolation to find effect size at 80% power\n  approx(x = power_data$power_interaction, y = power_data$effect_min, xout = 0.8)$y\n}\n\n# Calculate minimum detectable effects for ITT across different variability settings\nmde_table_itt &lt;- power_results_multi %&gt;%\n  group_by(s_between, s_within) %&gt;%\n  summarise(\n    mde_80_itt = find_mde_80(cur_data()),\n    max_power_itt = max(power_interaction, na.rm = TRUE),\n    mean_power_itt = mean(power_interaction, na.rm = TRUE),\n    .groups = \"drop\"\n  ) %&gt;%\n  arrange(s_between, s_within) %&gt;%\n  mutate(\n    # Format effect sizes for display\n    mde_80_itt_fmt = ifelse(is.na(mde_80_itt), \n                           paste0(\"&gt;\", max(power_results_multi$effect_min)), \n                           sprintf(\"%.0f\", mde_80_itt)),\n    max_power_itt_fmt = sprintf(\"%.1f%%\", max_power_itt * 100),\n    mean_power_itt_fmt = sprintf(\"%.1f%%\", mean_power_itt * 100),\n    # Create combined variability label for easier interpretation\n    variability_profile = case_when(\n      s_between &lt;= 0.15 & s_within &lt;= 0.20 ~ \"Low variability (consistent participants)\",\n      s_between &lt;= 0.15 & s_within &gt; 0.20 ~ \"Low between, high within (stable people, variable days)\",\n      s_between &gt; 0.15 & s_within &lt;= 0.20 ~ \"High between, low within (different people, stable days)\",\n      TRUE ~ \"High variability (variable participants & days)\"\n    )\n  )\n\n# Create formatted table for ITT effects\nlibrary(kableExtra)\n\nmde_table_itt %&gt;%\n  dplyr::select(\n    `Between-Subject SD` = s_between,\n    `Within-Subject SD` = s_within,\n    `Variability Profile` = variability_profile,\n    `MDE at 80% Power (min)` = mde_80_itt_fmt,\n    `Mean Power` = mean_power_itt_fmt,\n    `Max Power Achieved` = max_power_itt_fmt\n  ) %&gt;%\n  kable(\n    caption = \"Minimum Detectable Effect Sizes at 80% Power - ITT (Intention-to-Treat) Effects\",\n    align = c(\"c\", \"c\", \"l\", \"c\", \"c\", \"c\")\n  ) %&gt;%\n  kable_styling(\n    bootstrap_options = c(\"striped\", \"hover\", \"condensed\"),\n    full_width = TRUE,\n    position = \"left\"\n  ) %&gt;%\n  pack_rows(\"Low Between-Subject Variability (0.10-0.15)\", 1, sum(mde_table_itt$s_between &lt;= 0.15)) %&gt;%\n  pack_rows(\"High Between-Subject Variability (0.20-0.30)\", sum(mde_table_itt$s_between &lt;= 0.15) + 1, nrow(mde_table_itt)) %&gt;%\n  footnote(\n    general = c(\n      \"MDE = Minimum Detectable Effect size at 80% power (minutes of sedentary time reduction)\",\n      \"Between-Subject SD reflects variability between different participants\",\n      \"Within-Subject SD reflects day-to-day variability within the same participant\",\n      \"Values &gt;120 indicate the model did not achieve 80% power at the largest tested effect size\"\n    ),\n    general_title = \"Notes:\"\n  )\n\n\n\nMinimum Detectable Effect Sizes at 80% Power - ITT (Intention-to-Treat) Effects\n\n\nBetween-Subject SD\nWithin-Subject SD\nVariability Profile\nMDE at 80% Power (min)\nMean Power\nMax Power Achieved\n\n\n\n\nLow Between-Subject Variability (0.10-0.15)\n\n\n0.00\n0.0\nLow variability (consistent participants)\n30\n100.0%\n100.0%\n\n\n0.00\n0.1\nLow variability (consistent participants)\n30\n94.1%\n100.0%\n\n\n0.00\n0.2\nLow variability (consistent participants)\n57\n71.4%\n99.6%\n\n\n0.00\n0.3\nLow between, high within (stable people, variable days)\n85\n51.6%\n85.8%\n\n\nHigh Between-Subject Variability (0.20-0.30)\n\n\n0.25\n0.0\nHigh between, low within (different people, stable days)\n30\n100.0%\n100.0%\n\n\n0.25\n0.1\nHigh between, low within (different people, stable days)\n30\n94.0%\n100.0%\n\n\n0.25\n0.2\nHigh between, low within (different people, stable days)\n58\n71.5%\n99.5%\n\n\n0.25\n0.3\nHigh variability (variable participants & days)\n83\n51.8%\n88.1%\n\n\n0.50\n0.1\nHigh between, low within (different people, stable days)\n30\n94.3%\n100.0%\n\n\n0.50\n0.2\nHigh between, low within (different people, stable days)\n58\n71.0%\n99.6%\n\n\n\nNotes:\n\n\n\n\n\n\n\n MDE = Minimum Detectable Effect size at 80% power (minutes of sedentary time reduction)\n\n\n\n\n\n\n\n Between-Subject SD reflects variability between different participants\n\n\n\n\n\n\n\n Within-Subject SD reflects day-to-day variability within the same participant\n\n\n\n\n\n\n\n Values &gt;120 indicate the model did not achieve 80% power at the largest tested effect size\n\n\n\n\n\n\n\n\n\n\n\n\n\n2.5.2 Per-Protocol Effects - Minimum Detectable Effect Sizes\n\n\nShow code (per-protocol minimum detectable effects table)\n# Function for per-protocol MDE calculation\nfind_mde_80_protocol &lt;- function(power_data, power_col) {\n  power_values &lt;- power_data[[power_col]]\n  # If we already have 80% power or higher at the smallest effect, return that\n  if (min(power_values, na.rm = TRUE) &gt;= 0.8) {\n    return(min(power_data$effect_min, na.rm = TRUE))\n  }\n  \n  # If we never reach 80% power, return NA\n  if (max(power_values, na.rm = TRUE) &lt; 0.8) {\n    return(NA_real_)\n  }\n  \n  # Linear interpolation to find effect size at 80% power\n  approx(x = power_values, y = power_data$effect_min, xout = 0.8)$y\n}\n\n# Calculate minimum detectable effects for both per-protocol approaches\nmde_table_protocol &lt;- power_results_multi %&gt;%\n  group_by(s_between, s_within) %&gt;%\n  summarise(\n    mde_80_change = find_mde_80_protocol(cur_data(), \"power_protocol_change\"),\n    mde_80_robust = find_mde_80_protocol(cur_data(), \"power_protocol_robust\"),\n    max_power_change = max(power_protocol_change, na.rm = TRUE),\n    max_power_robust = max(power_protocol_robust, na.rm = TRUE),\n    mean_power_change = mean(power_protocol_change, na.rm = TRUE),\n    mean_power_robust = mean(power_protocol_robust, na.rm = TRUE),\n    .groups = \"drop\"\n  ) %&gt;%\n  arrange(s_between, s_within) %&gt;%\n  mutate(\n    # Format effect sizes for display\n    mde_80_change_fmt = ifelse(is.na(mde_80_change), \n                              paste0(\"&gt;\", max(power_results_multi$effect_min)), \n                              sprintf(\"%.0f\", mde_80_change)),\n    mde_80_robust_fmt = ifelse(is.na(mde_80_robust), \n                              paste0(\"&gt;\", max(power_results_multi$effect_min)), \n                              sprintf(\"%.0f\", mde_80_robust)),\n    max_power_change_fmt = sprintf(\"%.1f%%\", max_power_change * 100),\n    max_power_robust_fmt = sprintf(\"%.1f%%\", max_power_robust * 100),\n    mean_power_change_fmt = sprintf(\"%.1f%%\", mean_power_change * 100),\n    mean_power_robust_fmt = sprintf(\"%.1f%%\", mean_power_robust * 100),\n    # Variability profile\n    variability_profile = case_when(\n      s_between &lt;= 0.15 & s_within &lt;= 0.20 ~ \"Low variability\",\n      s_between &lt;= 0.15 & s_within &gt; 0.20 ~ \"Low between, high within\",\n      s_between &gt; 0.15 & s_within &lt;= 0.20 ~ \"High between, low within\",\n      TRUE ~ \"High variability\"\n    )\n  )\n\n# Create side-by-side comparison table for per-protocol approaches\ncomparison_table &lt;- mde_table_protocol %&gt;%\n  dplyr::select(\n    `Between SD` = s_between,\n    `Within SD` = s_within,\n    `Profile` = variability_profile,\n    `Change Score MDE` = mde_80_change_fmt,\n    `Change Max Power` = max_power_change_fmt,\n    `Robust MDE` = mde_80_robust_fmt,\n    `Robust Max Power` = max_power_robust_fmt\n  )\n\ncomparison_table %&gt;%\n  kable(\n    caption = \"Per-Protocol Minimum Detectable Effect Sizes at 80% Power - Change Score vs Robust Approach\",\n    align = c(\"c\", \"c\", \"l\", \"c\", \"c\", \"c\", \"c\")\n  ) %&gt;%\n  kable_styling(\n    bootstrap_options = c(\"striped\", \"hover\", \"condensed\"),\n    full_width = FALSE,\n    position = \"left\"\n  ) %&gt;%\n  add_header_above(c(\" \" = 3, \"Change Score Approach\" = 2, \"Robust Approach\" = 2)) %&gt;%\n  pack_rows(\"Low Between-Subject Variability\", 1, sum(mde_table_protocol$s_between &lt;= 0.15)) %&gt;%\n  pack_rows(\"High Between-Subject Variability\", sum(mde_table_protocol$s_between &lt;= 0.15) + 1, nrow(mde_table_protocol)) %&gt;%\n  footnote(\n    general = c(\n      \"Change Score Approach: Tests if reducing playtime improves outcomes (positive effect)\",\n      \"Robust Approach: Tests if lower playtime during intervention improves outcomes (negative effect)\", \n      \"Both approaches test the same underlying hypothesis from different analytical perspectives\",\n      \"MDE values in minutes represent the minimum sedentary time reduction detectable at 80% power\"\n    ),\n    general_title = \"Notes:\"\n  )\n\n\n\nPer-Protocol Minimum Detectable Effect Sizes at 80% Power - Change Score vs Robust Approach\n\n\n\n\n\n\n\n\n\n\n\n\n\nChange Score Approach\n\n\nRobust Approach\n\n\n\nBetween SD\nWithin SD\nProfile\nChange Score MDE\nChange Max Power\nRobust MDE\nRobust Max Power\n\n\n\n\nLow Between-Subject Variability\n\n\n0.00\n0.0\nLow variability\n30\n100.0%\n72\n90.6%\n\n\n0.00\n0.1\nLow variability\n30\n100.0%\n&gt;90\n57.2%\n\n\n0.00\n0.2\nLow variability\n48\n100.0%\n&gt;90\n37.1%\n\n\n0.00\n0.3\nLow between, high within\n70\n98.0%\n&gt;90\n23.9%\n\n\nHigh Between-Subject Variability\n\n\n0.25\n0.0\nHigh between, low within\n86\n100.0%\n83\n87.5%\n\n\n0.25\n0.1\nHigh between, low within\n30\n100.0%\n&gt;90\n37.3%\n\n\n0.25\n0.2\nHigh between, low within\n50\n100.0%\n&gt;90\n31.3%\n\n\n0.25\n0.3\nHigh variability\n71\n98.7%\n&gt;90\n34.2%\n\n\n0.50\n0.1\nHigh between, low within\n30\n100.0%\n83\n88.8%\n\n\n0.50\n0.2\nHigh between, low within\n49\n100.0%\n86\n85.9%\n\n\n\nNotes:\n\n\n\n\n\n\n\n\n Change Score Approach: Tests if reducing playtime improves outcomes (positive effect)\n\n\n\n\n\n\n\n\n Robust Approach: Tests if lower playtime during intervention improves outcomes (negative effect)\n\n\n\n\n\n\n\n\n Both approaches test the same underlying hypothesis from different analytical perspectives\n\n\n\n\n\n\n\n\n MDE values in minutes represent the minimum sedentary time reduction detectable at 80% power",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>H1 - Effect of Abstention on Sendentary Activity</span>"
    ]
  },
  {
    "objectID": "scripts/sim_self_report.html#recalculating-h3b-power-with-corrected-interpretation",
    "href": "scripts/sim_self_report.html#recalculating-h3b-power-with-corrected-interpretation",
    "title": "4  H3 - Effect of Abstention on Wellbeing",
    "section": "4.5 Recalculating H3b Power with Corrected Interpretation",
    "text": "4.5 Recalculating H3b Power with Corrected Interpretation\nIf you have already run the simulations and need to recalculate the power with the correct interpretation:\n\n\nRecalculate H3b power with corrected interpretation\n# If you already have results_h3b from a previous simulation run:\nif (exists(\"results_h3b\")) {\n  sim_summary_h3b_corrected &lt;- results_h3b |&gt; \n    group_by(row_id) |&gt; \n    summarise(\n      model = first(model),\n      b = first(b),\n      expected_effect = first(expected_effect),\n      effect_shape = first(effect_shape),\n      mean_effect = mean(estimate, na.rm = TRUE),\n      mean_se = mean(std.error, na.rm = TRUE),\n      mean_conf.low = mean(conf.low, na.rm = TRUE),\n      mean_conf.high = mean(conf.high, na.rm = TRUE),\n      # Correct power calculation based on model type\n      power = if_else(\n        first(model) == \"fit_mlm_reduction_robust\",\n        sum(conf.high &lt; 0, na.rm = TRUE) / sum(!is.na(conf.high)),  # Robust expects negative\n        sum(conf.low &gt; 0, na.rm = TRUE) / sum(!is.na(conf.low))     # Change score expects positive\n      )\n    )\n  \n  message(\"Recalculated H3b summary with corrected power calculation\")\n  message(\"Change Score Approach - Mean Power: \", \n          round(mean(sim_summary_h3b_corrected$power[sim_summary_h3b_corrected$model == \"fit_mlm_reduction\"], na.rm = TRUE), 3))\n  message(\"Robust Approach - Mean Power: \", \n          round(mean(sim_summary_h3b_corrected$power[sim_summary_h3b_corrected$model == \"fit_mlm_reduction_robust\"], na.rm = TRUE), 3))\n}",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>H3 - Effect of Abstention on Wellbeing</span>"
    ]
  },
  {
    "objectID": "scripts/sim_self_report.html#timing-summary",
    "href": "scripts/sim_self_report.html#timing-summary",
    "title": "4  H3 - Effect of Abstention on Wellbeing",
    "section": "4.6 Timing Summary",
    "text": "4.6 Timing Summary\n\n\nShow code (timing summary)\n# Print timing summary if timing objects exist from tictoc\nif (exists(\"h3a_time\") && exists(\"h3b_time\")) {\n  cat(\"=== SIMULATION TIMING SUMMARY ===\\n\")\n  cat(sprintf(\"H3a simulations took: %.2f minutes\\n\", (h3a_time$toc - h3a_time$tic) / 60))\n  cat(sprintf(\"H3b simulations took: %.2f minutes\\n\", (h3b_time$toc - h3b_time$tic) / 60))\n  cat(sprintf(\"Total simulation time: %.2f minutes\\n\", \n              ((h3a_time$toc - h3a_time$tic) + (h3b_time$toc - h3b_time$tic)) / 60))\n  cat(\"================================\\n\")\n}",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>H3 - Effect of Abstention on Wellbeing</span>"
    ]
  }
]